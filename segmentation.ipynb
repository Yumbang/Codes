{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import Type\n",
    "from torch import nn\n",
    "from torch.optim import optimizer\n",
    "import rasterio\n",
    "import zipfile\n",
    "from matplotlib import pyplot as plt\n",
    "import datetime\n",
    "from torchvision import transforms as transforms\n",
    "import shutil\n",
    "import torchmetrics\n",
    "import os\n",
    "import pytorch_lightning as pl\n",
    "import sklearn\n",
    "from torch.nn import functional as F\n",
    "import tqdm\n",
    "\n",
    "# --- GPU selection --- #\n",
    "gpus = 7 # slot number (e.g., 3), no gpu use -> write just ' '\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpus)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax(array : Type[np.ndarray], dim = 0):\n",
    "    min = np.min(array, axis=dim)\n",
    "    max = np.max(array, axis=dim)\n",
    "    array = (array-min)/(max-min)\n",
    "    return array\n",
    "\n",
    "def log_minmax(array : Type[np.ndarray], dim = 0):\n",
    "    min = array.min()\n",
    "    array = array - min + 1\n",
    "    array = np.log(array)\n",
    "    max = array.max()\n",
    "    array = (array)/(max)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result(model: Type[nn.Module], dataloader : Type[DataLoader], path:str, description:str = '', reference_data:str = '', patch_size:int = 60, now = datetime.datetime.now()):\n",
    "    best_model = model\n",
    "    os.makedirs(os.path.join(path,f'{now.year}.{now.month}.{now.day}/', f'{description}/','tmp/'), exist_ok=True)\n",
    "    zipped_results = zipfile.ZipFile(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','RESULT_{0:0=2d}:{1:0=2d}'.format(now.hour, now.minute)+f'_{description}.zip'), 'w')\n",
    "    prediction = np.zeros((2400//patch_size,2400//patch_size,7))\n",
    "\n",
    "    with tqdm.tqdm(enumerate(dataloader)) as data_pbar:\n",
    "        data_pbar.set_description('Predicting...')\n",
    "        for i, (data, index_OHE, index) in data_pbar:\n",
    "            prediction[i, :, :] = best_model(data).detach().numpy()\n",
    "\n",
    "    \n",
    "\n",
    "    prediction_expanded = np.zeros((7,2400,2400))\n",
    "    for i in range(2400//patch_size):\n",
    "        for j in range(2400//patch_size):\n",
    "            for k in range(7):\n",
    "                prediction_expanded[k,i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size] = prediction[i,j,k]\n",
    "\n",
    "    reference_image = rasterio.open(reference_data)\n",
    "    layer_index = [1,2,7,8,9,10,11]\n",
    "\n",
    "    with tqdm.trange(prediction_expanded.shape[0]) as write_pbar:\n",
    "        write_pbar.set_description('Writing data')\n",
    "        for i in write_pbar:\n",
    "            #print('a') \n",
    "            processed_tiff = rasterio.open(\n",
    "                os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/', 'tmp/', f'Result_{layer_index[i]}_{description}.tif'),\n",
    "                'w',\n",
    "                driver='GTiff',\n",
    "                height=prediction_expanded.shape[1],\n",
    "                width=prediction_expanded.shape[2],\n",
    "                count=1,\n",
    "                dtype=prediction_expanded.dtype,\n",
    "                crs=reference_image.crs,\n",
    "                transform=reference_image.transform,\n",
    "            )\n",
    "            #print('b')\n",
    "            processed_tiff.write(prediction_expanded[i,:,:],1)\n",
    "            processed_tiff.close()\n",
    "            #print('c')\n",
    "            zipped_results.write(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/', 'tmp/', f'Result_{layer_index[i]}_{description}.tif'), f'Result_{layer_index[i]}_{description}.tif')\n",
    "\n",
    "    zipped_results.close()\n",
    "    return os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','RESULT_{0:0=2d}:{1:0=2d}'.format(now.hour, now.minute)+f'_{description}.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, scheduler, device, num_epochs=13, train_rate: float = 0.8, batch_size: int = 60, path:str = '../Data/N12/Model/', description:str = 'no_description', reference_data:str = ''): \n",
    "    train_loss_history = []\n",
    "    valid_loss_history = []\n",
    "\n",
    "    patch_size = dataloaders['Train'].dataset.data.shape[-1]\n",
    "    training_patches = len(dataloaders['Train'].dataset)\n",
    "    validating_patches = len(dataloaders['Validation'].dataset)\n",
    "    print(f'Training Patches : {training_patches}\\nValidating Patches : {validating_patches}')\n",
    "\n",
    "    best_model_epoch = 0\n",
    "    least_valid_loss = 100\n",
    "    now = datetime.datetime.now()\n",
    "    os.makedirs(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/', 'tmp/'), exist_ok=True)\n",
    "    zipped_model = zipfile.ZipFile(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/', '{0:0=2d}:{1:0=2d}'.format(now.hour, now.minute)+f'_{description}'+'.zip'), 'w')\n",
    "    \n",
    "    epoch_range = tqdm.trange(num_epochs)\n",
    "    for epoch in epoch_range:\n",
    "\n",
    "        train_running_loss = 0.0\n",
    "        valid_running_loss = 0.0\n",
    "\n",
    "        epoch_range.set_description(f'EPOCH #{epoch}')\n",
    "        \n",
    "\n",
    "        for state in ['Train', 'Validation']:\n",
    "            #pbar = tqdm.tqdm(dataloaders[state])\n",
    "            for inputs, labels_OHE, labels in dataloaders[state]:\n",
    "                \n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                model.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                if state == 'Train':\n",
    "                    model.train()\n",
    "                    train_loss = criterion(outputs, labels)\n",
    "                    train_loss.backward()\n",
    "                    train_running_loss += train_loss.item() * inputs.size(0)\n",
    "                    #pbar.set_description('Train')\n",
    "                \n",
    "                if state == 'Validation':\n",
    "                    model.eval()\n",
    "                    valid_loss = criterion(outputs, labels)\n",
    "                    valid_running_loss += valid_loss.item() * inputs.size(0)\n",
    "                    #pbar.set_description('Valid')\n",
    "\n",
    "                optimizer.step()\n",
    "                #valid_running_similarity += metric(outputs, labels)\n",
    "                #print('validating')\n",
    "                \n",
    "                #print(f'{i}th batch')\n",
    "            #pbar.clear()\n",
    "            \n",
    "        epoch_range.refresh()\n",
    "\n",
    "        \n",
    "        #print(f'Memory after a training : {torch.cuda.memory_allocated()/1024/1024}')\n",
    "\n",
    "        epoch_train_loss = train_running_loss / training_patches\n",
    "        epoch_valid_loss = valid_running_loss / validating_patches\n",
    "        scheduler.step(epoch_valid_loss)\n",
    "\n",
    "        #print(f'Valid loss: {epoch_valid_loss} | Train loss: {epoch_train_loss}')\n",
    "\n",
    "\n",
    "        if epoch_valid_loss < least_valid_loss:\n",
    "            least_valid_loss = epoch_valid_loss\n",
    "            best_model_epoch = epoch\n",
    "\n",
    "        train_loss_history.append(epoch_train_loss)      \n",
    "        valid_loss_history.append(epoch_valid_loss)\n",
    "\n",
    "        torch.save(model.state_dict(), os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','tmp/', '{0:0=2d}.pth'.format(epoch)))\n",
    "        zipped_model.write(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','tmp/', '{0:0=2d}.pth'.format(epoch)))\n",
    "\n",
    "    plt.figure(figsize=(20,8))\n",
    "    plt.plot(train_loss_history, 'r-')\n",
    "    plt.plot(valid_loss_history, 'bo')\n",
    "    plt.savefig(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','tmp/', 'Tendency.png'), dpi=300)\n",
    "    zipped_model.write(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','tmp/', 'Tendency.png'))\n",
    "    zipped_model.writestr('README.txt', f'{description}\\nThe best Model : #{best_model_epoch}th model with loss {least_valid_loss}\\nOptimizer : {optimizer}\\nLoss function : {criterion}\\nBatch size : {batch_size}\\nScheduler : {scheduler}\\nPatch size : {patch_size}\\nTotal epochs : {num_epochs}\\nModel information :\\n{model.modules}')\n",
    "    \n",
    "    print('Best loss: {:4f}, in Epoch #{:0=3d}'.format(least_valid_loss, best_model_epoch))    \n",
    "    zipped_model.close()\n",
    "    shutil.copy(src=os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/', 'tmp/', '{0:0=2d}.pth'.format(epoch)), dst=os.path.join(path,f'{now.year}.{now.month}.{now.day}/', 'Best_Model_Parameters_of_{0:0=2d}:{1:0=2d}'.format(now.hour, now.minute)+f'_{description}'+'.pth'))\n",
    "    print('Model information is saved in '+os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/', '{0:0=2d}:{1:0=2d}'.format(now.hour, now.minute)+f'_{description}'+'.zip'))\n",
    "\n",
    "    model.load_state_dict(torch.load(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','tmp/', '{0:0=2d}.pth'.format(best_model_epoch))))\n",
    "    result_path = save_result(model = model.to('cpu'), dataloader=dataloaders['Prediction'], path=path, description=description, reference_data=reference_data, patch_size=patch_size, now=now)\n",
    "    print('Model result is saved in '+ result_path)\n",
    "    \n",
    "    shutil.rmtree(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','tmp/'))\n",
    "    best_model_path = os.path.join(path,f'{now.year}.{now.month}.{now.day}/', 'Best_Model_Parameters_of_{0:0=2d}:{1:0=2d}'.format(now.hour, now.minute)+f'_{description}'+'.pth')\n",
    "    return best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_raw_files(region:str):\n",
    "    if (os.path.exists(f'../Data/{region}/np/train_array.npy') and os.path.exists(f'../Data/{region}/np/target_array_OHE.npy')) and (os.path.exists(f'../Data/{region}/np/target_array_RAW.npy')):\n",
    "        print('Preexisting Data Found. Loading...')\n",
    "        train_array = np.load(f'../Data/{region}/np/train_array.npy')\n",
    "        target_array_OHE = np.load(f'../Data/{region}/np/target_array_OHE.npy')\n",
    "        target_array = np.load(f'../Data/{region}/np/target_array_RAW.npy')\n",
    "    else:\n",
    "        print('No Data Found. Loading from Raw Data')\n",
    "        lidar_image = rasterio.open(f'../Data/{region}/{region}_lidar.tif').read()\n",
    "        lidar_array = np.array(lidar_image)\n",
    "        lidar_array = log_minmax(lidar_array, dim=(0,1))\n",
    "\n",
    "        lidar_1n_image = rasterio.open(f'../Data/{region}/{region}_lidar_1n.tif').read()\n",
    "        lidar_1n_array = np.array(lidar_1n_image)\n",
    "        lidar_1n_array = log_minmax(lidar_1n_array, dim=(0,1))\n",
    "\n",
    "        lidar_nt_image = rasterio.open(f'../Data/{region}/{region}_lidar_nt.tif').read()\n",
    "        lidar_nt_array = np.array(lidar_nt_image)\n",
    "        lidar_nt_array = log_minmax(lidar_nt_array, dim=(0,1))\n",
    "\n",
    "        RGB2020_image = rasterio.open(f'../Data/{region}/{region}_RGB2020.tif').read()\n",
    "        RGB2020_array = np.array(RGB2020_image)\n",
    "\n",
    "        train_array = np.stack([lidar_array, lidar_1n_array, lidar_nt_array]).squeeze()\n",
    "        train_array = np.concatenate((train_array,RGB2020_array))\n",
    "        target_image = rasterio.open(f'../Data/{region}/{region}_newlc.tif').read()\n",
    "        target_array = np.array(target_image, dtype=int).squeeze()\n",
    "        target_array = np.where(target_array == 1, 0, target_array)\n",
    "        target_array = np.where(target_array == 2, 1, target_array)\n",
    "        target_array = np.where(target_array == 7, 2, target_array)\n",
    "        target_array = np.where(target_array == 8, 3, target_array)\n",
    "        target_array = np.where(target_array == 9, 4, target_array)\n",
    "        target_array = np.where(target_array == 10, 5, target_array)\n",
    "        target_array = np.where(target_array == 11, 6, target_array)\n",
    "\n",
    "        target_array_OHE = np.zeros(shape=(7,2400,2400))\n",
    "        num = np.unique(target_array)\n",
    "\n",
    "        num = max(num.shape[0],7)\n",
    "        encoded_target_array = np.eye(num)[target_array]\n",
    "        for i in range(encoded_target_array.shape[-1]):\n",
    "            target_array_OHE[i,:,:]=encoded_target_array[:,:,i]\n",
    "        \n",
    "        os.makedirs(f'../Data/{region}/np', exist_ok=True)\n",
    "        np.save(f'../Data/{region}/np/train_array.npy', train_array)\n",
    "        np.save(f'../Data/{region}/np/target_array_RAW.npy', target_array)\n",
    "        np.save(f'../Data/{region}/np/target_array_OHE.npy', target_array_OHE)\n",
    "\n",
    "    return train_array, target_array.astype(int), target_array_OHE.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset2(Dataset):\n",
    "    def __init__(self, data_array : Type[np.ndarray], target_array_OHE : Type[np.ndarray], target_array_RAW : Type[np.ndarray], patch_size : int, is_evaluating : bool = False, is_validating : bool = False, rotate : bool = False, train_ratio : float = 0.8):\n",
    "        self.is_validating = is_validating\n",
    "        self.is_evaluating = is_evaluating\n",
    "        seed = 386579\n",
    "\n",
    "        #print(f'Data shape: {data_array.shape} | Target shape: {target_array.shape}')\n",
    "\n",
    "        self.data = np.zeros(((data_array.shape[1]//patch_size) * (data_array.shape[2]//patch_size), data_array.shape[0], patch_size, patch_size))\n",
    "\n",
    "        for i in range(0,data_array.shape[1]//patch_size):\n",
    "            for j in range(0,data_array.shape[2]//patch_size):\n",
    "                self.data[data_array.shape[1]//patch_size*i+j,:,:,:] = data_array[:,i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size]\n",
    "\n",
    "        self.label_OHE = np.zeros(((data_array.shape[1]//patch_size) * (data_array.shape[2]//patch_size), target_array_OHE.shape[0] ,patch_size, patch_size), dtype=float)\n",
    "        for k in range(0,data_array.shape[1]//patch_size):\n",
    "            for l in range(0,data_array.shape[2]//patch_size):\n",
    "                self.label_OHE[data_array.shape[1]//patch_size*k+l,:,:,:] = target_array_OHE[:,i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size]\n",
    "\n",
    "        self.label_RAW = np.zeros(((data_array.shape[1]//patch_size) * (data_array.shape[2]//patch_size),data_array.shape[0]+1))\n",
    "        for k in range(0,data_array.shape[1]//patch_size):\n",
    "            for l in range(0,data_array.shape[2]//patch_size):\n",
    "                self.label_RAW[data_array.shape[1]//patch_size*k+l,:] = np.bincount(target_array_RAW[k*patch_size:(k+1)*patch_size, l*patch_size:(l+1)*patch_size].reshape(-1), minlength=7)/(patch_size*patch_size)\n",
    "\n",
    "\n",
    "        if not is_evaluating:\n",
    "            if rotate:\n",
    "                for i in range(2):\n",
    "                    rotated_data = np.rot90(self.data, k=i+1, axes=(-2, -1))\n",
    "                    self.data = np.concatenate((self.data, rotated_data), axis=0)\n",
    "                    rotated_label_OHE = np.rot90(self.label_OHE, k=i+1, axes=(-2, -1))\n",
    "                    rotated_label_RAW = self.label_RAW\n",
    "                    self.label_OHE = np.concatenate((self.label_OHE, rotated_label_OHE), axis=0)\n",
    "                    self.label_RAW = np.concatenate((self.label_RAW, rotated_label_RAW), axis=0)\n",
    "\n",
    "        train_size = int(self.data.shape[0]*train_ratio)\n",
    "        index_array = np.random.RandomState(seed=seed).permutation(self.data.shape[0])\n",
    "        self.train_index = index_array[0:train_size]\n",
    "        self.valid_index = index_array[train_size:index_array.shape[0]]\n",
    "        \n",
    "        self.data = torch.as_tensor(self.data).float()\n",
    "        self.label_OHE = torch.as_tensor(self.label_OHE).float()\n",
    "        self.label_RAW = torch.as_tensor(self.label_RAW).float()\n",
    "\n",
    "        self.data[:,3:6,:,:] = self.data[:,3:6,:,:]/255\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.is_evaluating:\n",
    "            return self.data.shape[0]\n",
    "\n",
    "        if self.is_validating:\n",
    "            return self.valid_index.shape[0]\n",
    "        else:\n",
    "            return self.train_index.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_evaluating:\n",
    "            sample = torch.as_tensor(self.data[idx,:,:,:]).float()\n",
    "            label_OHE = torch.as_tensor(self.label_OHE[idx,:]).float()\n",
    "            label_RAW = torch.as_tensor(self.label_RAW[idx,:]).float()\n",
    "            return sample, label_OHE, label_RAW\n",
    "        \n",
    "        if self.is_validating:\n",
    "            sample = torch.as_tensor(self.data[self.valid_index[idx],:,:,:]).float()\n",
    "            label_OHE = torch.as_tensor(self.label_OHE[self.valid_index[idx],:]).float()\n",
    "            label_RAW = torch.as_tensor(self.label_RAW[self.valid_index[idx],:]).float()\n",
    "        else:\n",
    "            sample = torch.as_tensor(self.data[self.train_index[idx],:,:,:]).float()\n",
    "            label_OHE = torch.as_tensor(self.label_OHE[self.train_index[idx],:]).float()\n",
    "            label_RAW = torch.as_tensor(self.label_RAW[self.train_index[idx],:]).float()\n",
    "\n",
    "        return sample, label_OHE, label_RAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_padding(inputs, kernel_size, dilation):\n",
    "    kernel_size_effective = kernel_size + (kernel_size - 1) * (dilation - 1)\n",
    "    pad_total = kernel_size_effective - 1\n",
    "    pad_beg = pad_total // 2\n",
    "    pad_end = pad_total - pad_beg\n",
    "    padded_inputs = F.pad(inputs, (pad_beg, pad_end, pad_beg, pad_end))\n",
    "    return padded_inputs\n",
    "\n",
    "\n",
    "class SeparableConv2d(nn.Module):\n",
    "    def __init__(self, inplanes, planes, kernel_size=3, stride=1, dilation=1, bias=False, BatchNorm=None):\n",
    "        super(SeparableConv2d, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(inplanes, inplanes, kernel_size, stride, 0, dilation,\n",
    "                               groups=inplanes, bias=bias)\n",
    "        self.bn = BatchNorm(inplanes)\n",
    "        self.pointwise = nn.Conv2d(inplanes, planes, 1, 1, 0, 1, 1, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = fixed_padding(x, self.conv1.kernel_size[0], dilation=self.conv1.dilation[0])\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBN(nn.Module):\n",
    "    def __init__(self, C_in, C_out, kernel_size, stride, dilation = 1, affine=True, fix_padding = False):\n",
    "        super(ConvBN, self).__init__()\n",
    "        self.fix_padding = fix_padding\n",
    "        self.conv2d = nn.Conv2d(C_in, C_in, kernel_size=kernel_size, stride=stride, groups=C_in, bias=False, dilation=dilation)\n",
    "        self.pointwise = nn.Conv2d(C_in, C_out, kernel_size=1, padding=0, bias=False)\n",
    "        self.batchnorm = nn.BatchNorm2d(C_in, affine=affine)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.fix_padding:\n",
    "           x = fixed_padding(x, self.conv2d.kernel_size[0], dilation=self.conv2d.dilation[0])\n",
    "        x = self.conv2d(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UrbanGreenRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UrbanGreenRegression, self).__init__()\n",
    "        '''self.conv_block_1 = nn.Sequential(\n",
    "            ConvBN(6,32,3,1),#98\n",
    "            nn.ReLU(),\n",
    "            ConvBN(32,32,3,1),#96\n",
    "            nn.ReLU(),\n",
    "            ConvBN(32,32,3,1),#94\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)#47\n",
    "        )\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            ConvBN(32,64,3,1),#45\n",
    "            nn.ReLU(),\n",
    "            ConvBN(64,64,3,1),#43\n",
    "            nn.ReLU(),\n",
    "            ConvBN(64,64,3,1),#41\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)#8\n",
    "        )'''\n",
    "\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(6,1,kernel_size=1,stride=1),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc_block_1 = nn.Sequential(\n",
    "            nn.Linear(in_features=100, out_features=256, bias=False),\n",
    "            nn.BatchNorm1d(num_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=256, bias=False),\n",
    "            nn.BatchNorm1d(num_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=256, bias=False),\n",
    "            nn.BatchNorm1d(num_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=256, bias=False),\n",
    "            nn.BatchNorm1d(num_features=256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc_block_2 = nn.Sequential(\n",
    "            nn.Linear(in_features=256, out_features=64, bias=False),\n",
    "            nn.BatchNorm1d(num_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=64, bias=False),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,7, False),\n",
    "            nn.BatchNorm1d(7)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv_block_1(x)\n",
    "        #x = self.conv_block_2(x)\n",
    "        #print(x.shape)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        #print(x.shape)\n",
    "        x = self.fc_block_1(x)\n",
    "        x = self.fc_block_2(x)\n",
    "        return torch.softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Data Found. Loading from Raw Data\n"
     ]
    }
   ],
   "source": [
    "raw_data_array ,raw_target_array, OHE_target_array = prepare_raw_files('N12')\n",
    "batch_size = 4\n",
    "patch_size = 100\n",
    "train_ratio = 0.8\n",
    "rotate_training_data = False\n",
    "Datasets_NON_OHE = {\n",
    "    'Train' : TrainDataset2(raw_data_array, OHE_target_array, raw_target_array, patch_size = patch_size, rotate = rotate_training_data, train_ratio = train_ratio),\n",
    "    'Validation' : TrainDataset2(raw_data_array, OHE_target_array, raw_target_array, patch_size = patch_size, is_validating = True, rotate = rotate_training_data, train_ratio = train_ratio),\n",
    "    'Prediction' : TrainDataset2(raw_data_array, OHE_target_array, raw_target_array, patch_size = patch_size, is_evaluating = True, train_ratio = train_ratio)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Datasets_NON_OHE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1293/1910343804.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m Dataloaders_NON_OHE = {\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;34m'Train'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDatasets_NON_OHE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m'Validation'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDatasets_NON_OHE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Validation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m'Prediction'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDatasets_NON_OHE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Prediction'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2400\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Datasets_NON_OHE' is not defined"
     ]
    }
   ],
   "source": [
    "Dataloaders_NON_OHE = {\n",
    "    'Train' : DataLoader(Datasets_NON_OHE['Train'], batch_size=batch_size),\n",
    "    'Validation' : DataLoader(Datasets_NON_OHE['Validation'], batch_size=batch_size),\n",
    "    'Prediction' : DataLoader(Datasets_NON_OHE['Prediction'], batch_size=2400//patch_size)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [64, 1, 10, 10]               7\n",
      "       BatchNorm2d-2            [64, 1, 10, 10]               2\n",
      "              ReLU-3            [64, 1, 10, 10]               0\n",
      "            Linear-4                  [64, 256]          25,600\n",
      "       BatchNorm1d-5                  [64, 256]             512\n",
      "              ReLU-6                  [64, 256]               0\n",
      "            Linear-7                  [64, 256]          65,536\n",
      "       BatchNorm1d-8                  [64, 256]             512\n",
      "              ReLU-9                  [64, 256]               0\n",
      "           Linear-10                  [64, 256]          65,536\n",
      "      BatchNorm1d-11                  [64, 256]             512\n",
      "             ReLU-12                  [64, 256]               0\n",
      "           Linear-13                  [64, 256]          65,536\n",
      "      BatchNorm1d-14                  [64, 256]             512\n",
      "             ReLU-15                  [64, 256]               0\n",
      "           Linear-16                   [64, 64]          16,384\n",
      "      BatchNorm1d-17                   [64, 64]             128\n",
      "             ReLU-18                   [64, 64]               0\n",
      "           Linear-19                   [64, 64]           4,096\n",
      "      BatchNorm1d-20                   [64, 64]             128\n",
      "             ReLU-21                   [64, 64]               0\n",
      "           Linear-22                    [64, 7]             448\n",
      "      BatchNorm1d-23                    [64, 7]              14\n",
      "================================================================\n",
      "Total params: 245,463\n",
      "Trainable params: 245,463\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.15\n",
      "Forward/backward pass size (MB): 1.84\n",
      "Params size (MB): 0.94\n",
      "Estimated Total Size (MB): 2.92\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "model_for_summary = UrbanGreenRegression()\n",
    "model_for_summary.to(device)\n",
    "summary(model_for_summary, input_size=(6,10,10), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = UrbanGreenRegression()\n",
    "criterion2 = torch.nn.MSELoss(reduction='mean')\n",
    "optimizer2 = torch.optim.SGD(model2.parameters(), lr=0.01, momentum=0.9)\n",
    "scheduler2 = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer2, 'min', patience=5, factor=0.75)\n",
    "best_model_path = train_model(model2, Dataloaders_NON_OHE, criterion2, optimizer2, scheduler2, device, num_epochs=100, batch_size=batch_size, path='/home/bcyoon/Byeongchan/Data/N12/Model/Segmentation/Regression/', description='patch_10_pointwiseConv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = '/home/bcyoon/Byeongchan/Data/N12/Model/Segmentation/Regression/2022.7.26/Best_Model_Parameters_of_15:32_patch_10_pointwiseConv.pth'\n",
    "model2.load_state_dict(torch.load(best_model_path))\n",
    "result_path = save_result(model = model2.to('cpu'), dataloader=Dataloaders_NON_OHE['Prediction'], path='/home/bcyoon/Byeongchan/Data/N12/Model/Segmentation/Regression/', description='patch_10_pointwiseConv', reference_data='/home/bcyoon/Byeongchan/Data/N12/N12_lidar.tif', patch_size=patch_size, now=datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBN(nn.Module):\n",
    "    def __init__(self, Cin, Cout, kernel_size, stride=1):\n",
    "        super(ConvBN,self).__init__()\n",
    "        self.conv = nn.Conv2d(Cin, Cin, kernel_size=kernel_size, stride=stride, groups=Cin, bias=False)\n",
    "        self.batchnorm = nn.BatchNorm2d(Cin)\n",
    "        self.pointwise = nn.Conv2d(Cin, Cout, kernel_size=1, padding=0, bias=False)\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegBlock(nn.Module):\n",
    "    def __init__(self, skip:bool, in_channel:int, out_channel:int, is_last:bool = False):\n",
    "        super(SegBlock,self).__init__()\n",
    "        self.skip = skip\n",
    "        self.is_last = is_last\n",
    "        self.conv1 = ConvBN(in_channel, out_channel, kernel_size=3, stride=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = ConvBN(out_channel, out_channel, kernel_size=3, stride=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_add(skip:Type[torch.Tensor], target:Type[torch.Tensor])->torch.Tensor:\n",
    "    cropped_skip = skip[:,:,(skip.shape[-2]-target.shape[-2])//2:(skip.shape[-2]+target.shape[-2])//2,(skip.shape[-1]-target.shape[-1])//2:(skip.shape[-1]+target.shape[-1])//2]\n",
    "    return torch.cat((cropped_skip, target), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        self.enc1 = SegBlock(True, 3,64)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.enc2 = SegBlock(True, 64,128)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.enc3 = SegBlock(True, 128, 256)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.enc4 = SegBlock(True, 256, 512)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "        self.dec0 = SegBlock(False, 512, 1024)\n",
    "        self.upconv1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.dec1 = SegBlock(False,1024,512)\n",
    "        self.upconv2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec2 = SegBlock(False,512,256)\n",
    "        self.upconv3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec3 = SegBlock(False,256,128)\n",
    "        self.upconv4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec4 = SegBlock(False,128,64, is_last = True)\n",
    "\n",
    "    def forward(self,x):\n",
    "        enc1 = self.enc1(x)\n",
    "        x = self.pool1(enc1)\n",
    "        enc2 = self.enc2(x)\n",
    "        x = self.pool2(enc2)\n",
    "        enc3 = self.enc3(x)\n",
    "        x = self.pool3(enc3)\n",
    "        enc4 = self.enc4(x)\n",
    "        x = self.pool4(enc4)\n",
    "        x = self.dec0(x)\n",
    "        x = self.upconv1(x)\n",
    "        x = self.dec1(crop_add(enc4, x))\n",
    "        x = self.upconv2(x)\n",
    "        x = self.dec2(crop_add(enc3, x))\n",
    "        x = self.upconv3(x)\n",
    "        x = self.dec3(crop_add(enc2, x))\n",
    "        x = self.upconv4(x)\n",
    "        x = self.dec4(crop_add(enc1, x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mirror_extrapolate(inp:torch.Tensor, in_shape:tuple = (100,100), out_shape:tuple = (284,284)) -> torch.Tensor: # 배치 포함해서 input으로 넣어야 함\n",
    "    pad = ((out_shape[0]-in_shape[0])//2,(out_shape[0]-in_shape[0])//2,(out_shape[0]-in_shape[0])//2,(out_shape[0]-in_shape[0])//2)\n",
    "    return F.pad(inp, pad=pad, mode=\"reflect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset3(Dataset):\n",
    "    def __init__(self, data_array : Type[np.ndarray], target_array_OHE : Type[np.ndarray], target_array_RAW : Type[np.ndarray], patch_size : int, is_evaluating : bool = False, is_validating : bool = False, rotate : bool = False, train_ratio : float = 0.8):\n",
    "        self.is_validating = is_validating\n",
    "        self.is_evaluating = is_evaluating\n",
    "        seed = 386579\n",
    "\n",
    "        #print(f'Data shape: {data_array.shape} | Target shape: {target_array.shape}')\n",
    "\n",
    "        self.data = np.zeros(((data_array.shape[1]//patch_size) * (data_array.shape[2]//patch_size), data_array.shape[0], patch_size, patch_size))\n",
    "\n",
    "        for i in range(0,data_array.shape[1]//patch_size):\n",
    "            for j in range(0,data_array.shape[2]//patch_size):\n",
    "                self.data[data_array.shape[1]//patch_size*i+j,:,:,:] = data_array[:,i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size]\n",
    "\n",
    "        self.label_OHE = np.zeros(((data_array.shape[1]//patch_size) * (data_array.shape[2]//patch_size), target_array_OHE.shape[0] ,patch_size, patch_size), dtype=float)\n",
    "        for k in range(0,data_array.shape[1]//patch_size):\n",
    "            for l in range(0,data_array.shape[2]//patch_size):\n",
    "                self.label_OHE[data_array.shape[1]//patch_size*k+l,:,:,:] = target_array_OHE[:,i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size]\n",
    "\n",
    "        self.label_RAW = np.zeros(((data_array.shape[1]//patch_size) * (data_array.shape[2]//patch_size),data_array.shape[0]+1))\n",
    "        for k in range(0,data_array.shape[1]//patch_size):\n",
    "            for l in range(0,data_array.shape[2]//patch_size):\n",
    "                self.label_RAW[data_array.shape[1]//patch_size*k+l,:] = np.bincount(target_array_RAW[k*patch_size:(k+1)*patch_size, l*patch_size:(l+1)*patch_size].reshape(-1), minlength=7)/(patch_size*patch_size)\n",
    "\n",
    "\n",
    "        if not is_evaluating:\n",
    "            if rotate:\n",
    "                for i in range(2):\n",
    "                    rotated_data = np.rot90(self.data, k=i+1, axes=(-2, -1))\n",
    "                    self.data = np.concatenate((self.data, rotated_data), axis=0)\n",
    "                    rotated_label_OHE = np.rot90(self.label_OHE, k=i+1, axes=(-2, -1))\n",
    "                    rotated_label_RAW = self.label_RAW\n",
    "                    self.label_OHE = np.concatenate((self.label_OHE, rotated_label_OHE), axis=0)\n",
    "                    self.label_RAW = np.concatenate((self.label_RAW, rotated_label_RAW), axis=0)\n",
    "\n",
    "        train_size = int(self.data.shape[0]*train_ratio)\n",
    "        index_array = np.random.RandomState(seed=seed).permutation(self.data.shape[0])\n",
    "        self.train_index = index_array[0:train_size]\n",
    "        self.valid_index = index_array[train_size:index_array.shape[0]]\n",
    "        \n",
    "        self.data = torch.as_tensor(self.data).float()\n",
    "        self.data[:,3:6,:,:] = self.data[:,3:6,:,:]/255\n",
    "        self.data_seg = mirror_extrapolate(self.data).squeeze()[:,0:3,:,:]\n",
    "        self.data_reg = torch.zeros((self.data.shape[0], 100, 6, self.data.shape[-2]//10, self.data.shape[-1]//10))\n",
    "        print(self.data.shape)\n",
    "        for k in tqdm.trange(self.data.shape[0]):\n",
    "            for i in range(self.data.shape[-1]//10):\n",
    "                for j in range(self.data.shape[-2]//10):\n",
    "                    self.data_reg[k,10*i+j,:,:,:] = self.data[k,:,10*j:10*j+10, 10*i:10*i+10]\n",
    "\n",
    "\n",
    "        self.label_OHE = torch.as_tensor(self.label_OHE).float()\n",
    "        self.label_RAW = torch.as_tensor(self.label_RAW).float()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.is_evaluating:\n",
    "            return self.data.shape[0]\n",
    "\n",
    "        if self.is_validating:\n",
    "            return self.valid_index.shape[0]\n",
    "        else:\n",
    "            return self.train_index.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_evaluating:\n",
    "            data_reg = torch.as_tensor(self.data_reg[idx,:,:,:]).float()\n",
    "            data_seg = torch.as_tensor(self.data_seg[idx,:,:,:]).float()\n",
    "            label_OHE = torch.as_tensor(self.label_OHE[idx,:]).float()\n",
    "            label_RAW = torch.as_tensor(self.label_RAW[idx,:]).float()\n",
    "            return data_seg, data_reg, label_OHE, label_RAW\n",
    "        \n",
    "        if self.is_validating:\n",
    "            data_reg = torch.as_tensor(self.data_reg[self.valid_index[idx],:,:,:]).float()\n",
    "            data_seg = torch.as_tensor(self.data_seg[self.valid_index[idx],:,:,:]).float()\n",
    "            label_OHE = torch.as_tensor(self.label_OHE[self.valid_index[idx],:]).float()\n",
    "            label_RAW = torch.as_tensor(self.label_RAW[self.valid_index[idx],:]).float()\n",
    "        else:\n",
    "            data_reg = torch.as_tensor(self.data_reg[self.train_index[idx],:,:,:]).float()\n",
    "            data_seg = torch.as_tensor(self.data_seg[self.train_index[idx],:,:,:]).float()\n",
    "            label_OHE = torch.as_tensor(self.label_OHE[self.train_index[idx],:]).float()\n",
    "            label_RAW = torch.as_tensor(self.label_RAW[self.train_index[idx],:]).float()\n",
    "\n",
    "        return data_seg, data_reg, label_OHE, label_RAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preexisting Data Found. Loading...\n",
      "torch.Size([576, 6, 100, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:01<00:00, 371.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([576, 6, 100, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:01<00:00, 364.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([576, 6, 100, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:02<00:00, 261.23it/s]\n"
     ]
    }
   ],
   "source": [
    "raw_data_array ,raw_target_array, OHE_target_array = prepare_raw_files('N12')\n",
    "batch_size = 4\n",
    "patch_size = 100\n",
    "train_ratio = 0.8\n",
    "rotate_training_data = False\n",
    "Datasets_ver3 = {\n",
    "    'Train' : TrainDataset3(raw_data_array, OHE_target_array, raw_target_array, patch_size = patch_size, rotate = rotate_training_data, train_ratio = train_ratio),\n",
    "    'Validation' : TrainDataset3(raw_data_array, OHE_target_array, raw_target_array, patch_size = patch_size, is_validating = True, rotate = rotate_training_data, train_ratio = train_ratio),\n",
    "    'Prediction' : TrainDataset3(raw_data_array, OHE_target_array, raw_target_array, patch_size = patch_size, is_evaluating = True, train_ratio = train_ratio)\n",
    "}\n",
    "Dataloaders_ver3 = {\n",
    "    'Train' : DataLoader(Datasets_ver3['Train'], batch_size=batch_size),\n",
    "    'Validation' : DataLoader(Datasets_ver3['Validation'], batch_size=batch_size),\n",
    "    'Prediction' : DataLoader(Datasets_ver3['Prediction'], batch_size=2400//patch_size)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Splitted_Regression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Splitted_Regression, self).__init__()\n",
    "        self.regression = UrbanGreenRegression() # 4차원 텐서만 받음.\n",
    "        self.regression.load_state_dict(torch.load('/home/bcyoon/Byeongchan/Data/N12/Model/Segmentation/Regression/2022.7.26/Best_Model_Parameters_of_15:32_patch_10_pointwiseConv.pth'))\n",
    "        self.regression.to('cuda:0')\n",
    "        for param in self.regression.parameters():\n",
    "            param.requires_grad = False\n",
    "        #self.batchnorm = nn.BatchNorm2d(7)\n",
    "    def forward(self, x):\n",
    "        # x : (batch, 100, 6, 10, 10) 데이터\n",
    "        out = torch.zeros(x.shape[0],7,100)\n",
    "        out = out.to('cuda:0')\n",
    "        for i in range(x.shape[0]):\n",
    "            tmp = self.regression(x[i,:,:,:,:])\n",
    "            #print(tmp.shape)\n",
    "            out[i,:,:] = torch.transpose(tmp, 0, 1)\n",
    "        out = out.view(x.shape[0], 7, 10, 10)\n",
    "        #Bilinear Interpolation 추가할 것\n",
    "        out = F.interpolate(out, size=(100,100), mode='nearest')\n",
    "        #out = self.batchnorm(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "spl = Splitted_Regression()\n",
    "inp_seg, inp_reg, _,_ = Dataloaders_ver3['Prediction'].dataset[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 7, 100, 100])\n"
     ]
    }
   ],
   "source": [
    "re = spl(inp_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression 결과 Bilinear Interpolation 함수 추가 -> Nearest Neighborhood로 수정해서 추가완료\n",
    "## Regression 결과 Fully Convolutional Layer에 조합할 연산 추가, 이후 다시 Convolutional Layer 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UrbanGreenSegmentation(pl.LightningModule):\n",
    "    def __init__(self, rotate_training_data : bool = False, train_ratio : float = 0.8, patch_size : int = 100, batch_size : int = 4, region:str = 'N12'):\n",
    "        super(UrbanGreenSegmentation, self).__init__()\n",
    "        raw_data_array, OHE_target_array, raw_target_array = prepare_raw_files(region)\n",
    "        self.batch_size = batch_size\n",
    "        self.Datasets = {\n",
    "            'Train' : TrainDataset2(raw_data_array, OHE_target_array, raw_target_array, patch_size = patch_size, rotate = rotate_training_data, train_ratio = train_ratio),\n",
    "            'Validation' : TrainDataset2(raw_data_array, OHE_target_array, raw_target_array, patch_size = patch_size, is_validating = True, rotate = rotate_training_data, train_ratio = train_ratio),\n",
    "            'Prediction' : TrainDataset2(raw_data_array, OHE_target_array, raw_target_array, patch_size = patch_size, is_evaluating = True, train_ratio = train_ratio)\n",
    "        }\n",
    "\n",
    "        self.Dataloaders = {\n",
    "            'Train' : DataLoader(self.Datasets['Train'], batch_size=batch_size),\n",
    "            'Validation' : DataLoader(self.Datasets['Validation'], batch_size=batch_size),\n",
    "            'Prediction' : DataLoader(self.Datasets['Prediction'], batch_size=batch_size)\n",
    "        }\n",
    "        \n",
    "        \n",
    "\n",
    "        self.unet = UNet()\n",
    "        self.regression = Splitted_Regression()\n",
    "        \n",
    "        self.fc1 = nn.Conv2d(in_channels=32, out_channels=7)\n",
    "        self.bn1 = nn.BatchNorm2d(7)\n",
    "        self.fc2 = nn.Conv2d(in_channels=14, out_channels=7)\n",
    "        self.softmax = nn.Softmax2d()\n",
    "\n",
    "    def forward(self, x_seg, x_reg):\n",
    "        x_reg = self.regression(x_reg)\n",
    "        x_seg = self.unet(x_seg)\n",
    "        x_seg = self.fc1(x_seg)\n",
    "        x_seg = self.bn1(x_seg)\n",
    "        x_seg = torch.cat((x_reg, x_seg), dim=1)\n",
    "        x_seg = self.fc2(x_seg)\n",
    "        x_seg = self.softmax(x_seg)\n",
    "        return x_seg\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_seg, x_reg, y_seg, _ = batch\n",
    "        y_hat = self(x_seg, x_reg)\n",
    "        #손실함수 추가하기\n",
    "        pass\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        pass\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        pass\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        train_optimizer = torch.optim.Adam(self.parameters(), lr=0.02)\n",
    "        train_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(train_optimizer, T_max=10)\n",
    "        return [train_optimizer], [train_scheduler]\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.Datasets['Train'], batch_size = self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.Datasets['Validation'], batch_size = self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.Datasets['Prediction'], batch_size = self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UrbanGreenSegmentation(nn.Module):\n",
    "    def __init__(self, rotate_training_data : bool = False, train_ratio : float = 0.8, patch_size : int = 100, batch_size : int = 4, region:str = 'N12'):\n",
    "        super(UrbanGreenSegmentation, self).__init__()\n",
    "        '''raw_data_array, OHE_target_array, raw_target_array = prepare_raw_files(region)\n",
    "        self.batch_size = batch_size\n",
    "        self.Datasets = {\n",
    "            'Train' : TrainDataset2(raw_data_array, OHE_target_array, raw_target_array, patch_size = patch_size, rotate = rotate_training_data, train_ratio = train_ratio),\n",
    "            'Validation' : TrainDataset2(raw_data_array, OHE_target_array, raw_target_array, patch_size = patch_size, is_validating = True, rotate = rotate_training_data, train_ratio = train_ratio),\n",
    "            'Prediction' : TrainDataset2(raw_data_array, OHE_target_array, raw_target_array, patch_size = patch_size, is_evaluating = True, train_ratio = train_ratio)\n",
    "        }\n",
    "\n",
    "        self.Dataloaders = {\n",
    "            'Train' : DataLoader(self.Datasets['Train'], batch_size=batch_size),\n",
    "            'Validation' : DataLoader(self.Datasets['Validation'], batch_size=batch_size),\n",
    "            'Prediction' : DataLoader(self.Datasets['Prediction'], batch_size=batch_size)\n",
    "        }'''\n",
    "        \n",
    "        \n",
    "\n",
    "        self.unet = UNet()\n",
    "        self.regression = Splitted_Regression()\n",
    "        self.regression.to(device)\n",
    "        \n",
    "        self.fc1 = nn.Conv2d(in_channels=64, out_channels=7, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm2d(7)\n",
    "        self.fc2 = nn.Conv2d(in_channels=14, out_channels=7, kernel_size=1)\n",
    "        self.softmax = nn.Softmax2d()\n",
    "\n",
    "    def forward(self, x_seg, x_reg):\n",
    "        x_reg = self.regression(x_reg)\n",
    "        print(x_reg.type())\n",
    "        x_seg = self.unet(x_seg)\n",
    "        x_seg = self.fc1(x_seg)\n",
    "        x_seg = self.bn1(x_seg)\n",
    "        print(x_seg.type())\n",
    "        x_seg = torch.cat((x_reg, x_seg), dim=1)\n",
    "        x_seg = self.fc2(x_seg)\n",
    "        x_seg = self.softmax(x_seg)\n",
    "        return x_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c, d = Dataloaders_ver3['Train'].dataset[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.to(device)\n",
    "b = b.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.FloatTensor\n",
      "torch.cuda.FloatTensor\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [10, 1, 10, 10]               7\n",
      "       BatchNorm2d-2            [10, 1, 10, 10]               2\n",
      "              ReLU-3            [10, 1, 10, 10]               0\n",
      "            Linear-4                  [10, 256]          25,600\n",
      "       BatchNorm1d-5                  [10, 256]             512\n",
      "              ReLU-6                  [10, 256]               0\n",
      "            Linear-7                  [10, 256]          65,536\n",
      "       BatchNorm1d-8                  [10, 256]             512\n",
      "              ReLU-9                  [10, 256]               0\n",
      "           Linear-10                  [10, 256]          65,536\n",
      "      BatchNorm1d-11                  [10, 256]             512\n",
      "             ReLU-12                  [10, 256]               0\n",
      "           Linear-13                  [10, 256]          65,536\n",
      "      BatchNorm1d-14                  [10, 256]             512\n",
      "             ReLU-15                  [10, 256]               0\n",
      "           Linear-16                   [10, 64]          16,384\n",
      "      BatchNorm1d-17                   [10, 64]             128\n",
      "             ReLU-18                   [10, 64]               0\n",
      "           Linear-19                   [10, 64]           4,096\n",
      "      BatchNorm1d-20                   [10, 64]             128\n",
      "             ReLU-21                   [10, 64]               0\n",
      "           Linear-22                    [10, 7]             448\n",
      "      BatchNorm1d-23                    [10, 7]              14\n",
      "UrbanGreenRegression-24                    [10, 7]               0\n",
      "           Conv2d-25            [10, 1, 10, 10]               7\n",
      "      BatchNorm2d-26            [10, 1, 10, 10]               2\n",
      "             ReLU-27            [10, 1, 10, 10]               0\n",
      "           Linear-28                  [10, 256]          25,600\n",
      "      BatchNorm1d-29                  [10, 256]             512\n",
      "             ReLU-30                  [10, 256]               0\n",
      "           Linear-31                  [10, 256]          65,536\n",
      "      BatchNorm1d-32                  [10, 256]             512\n",
      "             ReLU-33                  [10, 256]               0\n",
      "           Linear-34                  [10, 256]          65,536\n",
      "      BatchNorm1d-35                  [10, 256]             512\n",
      "             ReLU-36                  [10, 256]               0\n",
      "           Linear-37                  [10, 256]          65,536\n",
      "      BatchNorm1d-38                  [10, 256]             512\n",
      "             ReLU-39                  [10, 256]               0\n",
      "           Linear-40                   [10, 64]          16,384\n",
      "      BatchNorm1d-41                   [10, 64]             128\n",
      "             ReLU-42                   [10, 64]               0\n",
      "           Linear-43                   [10, 64]           4,096\n",
      "      BatchNorm1d-44                   [10, 64]             128\n",
      "             ReLU-45                   [10, 64]               0\n",
      "           Linear-46                    [10, 7]             448\n",
      "      BatchNorm1d-47                    [10, 7]              14\n",
      "UrbanGreenRegression-48                    [10, 7]               0\n",
      "Splitted_Regression-49          [10, 7, 100, 100]               0\n",
      "           Conv2d-50          [10, 3, 282, 282]              27\n",
      "      BatchNorm2d-51          [10, 3, 282, 282]               6\n",
      "           Conv2d-52         [10, 64, 282, 282]             192\n",
      "           ConvBN-53         [10, 64, 282, 282]               0\n",
      "             ReLU-54         [10, 64, 282, 282]               0\n",
      "           Conv2d-55         [10, 64, 280, 280]             576\n",
      "      BatchNorm2d-56         [10, 64, 280, 280]             128\n",
      "           Conv2d-57         [10, 64, 280, 280]           4,096\n",
      "           ConvBN-58         [10, 64, 280, 280]               0\n",
      "             ReLU-59         [10, 64, 280, 280]               0\n",
      "         SegBlock-60         [10, 64, 280, 280]               0\n",
      "        MaxPool2d-61         [10, 64, 140, 140]               0\n",
      "           Conv2d-62         [10, 64, 138, 138]             576\n",
      "      BatchNorm2d-63         [10, 64, 138, 138]             128\n",
      "           Conv2d-64        [10, 128, 138, 138]           8,192\n",
      "           ConvBN-65        [10, 128, 138, 138]               0\n",
      "             ReLU-66        [10, 128, 138, 138]               0\n",
      "           Conv2d-67        [10, 128, 136, 136]           1,152\n",
      "      BatchNorm2d-68        [10, 128, 136, 136]             256\n",
      "           Conv2d-69        [10, 128, 136, 136]          16,384\n",
      "           ConvBN-70        [10, 128, 136, 136]               0\n",
      "             ReLU-71        [10, 128, 136, 136]               0\n",
      "         SegBlock-72        [10, 128, 136, 136]               0\n",
      "        MaxPool2d-73          [10, 128, 68, 68]               0\n",
      "           Conv2d-74          [10, 128, 66, 66]           1,152\n",
      "      BatchNorm2d-75          [10, 128, 66, 66]             256\n",
      "           Conv2d-76          [10, 256, 66, 66]          32,768\n",
      "           ConvBN-77          [10, 256, 66, 66]               0\n",
      "             ReLU-78          [10, 256, 66, 66]               0\n",
      "           Conv2d-79          [10, 256, 64, 64]           2,304\n",
      "      BatchNorm2d-80          [10, 256, 64, 64]             512\n",
      "           Conv2d-81          [10, 256, 64, 64]          65,536\n",
      "           ConvBN-82          [10, 256, 64, 64]               0\n",
      "             ReLU-83          [10, 256, 64, 64]               0\n",
      "         SegBlock-84          [10, 256, 64, 64]               0\n",
      "        MaxPool2d-85          [10, 256, 32, 32]               0\n",
      "           Conv2d-86          [10, 256, 30, 30]           2,304\n",
      "      BatchNorm2d-87          [10, 256, 30, 30]             512\n",
      "           Conv2d-88          [10, 512, 30, 30]         131,072\n",
      "           ConvBN-89          [10, 512, 30, 30]               0\n",
      "             ReLU-90          [10, 512, 30, 30]               0\n",
      "           Conv2d-91          [10, 512, 28, 28]           4,608\n",
      "      BatchNorm2d-92          [10, 512, 28, 28]           1,024\n",
      "           Conv2d-93          [10, 512, 28, 28]         262,144\n",
      "           ConvBN-94          [10, 512, 28, 28]               0\n",
      "             ReLU-95          [10, 512, 28, 28]               0\n",
      "         SegBlock-96          [10, 512, 28, 28]               0\n",
      "        MaxPool2d-97          [10, 512, 14, 14]               0\n",
      "           Conv2d-98          [10, 512, 12, 12]           4,608\n",
      "      BatchNorm2d-99          [10, 512, 12, 12]           1,024\n",
      "          Conv2d-100         [10, 1024, 12, 12]         524,288\n",
      "          ConvBN-101         [10, 1024, 12, 12]               0\n",
      "            ReLU-102         [10, 1024, 12, 12]               0\n",
      "          Conv2d-103         [10, 1024, 10, 10]           9,216\n",
      "     BatchNorm2d-104         [10, 1024, 10, 10]           2,048\n",
      "          Conv2d-105         [10, 1024, 10, 10]       1,048,576\n",
      "          ConvBN-106         [10, 1024, 10, 10]               0\n",
      "            ReLU-107         [10, 1024, 10, 10]               0\n",
      "        SegBlock-108         [10, 1024, 10, 10]               0\n",
      " ConvTranspose2d-109          [10, 512, 20, 20]       2,097,664\n",
      "          Conv2d-110         [10, 1024, 18, 18]           9,216\n",
      "     BatchNorm2d-111         [10, 1024, 18, 18]           2,048\n",
      "          Conv2d-112          [10, 512, 18, 18]         524,288\n",
      "          ConvBN-113          [10, 512, 18, 18]               0\n",
      "            ReLU-114          [10, 512, 18, 18]               0\n",
      "          Conv2d-115          [10, 512, 16, 16]           4,608\n",
      "     BatchNorm2d-116          [10, 512, 16, 16]           1,024\n",
      "          Conv2d-117          [10, 512, 16, 16]         262,144\n",
      "          ConvBN-118          [10, 512, 16, 16]               0\n",
      "            ReLU-119          [10, 512, 16, 16]               0\n",
      "        SegBlock-120          [10, 512, 16, 16]               0\n",
      " ConvTranspose2d-121          [10, 256, 32, 32]         524,544\n",
      "          Conv2d-122          [10, 512, 30, 30]           4,608\n",
      "     BatchNorm2d-123          [10, 512, 30, 30]           1,024\n",
      "          Conv2d-124          [10, 256, 30, 30]         131,072\n",
      "          ConvBN-125          [10, 256, 30, 30]               0\n",
      "            ReLU-126          [10, 256, 30, 30]               0\n",
      "          Conv2d-127          [10, 256, 28, 28]           2,304\n",
      "     BatchNorm2d-128          [10, 256, 28, 28]             512\n",
      "          Conv2d-129          [10, 256, 28, 28]          65,536\n",
      "          ConvBN-130          [10, 256, 28, 28]               0\n",
      "            ReLU-131          [10, 256, 28, 28]               0\n",
      "        SegBlock-132          [10, 256, 28, 28]               0\n",
      " ConvTranspose2d-133          [10, 128, 56, 56]         131,200\n",
      "          Conv2d-134          [10, 256, 54, 54]           2,304\n",
      "     BatchNorm2d-135          [10, 256, 54, 54]             512\n",
      "          Conv2d-136          [10, 128, 54, 54]          32,768\n",
      "          ConvBN-137          [10, 128, 54, 54]               0\n",
      "            ReLU-138          [10, 128, 54, 54]               0\n",
      "          Conv2d-139          [10, 128, 52, 52]           1,152\n",
      "     BatchNorm2d-140          [10, 128, 52, 52]             256\n",
      "          Conv2d-141          [10, 128, 52, 52]          16,384\n",
      "          ConvBN-142          [10, 128, 52, 52]               0\n",
      "            ReLU-143          [10, 128, 52, 52]               0\n",
      "        SegBlock-144          [10, 128, 52, 52]               0\n",
      " ConvTranspose2d-145         [10, 64, 104, 104]          32,832\n",
      "          Conv2d-146        [10, 128, 102, 102]           1,152\n",
      "     BatchNorm2d-147        [10, 128, 102, 102]             256\n",
      "          Conv2d-148         [10, 64, 102, 102]           8,192\n",
      "          ConvBN-149         [10, 64, 102, 102]               0\n",
      "            ReLU-150         [10, 64, 102, 102]               0\n",
      "          Conv2d-151         [10, 64, 100, 100]             576\n",
      "     BatchNorm2d-152         [10, 64, 100, 100]             128\n",
      "          Conv2d-153         [10, 64, 100, 100]           4,096\n",
      "          ConvBN-154         [10, 64, 100, 100]               0\n",
      "            ReLU-155         [10, 64, 100, 100]               0\n",
      "        SegBlock-156         [10, 64, 100, 100]               0\n",
      "            UNet-157         [10, 64, 100, 100]               0\n",
      "          Conv2d-158          [10, 7, 100, 100]             455\n",
      "     BatchNorm2d-159          [10, 7, 100, 100]              14\n",
      "          Conv2d-160          [10, 7, 100, 100]             105\n",
      "       Softmax2d-161          [10, 7, 100, 100]               0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bcyoon/anaconda3/envs/tt/lib/python3.7/site-packages/numpy/core/fromnumeric.py:87: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4931/4142697479.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_for_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUrbanGreenSegmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_for_summary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_for_summary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m284\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m284\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tt/lib/python3.7/site-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;31m# assume 4 bytes/number (float on cuda).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0mtotal_input_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m     \u001b[0mtotal_output_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtotal_output\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# x2 for gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mtotal_params_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mprod\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tt/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mprod\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2998\u001b[0m     \"\"\"\n\u001b[1;32m   2999\u001b[0m     return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n\u001b[0;32m-> 3000\u001b[0;31m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[1;32m   3001\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tt/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'tuple'"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "model_for_summary = UrbanGreenSegmentation()\n",
    "model_for_summary.to(device)\n",
    "summary(model_for_summary, [(3,284,284),(100,6,10,10)], batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.FloatTensor\n",
      "torch.cuda.FloatTensor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.1420, 0.1660, 0.1452,  ..., 0.1174, 0.1625, 0.1482],\n",
       "          [0.1239, 0.1116, 0.0998,  ..., 0.1333, 0.1255, 0.1157],\n",
       "          [0.1752, 0.1546, 0.1158,  ..., 0.1176, 0.1067, 0.1264],\n",
       "          ...,\n",
       "          [0.1309, 0.1517, 0.1281,  ..., 0.0988, 0.1398, 0.0801],\n",
       "          [0.1450, 0.1229, 0.1254,  ..., 0.1157, 0.0833, 0.0706],\n",
       "          [0.1264, 0.1125, 0.1267,  ..., 0.1406, 0.1072, 0.1006]],\n",
       "\n",
       "         [[0.1605, 0.1234, 0.1252,  ..., 0.1750, 0.1209, 0.1418],\n",
       "          [0.0945, 0.1206, 0.0627,  ..., 0.1412, 0.1293, 0.1809],\n",
       "          [0.1225, 0.1183, 0.1144,  ..., 0.1452, 0.1472, 0.1592],\n",
       "          ...,\n",
       "          [0.1315, 0.1069, 0.1518,  ..., 0.1138, 0.0860, 0.1184],\n",
       "          [0.1343, 0.1277, 0.1081,  ..., 0.0797, 0.0932, 0.1229],\n",
       "          [0.1243, 0.1622, 0.1132,  ..., 0.0795, 0.1273, 0.0819]],\n",
       "\n",
       "         [[0.0764, 0.1231, 0.1862,  ..., 0.1463, 0.1234, 0.1330],\n",
       "          [0.1508, 0.1051, 0.1295,  ..., 0.1199, 0.1230, 0.1386],\n",
       "          [0.1211, 0.1799, 0.2477,  ..., 0.1557, 0.0950, 0.1372],\n",
       "          ...,\n",
       "          [0.1438, 0.0654, 0.1218,  ..., 0.0846, 0.1044, 0.0745],\n",
       "          [0.1555, 0.1164, 0.1035,  ..., 0.1726, 0.0902, 0.0682],\n",
       "          [0.1218, 0.1051, 0.1316,  ..., 0.1593, 0.1402, 0.1210]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0901, 0.1362, 0.1352,  ..., 0.0924, 0.1010, 0.1004],\n",
       "          [0.1675, 0.1213, 0.1851,  ..., 0.0881, 0.0992, 0.0847],\n",
       "          [0.1159, 0.1227, 0.1242,  ..., 0.1074, 0.0863, 0.0882],\n",
       "          ...,\n",
       "          [0.1239, 0.1067, 0.1093,  ..., 0.0918, 0.1438, 0.1149],\n",
       "          [0.1199, 0.1354, 0.1447,  ..., 0.1817, 0.1692, 0.1066],\n",
       "          [0.1375, 0.1004, 0.1438,  ..., 0.1618, 0.1151, 0.1433]],\n",
       "\n",
       "         [[0.2348, 0.1842, 0.1503,  ..., 0.1820, 0.1702, 0.1767],\n",
       "          [0.1767, 0.2183, 0.1626,  ..., 0.1858, 0.1882, 0.1897],\n",
       "          [0.1737, 0.1643, 0.1350,  ..., 0.1828, 0.2098, 0.1813],\n",
       "          ...,\n",
       "          [0.1784, 0.2152, 0.1974,  ..., 0.2337, 0.2091, 0.2737],\n",
       "          [0.1640, 0.2094, 0.2004,  ..., 0.1647, 0.2315, 0.2789],\n",
       "          [0.1872, 0.2177, 0.1850,  ..., 0.1412, 0.1895, 0.1857]],\n",
       "\n",
       "         [[0.1557, 0.1438, 0.1538,  ..., 0.1178, 0.1308, 0.1161],\n",
       "          [0.2103, 0.2122, 0.3057,  ..., 0.1379, 0.1409, 0.1150],\n",
       "          [0.1646, 0.1624, 0.1429,  ..., 0.1368, 0.1397, 0.1143],\n",
       "          ...,\n",
       "          [0.1344, 0.1845, 0.1225,  ..., 0.1942, 0.2028, 0.2057],\n",
       "          [0.1228, 0.1530, 0.1828,  ..., 0.1715, 0.2346, 0.2456],\n",
       "          [0.1690, 0.1401, 0.1646,  ..., 0.1776, 0.1726, 0.2490]]],\n",
       "\n",
       "\n",
       "        [[[0.1742, 0.1349, 0.1465,  ..., 0.1234, 0.1587, 0.1048],\n",
       "          [0.1580, 0.1131, 0.1281,  ..., 0.1937, 0.1296, 0.0529],\n",
       "          [0.1304, 0.2725, 0.1425,  ..., 0.1502, 0.2937, 0.1148],\n",
       "          ...,\n",
       "          [0.0604, 0.2032, 0.5288,  ..., 0.0715, 0.1139, 0.1850],\n",
       "          [0.2926, 0.0115, 0.3087,  ..., 0.1299, 0.1299, 0.1059],\n",
       "          [0.0653, 0.2463, 0.1152,  ..., 0.1052, 0.1780, 0.1453]],\n",
       "\n",
       "         [[0.0779, 0.1656, 0.1325,  ..., 0.1434, 0.0669, 0.1059],\n",
       "          [0.0937, 0.1087, 0.1447,  ..., 0.1255, 0.1101, 0.1931],\n",
       "          [0.1112, 0.0604, 0.1110,  ..., 0.1381, 0.0295, 0.0783],\n",
       "          ...,\n",
       "          [0.0644, 0.0277, 0.0017,  ..., 0.1426, 0.1552, 0.0915],\n",
       "          [0.0011, 0.1191, 0.0401,  ..., 0.1343, 0.1155, 0.1582],\n",
       "          [0.0140, 0.0077, 0.0356,  ..., 0.1603, 0.0858, 0.1203]],\n",
       "\n",
       "         [[0.2189, 0.2664, 0.1864,  ..., 0.0983, 0.1741, 0.1665],\n",
       "          [0.0731, 0.2572, 0.1406,  ..., 0.1287, 0.3788, 0.1036],\n",
       "          [0.0801, 0.2054, 0.1013,  ..., 0.0931, 0.1590, 0.1554],\n",
       "          ...,\n",
       "          [0.1016, 0.1424, 0.2860,  ..., 0.0842, 0.1585, 0.1155],\n",
       "          [0.0471, 0.5427, 0.2152,  ..., 0.0927, 0.1529, 0.1384],\n",
       "          [0.0753, 0.4218, 0.0738,  ..., 0.0768, 0.1798, 0.1116]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.1179, 0.0880, 0.1010,  ..., 0.1507, 0.2332, 0.1733],\n",
       "          [0.1278, 0.1600, 0.0874,  ..., 0.1542, 0.1243, 0.0921],\n",
       "          [0.1180, 0.1098, 0.0845,  ..., 0.1341, 0.2101, 0.1876],\n",
       "          ...,\n",
       "          [0.1352, 0.0947, 0.0616,  ..., 0.1133, 0.1446, 0.1089],\n",
       "          [0.3178, 0.0203, 0.0528,  ..., 0.1407, 0.1535, 0.1237],\n",
       "          [0.3259, 0.2014, 0.1706,  ..., 0.1118, 0.1556, 0.1359]],\n",
       "\n",
       "         [[0.1147, 0.1227, 0.1324,  ..., 0.1956, 0.1108, 0.1698],\n",
       "          [0.2313, 0.1273, 0.1823,  ..., 0.1427, 0.0750, 0.2298],\n",
       "          [0.2073, 0.0919, 0.1764,  ..., 0.1864, 0.0619, 0.1450],\n",
       "          ...,\n",
       "          [0.1520, 0.1332, 0.0080,  ..., 0.2481, 0.1729, 0.1540],\n",
       "          [0.0277, 0.0999, 0.0502,  ..., 0.2118, 0.1873, 0.2013],\n",
       "          [0.1158, 0.0220, 0.1614,  ..., 0.2239, 0.1427, 0.1773]],\n",
       "\n",
       "         [[0.1692, 0.0859, 0.1165,  ..., 0.1398, 0.1730, 0.1609],\n",
       "          [0.1647, 0.1418, 0.1247,  ..., 0.1354, 0.0876, 0.1641],\n",
       "          [0.1929, 0.1121, 0.1507,  ..., 0.1438, 0.1645, 0.2268],\n",
       "          ...,\n",
       "          [0.4255, 0.2065, 0.0649,  ..., 0.2196, 0.1313, 0.2139],\n",
       "          [0.3029, 0.1349, 0.0892,  ..., 0.1516, 0.1599, 0.1534],\n",
       "          [0.3826, 0.0662, 0.3135,  ..., 0.1736, 0.1536, 0.1731]]]],\n",
       "       device='cuda:0', grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_for_summary(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('tt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bef1a0741f78125b97ca6015f4b21165d553afbb2c419d3dfb1350931d81372"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

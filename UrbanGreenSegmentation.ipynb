{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from typing import Type\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "from pkgs import dataprepare\n",
    "from pkgs import legacytraining\n",
    "from pkgs import neuralnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UrbanGreenSegmentation(pl.LightningModule):\n",
    "    def __init__(self, rotate_training_data : bool = False, train_ratio : float = 0.8, patch_size : int = 100, batch_size : int = 4, region:str = 'N12'):\n",
    "        super(UrbanGreenSegmentation, self).__init__()\n",
    "        raw_data_array, OHE_target_array, raw_target_array = dataprepare.prepare_raw_files(region)\n",
    "        self.batch_size = batch_size\n",
    "        self.Datasets = {\n",
    "            'Train' : dataprepare.TrainDataset3(raw_data_array, OHE_target_array, raw_target_array, patch_size = patch_size, rotate = rotate_training_data, train_ratio = train_ratio),\n",
    "            'Validation' : dataprepare.TrainDataset3(raw_data_array, OHE_target_array, raw_target_array, patch_size = patch_size, is_validating = True, rotate = rotate_training_data, train_ratio = train_ratio),\n",
    "            'Prediction' : dataprepare.TrainDataset3(raw_data_array, OHE_target_array, raw_target_array, patch_size = patch_size, is_evaluating = True, train_ratio = train_ratio)\n",
    "        }\n",
    "\n",
    "        self.Dataloaders = {\n",
    "            'Train' : DataLoader(self.Datasets['Train'], batch_size=batch_size),\n",
    "            'Validation' : DataLoader(self.Datasets['Validation'], batch_size=batch_size),\n",
    "            'Prediction' : DataLoader(self.Datasets['Prediction'], batch_size=batch_size)\n",
    "        }\n",
    "        \n",
    "        # 3개 배치 사용시 메모리 5기가\n",
    "        # 2개 배치 사용시 메모리 3.8기가\n",
    "\n",
    "        self.unet = neuralnet.UNet()\n",
    "        self.regression = neuralnet.Splitted_Regression()\n",
    "        \n",
    "        self.fc1 = nn.Conv2d(in_channels=64, out_channels=7)\n",
    "        self.bn1 = nn.BatchNorm2d(7)\n",
    "        self.bn2 = nn.BatchNorm2d(14)\n",
    "        self.fc2 = nn.Conv2d(in_channels=14, out_channels=7)\n",
    "        self.softmax = nn.Softmax2d()\n",
    "\n",
    "    def forward(self, x_seg, x_reg):\n",
    "        x_reg = self.regression(x_reg)\n",
    "        x_seg = self.unet(x_seg)\n",
    "        x_seg = self.fc1(x_seg)\n",
    "        x_seg = self.bn1(x_seg)\n",
    "        x_seg = torch.cat((x_reg, x_seg), dim=1)\n",
    "        x_seg = self.bn2(x_seg)\n",
    "        x_seg = self.fc2(x_seg)\n",
    "        x_seg = self.softmax(x_seg)\n",
    "        return x_seg\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_seg, x_reg, y_seg, _ = batch\n",
    "        y_hat = self(x_seg, x_reg)\n",
    "        return {'loss' : F.cross_entropy(y_hat, y_seg)}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x_seg, x_reg, y_seg, _ = batch\n",
    "        y_hat = self(x_seg, x_reg)\n",
    "        return {\n",
    "            'valid_loss' : F.cross_entropy(y_hat, y_seg),\n",
    "            'y_hat' : y_hat.detach(),\n",
    "            'y' : y_seg.detach()\n",
    "        }\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        pass\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        train_optimizer = torch.optim.Adam(self.parameters(), lr=0.02)\n",
    "        train_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(train_optimizer, T_max=10)\n",
    "        return [train_optimizer], [train_scheduler]\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.Datasets['Train'], batch_size = self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.Datasets['Validation'], batch_size = self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.Datasets['Prediction'], batch_size = self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UrbanGreenSegmentation(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UrbanGreenSegmentation, self).__init__()\n",
    "        \n",
    "        # 3개 배치 사용시 메모리 5기가\n",
    "        # 2개 배치 사용시 메모리 3.8기가\n",
    "\n",
    "        self.unet = neuralnet.UNet()\n",
    "        self.regression = neuralnet.Splitted_Regression()\n",
    "        \n",
    "        self.fc1 = nn.Conv2d(in_channels=64, out_channels=7, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm2d(7)\n",
    "        self.bn2 = nn.BatchNorm2d(14)\n",
    "        self.fc2 = nn.Conv2d(in_channels=14, out_channels=7, kernel_size=1)\n",
    "        self.softmax = nn.Softmax2d()\n",
    "\n",
    "    def forward(self, x_seg, x_reg):\n",
    "        x_reg = self.regression(x_reg)\n",
    "        x_seg = self.unet(x_seg)\n",
    "        x_seg = self.fc1(x_seg)\n",
    "        x_seg = self.bn1(x_seg)\n",
    "        x_seg = torch.cat((x_reg, x_seg), dim=1)\n",
    "        x_seg = self.bn2(x_seg)\n",
    "        x_seg = self.fc2(x_seg)\n",
    "        x_seg = self.softmax(x_seg)\n",
    "        return x_seg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # --- GPU selection --- #\n",
    "    gpus = 7 # slot number (e.g., 3), no gpu use -> write just ' '\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpus)\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    raw_data_array ,raw_target_array, OHE_target_array = dataprepare.prepare_raw_files('N12')\n",
    "    batch_size = 2\n",
    "    patch_size = 100\n",
    "    train_ratio = 0.8\n",
    "    rotate_training_data = False\n",
    "    Datasets_ver3 = {\n",
    "        'Train' : dataprepare.TrainDataset3(raw_data_array, OHE_target_array, raw_target_array, patch_size = patch_size, rotate = rotate_training_data, train_ratio = train_ratio),\n",
    "        'Validation' : dataprepare.TrainDataset3(raw_data_array, OHE_target_array, raw_target_array, patch_size = patch_size, is_validating = True, rotate = rotate_training_data, train_ratio = train_ratio),\n",
    "        'Prediction' : dataprepare.TrainDataset3(raw_data_array, OHE_target_array, raw_target_array, patch_size = patch_size, is_evaluating = True, train_ratio = train_ratio)\n",
    "    }\n",
    "    Dataloaders_ver3 = {\n",
    "        'Train' : DataLoader(Datasets_ver3['Train'], batch_size=batch_size),\n",
    "        'Validation' : DataLoader(Datasets_ver3['Validation'], batch_size=batch_size),\n",
    "        'Prediction' : DataLoader(Datasets_ver3['Prediction'], batch_size=2400//patch_size)\n",
    "    }\n",
    "    model = UrbanGreenSegmentation()\n",
    "    criterion3 = nn.MSELoss()\n",
    "    optimizer3 = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    scheduler3 = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer3, 'min', patience=5, factor=0.75)\n",
    "\n",
    "    best_model_path = legacytraining.train_model(model, dataloaders=Dataloaders_ver3, criterion=criterion3, optimizer=optimizer3, num_epochs=100, scheduler=scheduler3, path='../Data/N12/Model/Segmentation/', description='functionality_test', device=device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('tt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bef1a0741f78125b97ca6015f4b21165d553afbb2c419d3dfb1350931d81372"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from typing import Type\n",
    "from torch import nn\n",
    "from torch.optim import optimizer\n",
    "import rasterio\n",
    "import zipfile\n",
    "from matplotlib import pyplot as plt\n",
    "import datetime\n",
    "from torchvision import transforms as transforms\n",
    "import shutil\n",
    "import torchmetrics\n",
    "import os\n",
    "#import pytorch_lightning as pl\n",
    "\n",
    "# --- GPU selection --- #\n",
    "gpus = 1 # slot number (e.g., 3), no gpu use -> write just ' '\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpus)\n",
    "#os.environ[\"TORCH_CUDA_ARCH_LIST\"]=\"3.5\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax(array : Type[np.ndarray], dim = 0):\n",
    "    min = np.min(array, axis=dim)\n",
    "    max = np.max(array, axis=dim)\n",
    "    array = (array-min)/(max-min)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar_image = rasterio.open('../Data/N12/N12_lidar.tif').read()\n",
    "lidar_array = np.array(lidar_image)\n",
    "lidar_array = minmax(lidar_array, dim=(0,1))\n",
    "\n",
    "lidar_1n_image = rasterio.open('../Data/N12/N12_lidar_1n.tif').read()\n",
    "lidar_1n_array = np.array(lidar_1n_image)\n",
    "lidar_1n_array = minmax(lidar_1n_array, dim=(0,1))\n",
    "\n",
    "lidar_nt_image = rasterio.open('../Data/N12/N12_lidar_nt.tif').read()\n",
    "lidar_nt_array = np.array(lidar_nt_image)\n",
    "lidar_nt_array = minmax(lidar_nt_array, dim=(0,1))\n",
    "\n",
    "RGB2020_image = rasterio.open('../Data/N12/N12_RGB2020.tif').read()\n",
    "RGB2020_array = np.array(RGB2020_image)\n",
    "train_array = np.stack([lidar_array, lidar_1n_array, lidar_nt_array]).squeeze()\n",
    "train_array = np.concatenate((train_array,RGB2020_array))\n",
    "target_image = rasterio.open('../Data/N12/N12_newlc.tif').read()\n",
    "target_array = np.array(target_image, dtype=int).squeeze()\n",
    "\n",
    "target_array = np.where(target_array == 1, 0, target_array)\n",
    "target_array = np.where(target_array == 2, 1, target_array)\n",
    "target_array = np.where(target_array == 7, 2, target_array)\n",
    "target_array = np.where(target_array == 8, 3, target_array)\n",
    "target_array = np.where(target_array == 9, 4, target_array)\n",
    "target_array = np.where(target_array == 10, 5, target_array)\n",
    "target_array = np.where(target_array == 11, 6, target_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset2(Dataset):\n",
    "    def __init__(self, data_array : Type[np.ndarray], target_array : Type[np.ndarray], patch_size : int, is_evaluating : bool = False, is_validating : bool = False, rotate : bool = False, train_ratio : float = 0.8):\n",
    "        self.is_validating = is_validating\n",
    "        self.is_evaluating = is_evaluating\n",
    "        seed = 386579\n",
    "\n",
    "        self.data = np.zeros(((data_array.shape[1]//patch_size) * (data_array.shape[2]//patch_size), data_array.shape[0], patch_size, patch_size))\n",
    "\n",
    "        for i in range(0,data_array.shape[1]//patch_size):\n",
    "            for j in range(0,data_array.shape[2]//patch_size):\n",
    "                self.data[data_array.shape[1]//patch_size*i+j,:,:,:] = data_array[:,i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size]\n",
    "\n",
    "        self.label = np.zeros(((data_array.shape[1]//patch_size) * (data_array.shape[2]//patch_size),data_array.shape[0]+1))\n",
    "\n",
    "        for k in range(0,data_array.shape[1]//patch_size):\n",
    "            for l in range(0,data_array.shape[2]//patch_size):\n",
    "                self.label[data_array.shape[1]//patch_size*k+l,:] = np.bincount(target_array[k*patch_size:(k+1)*patch_size, l*patch_size:(l+1)*patch_size].reshape(-1), minlength=7)/(patch_size*patch_size)\n",
    "\n",
    "        if not is_evaluating:\n",
    "            if rotate:\n",
    "                for i in range(2):\n",
    "                    rotated_data = np.rot90(self.data, k=i+1, axes=(-2, -1))\n",
    "                    self.data = np.concatenate((self.data, rotated_data), axis=0)\n",
    "                    rotated_data = self.label\n",
    "                    self.label = np.concatenate((self.label, rotated_data), axis=0)\n",
    "                    \n",
    "                        \n",
    "                #self.data =np.append(self.data, np.zeros(((1, data_array.shape[0], patch_size, patch_size))), axis = 0)\n",
    "                #self.data = np.concatenate(self.data, np.zeros(((1, data_array.shape[0], patch_size, patch_size))))\n",
    "\n",
    "        train_size = int(self.data.shape[0]*train_ratio)\n",
    "        index_array = np.random.RandomState(seed=seed).permutation(self.data.shape[0])\n",
    "        self.train_index = index_array[0:train_size]\n",
    "        self.valid_index = index_array[train_size:index_array.shape[0]]\n",
    "        \n",
    "        self.data = torch.as_tensor(self.data).float()\n",
    "        self.label = torch.as_tensor(self.label).float()\n",
    "\n",
    "        self.data[:,3:6,:,:] = self.data[:,3:6,:,:]/255\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.is_evaluating:\n",
    "            return self.data.shape[0]\n",
    "\n",
    "        if self.is_validating:\n",
    "            return self.valid_index.shape[0]\n",
    "        else:\n",
    "            return self.train_index.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_evaluating:\n",
    "            sample = torch.as_tensor(self.data[idx,:,:,:]).float()\n",
    "            label = torch.as_tensor(self.label[idx,:]).float()\n",
    "            return sample, label\n",
    "        \n",
    "        if self.is_validating:\n",
    "            sample = torch.as_tensor(self.data[self.valid_index[idx],:,:,:]).float()\n",
    "            label = torch.as_tensor(self.label[self.valid_index[idx],:]).float()\n",
    "        else:\n",
    "            sample = torch.as_tensor(self.data[self.train_index[idx],:,:,:]).float()\n",
    "            label = torch.as_tensor(self.label[self.train_index[idx],:]).float()\n",
    "\n",
    "        return sample, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 60\n",
    "N12_Dataset_training = TrainDataset2(data_array=train_array, target_array=target_array, patch_size=40, is_evaluating=False, is_validating=False, rotate=True)\n",
    "N12_Dataset_validating = TrainDataset2(data_array=train_array, target_array=target_array, patch_size=40, is_evaluating=False, is_validating=True, rotate=True)\n",
    "N12_Dataset_prediction = TrainDataset2(data_array=train_array, target_array=target_array, patch_size=40, is_evaluating=True)\n",
    "\n",
    "N12_Dataloader_training = DataLoader(N12_Dataset_training, batch_size=batch_size)\n",
    "N12_Dataloader_validating = DataLoader(N12_Dataset_validating, batch_size=batch_size)\n",
    "N12_Dataloader_prediction = DataLoader(N12_Dataset_prediction, batch_size=batch_size)\n",
    "\n",
    "N12_Dataloaders = {\n",
    "    'Training' : N12_Dataloader_training,\n",
    "    'Validating' : N12_Dataloader_validating,\n",
    "    'Prediction' : N12_Dataloader_prediction\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37665/1705254718.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mUrbanGreenNetwork3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLightningModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUrbanGreenNetwork3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         self.conv_block_1 = nn.Sequential(\n\u001b[1;32m      5\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pl' is not defined"
     ]
    }
   ],
   "source": [
    "class UrbanGreenNetwork3(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(UrbanGreenNetwork3, self).__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=3),\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #nn.Dropout2d(p = 0.2),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "            nn.Conv2d(in_channels=64, out_channels=32, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #nn.Dropout2d(p=0.2),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        self.conv_block_3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3),\n",
    "            #nn.Dropout2d(p=0.2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.fc_block = nn.Sequential(\n",
    "            nn.Linear(in_features=256, out_features=64),\n",
    "            nn.Linear(in_features=64, out_features=7)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv_block_1(x)\n",
    "        x = self.conv_block_2(x)\n",
    "        x = self.conv_block_3(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc_block(x)\n",
    "        return torch.softmax(x, dim=-1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        sample, label = batch\n",
    "        output = self(sample)\n",
    "        loss = torch.nn.functional.mse_loss(output, label)\n",
    "        return {'loss':loss}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=0.01, momentum=0.9)\n",
    "        return optimizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_array = np.load('../Data/N12/np/train_array.npy')\n",
    "        target_array = np.load('../Data/N12/np/target_array_OHE.npy')\n",
    "        Dataset_training = TrainDataset2(data_array=train_array, target_array=target_array, patch_size=40, is_evaluating=False, is_validating=False, rotate=False)\n",
    "        return DataLoader(Dataset_training, batch)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UrbanGreenNetwork2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UrbanGreenNetwork2, self).__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=3),\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p = 0.2),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "            nn.Conv2d(in_channels=64, out_channels=32, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.2),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        self.conv_block_3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3),\n",
    "            nn.Dropout2d(p=0.2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.fc_block = nn.Sequential(\n",
    "            nn.Linear(in_features=256, out_features=64),\n",
    "            nn.Linear(in_features=64, out_features=7)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv_block_1(x)\n",
    "        x = self.conv_block_2(x)\n",
    "        x = self.conv_block_3(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc_block(x)\n",
    "        return torch.softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UrbanGreenNetwork_FC_Reinforced(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UrbanGreenNetwork_FC_Reinforced, self).__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=6, out_channels=32, kernel_size=3),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p = 0.2),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3),\n",
    "            nn.Conv2d(in_channels=64, out_channels=32, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.2),\n",
    "            nn.MaxPool2d(kernel_size=3)\n",
    "        )\n",
    "\n",
    "        self.fc_block = nn.Sequential(\n",
    "            nn.Linear(in_features=512, out_features=256),\n",
    "            nn.Linear(in_features=256, out_features=256),\n",
    "            nn.Linear(in_features=256, out_features=64),\n",
    "            nn.Linear(in_features=64, out_features=7)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv_block_1(x)\n",
    "        x = self.conv_block_2(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc_block(x)\n",
    "        return torch.softmax(x, dim=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('cuda_enabled')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "343b36fa7dbbd4503f9612e52317d5b97216b427b326dcc37fb58c991bc15ddc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import Type\n",
    "from torch import nn\n",
    "from torch.optim import optimizer\n",
    "import rasterio\n",
    "import zipfile\n",
    "from matplotlib import pyplot as plt\n",
    "import datetime\n",
    "from torchvision import transforms as transforms\n",
    "import shutil\n",
    "import torchmetrics\n",
    "import os\n",
    "import pytorch_lightning as pl\n",
    "import sklearn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# --- GPU selection --- #\n",
    "gpus = 7 # slot number (e.g., 3), no gpu use -> write just ' '\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpus)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax(array : Type[np.ndarray], dim = 0):\n",
    "    min = np.min(array, axis=dim)\n",
    "    max = np.max(array, axis=dim)\n",
    "    array = (array-min)/(max-min)\n",
    "    return array\n",
    "\n",
    "def log_minmax(array : Type[np.ndarray], dim = 0):\n",
    "    min = np.min(array, axis=dim)\n",
    "    array = array - min + 1\n",
    "    array = np.log(array)\n",
    "    max = np.max(array, axis=dim)\n",
    "    array = (array)/(max)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result(model: Type[nn.Module], dataloader : Type[DataLoader], path:str, description:str = '', reference_data:str = '', patch_size:int = 60, now = datetime.datetime.now()):\n",
    "    best_model = model\n",
    "    os.makedirs(os.path.join(path,f'{now.year}.{now.month}.{now.day}/', f'{description}/','tmp/'), exist_ok=True)\n",
    "    zipped_results = zipfile.ZipFile(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','RESULT_{0:0=2d}:{1:0=2d}'.format(now.hour, now.minute)+f'_{description}.zip'), 'w')\n",
    "    prediction = np.zeros((60,60,7))\n",
    "    for i, (data, index) in enumerate(dataloader):\n",
    "        prediction[i, :, :] = best_model(data).detach().numpy()\n",
    "    prediction_expanded = np.zeros((7,2400,2400))\n",
    "    for i in range(60):\n",
    "        for j in range(60):\n",
    "            for k in range(7):\n",
    "                prediction_expanded[k,i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size] = prediction[i,j,k]\n",
    "\n",
    "    reference_image = rasterio.open(reference_data)\n",
    "    layer_index = [1,2,7,8,9,10,11]\n",
    "\n",
    "    for i in range(prediction_expanded.shape[0]):\n",
    "        print('a') \n",
    "        processed_tiff = rasterio.open(\n",
    "            os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/', 'tmp/', f'Result_{layer_index[i]}_{description}.tif'),\n",
    "            'w',\n",
    "            driver='GTiff',\n",
    "            height=prediction_expanded.shape[1],\n",
    "            width=prediction_expanded.shape[2],\n",
    "            count=1,\n",
    "            dtype=prediction_expanded.dtype,\n",
    "            crs=reference_image.crs,\n",
    "            transform=reference_image.transform,\n",
    "        )\n",
    "        print('b')\n",
    "        processed_tiff.write(prediction_expanded[i,:,:],1)\n",
    "        processed_tiff.close()\n",
    "        print('c')\n",
    "        zipped_results.write(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/', 'tmp/', f'Result_{layer_index[i]}_{description}.tif'), f'Result_{layer_index[i]}_{description}.tif')\n",
    "\n",
    "    zipped_results.close()\n",
    "    return os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','RESULT_{0:0=2d}:{1:0=2d}'.format(now.hour, now.minute)+f'_{description}.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, scheduler, device, num_epochs=13, train_rate: float = 0.8, batch_size: int = 60, path:str = '../Data/N12/Model/', description:str = 'no_description', reference_data:str = ''): \n",
    "    train_loss_history = []\n",
    "    valid_loss_history = []\n",
    "\n",
    "    patch_size = dataloaders['Train'].dataset.data.shape[-1]\n",
    "    training_patches = len(dataloaders['Train'].dataset)\n",
    "    validating_patches = len(dataloaders['Validation'].dataset)\n",
    "    print(f'Training Patches : {training_patches}\\nValidating Patches : {validating_patches}')\n",
    "\n",
    "    best_model_epoch = 0\n",
    "    least_valid_loss = 100\n",
    "    now = datetime.datetime.now()\n",
    "    os.makedirs(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/', 'tmp/'), exist_ok=True)\n",
    "    zipped_model = zipfile.ZipFile(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/', '{0:0=2d}:{1:0=2d}'.format(now.hour, now.minute)+f'_{description}'+'.zip'), 'w')\n",
    "    \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        train_running_loss = 0.0\n",
    "        valid_running_loss = 0.0\n",
    "\n",
    "        for state in ['Train', 'Validation']:\n",
    "            for i, (inputs, labels) in enumerate(dataloaders[state]):\n",
    "                \n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                model.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                if state == 'Train':\n",
    "                    model.train()\n",
    "                    train_loss = criterion(outputs, labels)\n",
    "                    train_loss.backward()\n",
    "                    train_running_loss += train_loss.item() * inputs.size(0)\n",
    "                \n",
    "                if state == 'Validation':\n",
    "                    model.eval()\n",
    "                    valid_loss = criterion(outputs, labels)\n",
    "                    valid_running_loss += valid_loss.item() * inputs.size(0)\n",
    "\n",
    "                optimizer.step()\n",
    "                #valid_running_similarity += metric(outputs, labels)\n",
    "                #print('validating')\n",
    "                \n",
    "                #print(f'{i}th batch')\n",
    "            \n",
    "\n",
    "\n",
    "        \n",
    "        #print(f'Memory after a training : {torch.cuda.memory_allocated()/1024/1024}')\n",
    "\n",
    "        epoch_train_loss = train_running_loss / training_patches\n",
    "        epoch_valid_loss = valid_running_loss / validating_patches\n",
    "        scheduler.step(epoch_valid_loss)\n",
    "\n",
    "        print(f'Valid loss: {epoch_valid_loss} | Train loss: {epoch_train_loss}')\n",
    "\n",
    "\n",
    "        if epoch_valid_loss < least_valid_loss:\n",
    "            least_valid_loss = epoch_valid_loss\n",
    "            best_model_epoch = epoch\n",
    "\n",
    "        train_loss_history.append(epoch_train_loss)      \n",
    "        valid_loss_history.append(epoch_valid_loss)\n",
    "\n",
    "        torch.save(model.state_dict(), os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','tmp/', '{0:0=2d}.pth'.format(epoch)))\n",
    "        zipped_model.write(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','tmp/', '{0:0=2d}.pth'.format(epoch)))\n",
    "\n",
    "    plt.figure(figsize=(20,8))\n",
    "    plt.plot(train_loss_history, 'r-')\n",
    "    plt.plot(valid_loss_history, 'bo')\n",
    "    plt.savefig(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','tmp/', 'Tendency.png'), dpi=300)\n",
    "    zipped_model.write(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','tmp/', 'Tendency.png'))\n",
    "    zipped_model.writestr('README.txt', f'{description}\\nThe best Model : #{best_model_epoch}th model with loss {least_valid_loss}\\nOptimizer : {optimizer}\\nLoss function : {criterion}\\nBatch size : {batch_size}\\nScheduler : {scheduler}\\nPatch size : {patch_size}\\nTotal epochs : {num_epochs}\\nModel information :\\n{model.modules}')\n",
    "    \n",
    "    print('Best loss: {:4f}, in Epoch #{:0=3d}'.format(least_valid_loss, best_model_epoch))    \n",
    "    zipped_model.close()\n",
    "    shutil.copy(src=os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/', 'tmp/', '{0:0=2d}.pth'.format(epoch)), dst=os.path.join(path,f'{now.year}.{now.month}.{now.day}/', 'Best_Model_Parameters_of_{0:0=2d}:{1:0=2d}'.format(now.hour, now.minute)+f'_{description}'+'.pth'))\n",
    "    print('Model information is saved in '+os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/', '{0:0=2d}:{1:0=2d}'.format(now.hour, now.minute)+f'_{description}'+'.zip'))\n",
    "\n",
    "    model.load_state_dict(torch.load(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','tmp/', '{0:0=2d}.pth'.format(best_model_epoch))))\n",
    "    result_path = save_result(model = model.to('cpu'), dataloader=dataloaders['Prediction'], path=path, description=description, reference_data=reference_data, patch_size=patch_size, now=now)\n",
    "    print('Model result is saved in '+ result_path)\n",
    "    \n",
    "    shutil.rmtree(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','tmp/'))\n",
    "    best_model_path = os.path.join(path,f'{now.year}.{now.month}.{now.day}/', 'Best_Model_Parameters_of_{0:0=2d}:{1:0=2d}'.format(now.hour, now.minute)+f'_{description}'+'.pth')\n",
    "    return best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_raw_files(one_hot_encode:bool = True):\n",
    "    '''if os.path.exists('../Data/N12/np/train_array.npy') and os.path.exists('../Data/N12/np/target_array_OHE.npy'):\n",
    "        train_array = np.load('../Data/N12/np/train_array.npy')\n",
    "        target_array = np.load('../Data/N12/np/target_array_OHE.npy')\n",
    "    else:'''\n",
    "    lidar_image = rasterio.open('../Data/N12/N12_lidar.tif').read()\n",
    "    lidar_array = np.array(lidar_image)\n",
    "    lidar_array = log_minmax(lidar_array, dim=(0,1))\n",
    "\n",
    "    lidar_1n_image = rasterio.open('../Data/N12/N12_lidar_1n.tif').read()\n",
    "    lidar_1n_array = np.array(lidar_1n_image)\n",
    "    lidar_1n_array = log_minmax(lidar_1n_array, dim=(0,1))\n",
    "\n",
    "    lidar_nt_image = rasterio.open('../Data/N12/N12_lidar_nt.tif').read()\n",
    "    lidar_nt_array = np.array(lidar_nt_image)\n",
    "    lidar_nt_array = log_minmax(lidar_nt_array, dim=(0,1))\n",
    "\n",
    "    RGB2020_image = rasterio.open('../Data/N12/N12_RGB2020.tif').read()\n",
    "    RGB2020_array = np.array(RGB2020_image)\n",
    "\n",
    "    train_array = np.stack([lidar_array, lidar_1n_array, lidar_nt_array]).squeeze()\n",
    "    train_array = np.concatenate((train_array,RGB2020_array))\n",
    "    target_image = rasterio.open('../Data/N12/N12_newlc.tif').read()\n",
    "    target_array = np.array(target_image, dtype=int).squeeze()\n",
    "    target_array = np.where(target_array == 1, 0, target_array)\n",
    "    target_array = np.where(target_array == 2, 1, target_array)\n",
    "    target_array = np.where(target_array == 7, 2, target_array)\n",
    "    target_array = np.where(target_array == 8, 3, target_array)\n",
    "    target_array = np.where(target_array == 9, 4, target_array)\n",
    "    target_array = np.where(target_array == 10, 5, target_array)\n",
    "    target_array = np.where(target_array == 11, 6, target_array)\n",
    "\n",
    "    if one_hot_encode:\n",
    "        num = np.unique(target_array)\n",
    "        num = num.shape[0]\n",
    "        encoded_target_array = np.eye(num)[target_array]\n",
    "        target_array=np.zeros(shape=(7,2400,2400))\n",
    "        for i in range(encoded_target_array.shape[-1]):\n",
    "            target_array[i,:,:]=encoded_target_array[:,:,i]\n",
    "\n",
    "    return train_array, target_array.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset2(Dataset):\n",
    "    def __init__(self, data_array : Type[np.ndarray], target_array : Type[np.ndarray], patch_size : int, is_evaluating : bool = False, is_validating : bool = False, rotate : bool = False, train_ratio : float = 0.8, one_hot_encode:bool = True):\n",
    "        self.is_validating = is_validating\n",
    "        self.is_evaluating = is_evaluating\n",
    "        seed = 386579\n",
    "\n",
    "        self.data = np.zeros(((data_array.shape[1]//patch_size) * (data_array.shape[2]//patch_size), data_array.shape[0], patch_size, patch_size))\n",
    "\n",
    "        for i in range(0,data_array.shape[1]//patch_size):\n",
    "            for j in range(0,data_array.shape[2]//patch_size):\n",
    "                self.data[data_array.shape[1]//patch_size*i+j,:,:,:] = data_array[:,i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size]\n",
    "\n",
    "        if one_hot_encode:\n",
    "            self.label = np.zeros(((data_array.shape[1]//patch_size) * (data_array.shape[2]//patch_size), target_array.shape[0] ,patch_size, patch_size), dtype=float)\n",
    "            for k in range(0,data_array.shape[1]//patch_size):\n",
    "                for l in range(0,data_array.shape[2]//patch_size):\n",
    "                    self.label[data_array.shape[1]//patch_size*k+l,:,:,:] = target_array[:,i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size]\n",
    "        else:\n",
    "            self.label = np.zeros(((data_array.shape[1]//patch_size) * (data_array.shape[2]//patch_size),data_array.shape[0]+1))\n",
    "            for k in range(0,data_array.shape[1]//patch_size):\n",
    "                for l in range(0,data_array.shape[2]//patch_size):\n",
    "                    self.label[data_array.shape[1]//patch_size*k+l,:] = np.bincount(target_array[k*patch_size:(k+1)*patch_size, l*patch_size:(l+1)*patch_size].reshape(-1), minlength=7)/(patch_size*patch_size)\n",
    "\n",
    "\n",
    "        if not is_evaluating:\n",
    "            if rotate:\n",
    "                for i in range(2):\n",
    "                    rotated_data = np.rot90(self.data, k=i+1, axes=(-2, -1))\n",
    "                    self.data = np.concatenate((self.data, rotated_data), axis=0)\n",
    "                    if one_hot_encode:\n",
    "                        rotated_data = np.rot90(self.label, k=i+1, axes=(-2, -1))\n",
    "                    else:\n",
    "                        rotated_data = self.label\n",
    "                    self.label = np.concatenate((self.label, rotated_data), axis=0)\n",
    "\n",
    "        train_size = int(self.data.shape[0]*train_ratio)\n",
    "        index_array = np.random.RandomState(seed=seed).permutation(self.data.shape[0])\n",
    "        self.train_index = index_array[0:train_size]\n",
    "        self.valid_index = index_array[train_size:index_array.shape[0]]\n",
    "        \n",
    "        self.data = torch.as_tensor(self.data).float()\n",
    "        self.label = torch.as_tensor(self.label).float()\n",
    "\n",
    "        self.data[:,3:6,:,:] = self.data[:,3:6,:,:]/255\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.is_evaluating:\n",
    "            return self.data.shape[0]\n",
    "\n",
    "        if self.is_validating:\n",
    "            return self.valid_index.shape[0]\n",
    "        else:\n",
    "            return self.train_index.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_evaluating:\n",
    "            sample = torch.as_tensor(self.data[idx,:,:,:]).float()\n",
    "            label = torch.as_tensor(self.label[idx,:]).float()\n",
    "            return sample, label\n",
    "        \n",
    "        if self.is_validating:\n",
    "            sample = torch.as_tensor(self.data[self.valid_index[idx],:,:,:]).float()\n",
    "            label = torch.as_tensor(self.label[self.valid_index[idx],:]).float()\n",
    "        else:\n",
    "            sample = torch.as_tensor(self.data[self.train_index[idx],:,:,:]).float()\n",
    "            label = torch.as_tensor(self.label[self.train_index[idx],:]).float()\n",
    "\n",
    "        return sample, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_padding(inputs, kernel_size, dilation):\n",
    "    kernel_size_effective = kernel_size + (kernel_size - 1) * (dilation - 1)\n",
    "    pad_total = kernel_size_effective - 1\n",
    "    pad_beg = pad_total // 2\n",
    "    pad_end = pad_total - pad_beg\n",
    "    padded_inputs = F.pad(inputs, (pad_beg, pad_end, pad_beg, pad_end))\n",
    "    return padded_inputs\n",
    "\n",
    "\n",
    "class SeparableConv2d(nn.Module):\n",
    "    def __init__(self, inplanes, planes, kernel_size=3, stride=1, dilation=1, bias=False, BatchNorm=None):\n",
    "        super(SeparableConv2d, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(inplanes, inplanes, kernel_size, stride, 0, dilation,\n",
    "                               groups=inplanes, bias=bias)\n",
    "        self.bn = BatchNorm(inplanes)\n",
    "        self.pointwise = nn.Conv2d(inplanes, planes, 1, 1, 0, 1, 1, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = fixed_padding(x, self.conv1.kernel_size[0], dilation=self.conv1.dilation[0])\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBN(nn.Module):\n",
    "    def __init__(self, C_in, C_out, kernel_size, stride, dilation = 1, affine=True, fix_padding = True):\n",
    "        super(ConvBN, self).__init__()\n",
    "        self.fix_padding = fix_padding\n",
    "        self.conv2d = nn.Conv2d(C_in, C_in, kernel_size=kernel_size, stride=stride, groups=C_in, bias=False, dilation=dilation)\n",
    "        self.pointwise = nn.Conv2d(C_in, C_out, kernel_size=1, padding=0, bias=False)\n",
    "        self.batchnorm = nn.BatchNorm2d(C_in, affine=affine)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.fix_padding:\n",
    "           x = fixed_padding(x, self.conv2d.kernel_size[0], dilation=self.conv2d.dilation[0])\n",
    "        x = self.conv2d(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, C_in, C_out, reps, stride = 1, dilation = 1, grow_first = True, start_with_relu = True, is_last = False):\n",
    "        super(Block, self).__init__()\n",
    "        \n",
    "        if C_in!=C_out or stride!=1:\n",
    "            self.skip = ConvBN(C_in, C_out, kernel_size=1, stride=stride)\n",
    "        else:\n",
    "            self.skip = None\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        rep = []\n",
    "\n",
    "        filters = C_in\n",
    "        if grow_first:\n",
    "            rep.append(self.relu)\n",
    "            rep.append(ConvBN(C_in, C_out, kernel_size=3, stride=1, dilation = dilation))\n",
    "            filters = C_out\n",
    "\n",
    "        for i in range(reps-1):\n",
    "            rep.append(self.relu)\n",
    "            rep.append(ConvBN(filters, filters, 3, stride=1, dilation = dilation))\n",
    "\n",
    "        if not grow_first:\n",
    "            rep.append(self.relu)\n",
    "            rep.append(ConvBN(C_in, C_out, 3, stride=1, dilation = dilation))\n",
    "\n",
    "        if stride != 1:\n",
    "            rep.append(self.relu)\n",
    "            rep.append(ConvBN(C_out, C_out, 3, stride=2, dilation = dilation))\n",
    "\n",
    "        if stride == 1 and is_last:\n",
    "            rep.append(self.relu)\n",
    "            rep.append(ConvBN(C_out, C_out, 3, 1))\n",
    "\n",
    "        if not start_with_relu:\n",
    "            rep = rep[1:]\n",
    "\n",
    "        self.rep = nn.Sequential(*rep)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(f'Shape before residual : {x.shape}')\n",
    "\n",
    "        if self.skip is not None:\n",
    "            #print('trying residual')\n",
    "            skip = self.skip(x)\n",
    "            #print('succeded residual')\n",
    "        else:\n",
    "            skip = x\n",
    "        x = self.rep(x)\n",
    "\n",
    "        #print(f'Shape after residual : {x.shape}')\n",
    "        x += skip\n",
    "        return x\n",
    "\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xception(nn.Module):\n",
    "    def __init__(self, output_stride=16):\n",
    "        super(Xception, self).__init__()\n",
    "        if output_stride == 16:\n",
    "            entry_block3_stride = 2\n",
    "            middle_block_dilation = 1\n",
    "            exit_block_dilations = (1, 2)\n",
    "        elif output_stride == 8:\n",
    "            entry_block3_stride = 1\n",
    "            middle_block_dilation = 2\n",
    "            exit_block_dilations = (2, 4)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.entry_flow = nn.Sequential(\n",
    "            nn.Conv2d(6, 32, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            Block(64, 128, reps=2, stride=2, start_with_relu=False),\n",
    "            Block(128, 256, reps=2, stride=2, start_with_relu=False, grow_first=True),\n",
    "            Block(256, 728, reps=2, stride=entry_block3_stride, start_with_relu=True, grow_first=True, is_last=True)\n",
    "        )\n",
    "\n",
    "        self.middle_flow = nn.Sequential(\n",
    "            Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True),\n",
    "            Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True),\n",
    "            Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True),\n",
    "            Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True),\n",
    "            Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True),\n",
    "            Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True),\n",
    "            Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True),\n",
    "            Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True)\n",
    "        )\n",
    "\n",
    "        self.exit_flow = nn.Sequential(\n",
    "            Block(728, 1024, reps=2, stride=1, dilation=exit_block_dilations[0], start_with_relu=True, grow_first=False, is_last=True),\n",
    "            ConvBN(1024, 1536, 3, stride=1, dilation=exit_block_dilations[1]),\n",
    "            ConvBN(1536, 1536, 3, stride=1, dilation=exit_block_dilations[1]),\n",
    "            ConvBN(1536, 2048, 3, stride=1, dilation=exit_block_dilations[1])\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.entry_flow(x)\n",
    "        x = self.middle_flow(x)\n",
    "        x = self.exit_flow(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UrbanGreenRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UrbanGreenRegression, self).__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            ConvBN(C_in=6, C_out=32, kernel_size=3, stride=1, fix_padding=False),\n",
    "            nn.ReLU(),\n",
    "            ConvBN(C_in=32, C_out=32, kernel_size=3, stride=1, fix_padding=False),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3)\n",
    "        )\n",
    "\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            ConvBN(C_in=32, C_out=64, kernel_size=3, stride=1, fix_padding=False),\n",
    "            nn.ReLU(),\n",
    "            ConvBN(C_in=64, C_out=64, kernel_size=3, stride=1, fix_padding=False),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.fc_block_1 = nn.Sequential(\n",
    "            nn.Linear(in_features=1024, out_features=1024, bias=False),\n",
    "            nn.BatchNorm1d(num_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=1024, out_features=1024, bias=False),\n",
    "            nn.BatchNorm1d(num_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=1024, out_features=1024, bias=False),\n",
    "            nn.BatchNorm1d(num_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=1024, out_features=1024, bias=False),\n",
    "            nn.BatchNorm1d(num_features=1024),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc_block_2 = nn.Sequential(\n",
    "            nn.Linear(in_features=1024, out_features=256, bias=False),\n",
    "            nn.BatchNorm1d(num_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=64, bias=False),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,7, False),\n",
    "            nn.BatchNorm1d(7)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv_block_1(x)\n",
    "        x = self.conv_block_2(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc_block_1(x)\n",
    "        x = self.fc_block_2(x)\n",
    "        return torch.softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_array, raw_target_array = prepare_raw_files(one_hot_encode=False)\n",
    "batch_size = 60\n",
    "patch_size = 40\n",
    "train_ratio = 0.8\n",
    "rotate_training_data = True\n",
    "Datasets_NON_OHE = {\n",
    "    'Train' : TrainDataset2(raw_data_array, raw_target_array, patch_size = patch_size, rotate = rotate_training_data, train_ratio = train_ratio, one_hot_encode=False),\n",
    "    'Validation' : TrainDataset2(raw_data_array, raw_target_array, patch_size = patch_size, is_validating = True, rotate = rotate_training_data, train_ratio = train_ratio, one_hot_encode=False),\n",
    "    'Prediction' : TrainDataset2(raw_data_array, raw_target_array, patch_size = patch_size, is_evaluating = True, train_ratio = train_ratio, one_hot_encode=False)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataloaders_NON_OHE = {\n",
    "    'Train' : DataLoader(Datasets_NON_OHE['Train'], batch_size=60),\n",
    "    'Validation' : DataLoader(Datasets_NON_OHE['Validation'], batch_size=60),\n",
    "    'Prediction' : DataLoader(Datasets_NON_OHE['Prediction'], batch_size=60)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [60, 6, 38, 38]              54\n",
      "       BatchNorm2d-2            [60, 6, 38, 38]              12\n",
      "            Conv2d-3           [60, 32, 38, 38]             192\n",
      "            ConvBN-4           [60, 32, 38, 38]               0\n",
      "              ReLU-5           [60, 32, 38, 38]               0\n",
      "            Conv2d-6           [60, 32, 36, 36]             288\n",
      "       BatchNorm2d-7           [60, 32, 36, 36]              64\n",
      "            Conv2d-8           [60, 32, 36, 36]           1,024\n",
      "            ConvBN-9           [60, 32, 36, 36]               0\n",
      "             ReLU-10           [60, 32, 36, 36]               0\n",
      "        MaxPool2d-11           [60, 32, 12, 12]               0\n",
      "           Conv2d-12           [60, 32, 10, 10]             288\n",
      "      BatchNorm2d-13           [60, 32, 10, 10]              64\n",
      "           Conv2d-14           [60, 64, 10, 10]           2,048\n",
      "           ConvBN-15           [60, 64, 10, 10]               0\n",
      "             ReLU-16           [60, 64, 10, 10]               0\n",
      "           Conv2d-17             [60, 64, 8, 8]             576\n",
      "      BatchNorm2d-18             [60, 64, 8, 8]             128\n",
      "           Conv2d-19             [60, 64, 8, 8]           4,096\n",
      "           ConvBN-20             [60, 64, 8, 8]               0\n",
      "             ReLU-21             [60, 64, 8, 8]               0\n",
      "        MaxPool2d-22             [60, 64, 4, 4]               0\n",
      "           Linear-23                 [60, 1024]       1,048,576\n",
      "      BatchNorm1d-24                 [60, 1024]           2,048\n",
      "             ReLU-25                 [60, 1024]               0\n",
      "           Linear-26                 [60, 1024]       1,048,576\n",
      "      BatchNorm1d-27                 [60, 1024]           2,048\n",
      "             ReLU-28                 [60, 1024]               0\n",
      "           Linear-29                 [60, 1024]       1,048,576\n",
      "      BatchNorm1d-30                 [60, 1024]           2,048\n",
      "             ReLU-31                 [60, 1024]               0\n",
      "           Linear-32                 [60, 1024]       1,048,576\n",
      "      BatchNorm1d-33                 [60, 1024]           2,048\n",
      "             ReLU-34                 [60, 1024]               0\n",
      "           Linear-35                  [60, 256]         262,144\n",
      "      BatchNorm1d-36                  [60, 256]             512\n",
      "             ReLU-37                  [60, 256]               0\n",
      "           Linear-38                   [60, 64]          16,384\n",
      "      BatchNorm1d-39                   [60, 64]             128\n",
      "             ReLU-40                   [60, 64]               0\n",
      "           Linear-41                    [60, 7]             448\n",
      "      BatchNorm1d-42                    [60, 7]              14\n",
      "================================================================\n",
      "Total params: 4,490,960\n",
      "Trainable params: 4,490,960\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 2.20\n",
      "Forward/backward pass size (MB): 196.05\n",
      "Params size (MB): 17.13\n",
      "Estimated Total Size (MB): 215.38\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "model_for_summary = UrbanGreenRegression()\n",
    "model_for_summary.to(device)\n",
    "summary(model_for_summary, input_size=(6,40,40), batch_size=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Patches : 11520\n",
      "Validating Patches : 2880\n",
      "Epoch 0/2\n",
      "----------\n",
      "Valid loss: 0.03438578767236322 | Train loss: 0.0494002255727537\n",
      "Epoch 1/2\n",
      "----------\n",
      "Valid loss: 0.028757170230771106 | Train loss: 0.028506357872781034\n",
      "Epoch 2/2\n",
      "----------\n",
      "Valid loss: 0.028721383384739358 | Train loss: 0.02086079362197779\n",
      "Best loss: 0.028721, in Epoch #002\n",
      "Model information is saved in ../Data/N12/Model/Segmentation/Regression/2022.7.19/temp/13:03_temp.zip\n"
     ]
    },
    {
     "ename": "RasterioIOError",
     "evalue": ": No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32mrasterio/_base.pyx\u001b[0m in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mrasterio/_shim.pyx\u001b[0m in \u001b[0;36mrasterio._shim.open_dataset\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mrasterio/_err.pyx\u001b[0m in \u001b[0;36mrasterio._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: : No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRasterioIOError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23456/1352780841.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moptimizer2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscheduler2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mbest_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataloaders_NON_OHE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../Data/N12/Model/Segmentation/Regression/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'temp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_23456/2572862183.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, criterion, optimizer, scheduler, device, num_epochs, train_rate, batch_size, path, description, reference_data)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'{now.year}.{now.month}.{now.day}/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'{description}/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'tmp/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'{0:0=2d}.pth'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mresult_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Prediction'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreference_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model result is saved in '\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mresult_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_23456/2872442810.py\u001b[0m in \u001b[0;36msave_result\u001b[0;34m(model, dataloader, path, description, reference_data, patch_size, now)\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mprediction_expanded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mreference_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mlayer_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tt/lib/python3.7/site-packages/rasterio/env.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0menv_ctor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tt/lib/python3.7/site-packages/rasterio/__init__.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, width, height, count, crs, transform, dtype, nodata, sharing, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;31m# None.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatasetReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msharing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"r+\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             s = get_writer_for_path(path, driver=driver)(\n",
      "\u001b[0;32mrasterio/_base.pyx\u001b[0m in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRasterioIOError\u001b[0m: : No such file or directory"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2 = UrbanGreenRegression()\n",
    "criterion2 = torch.nn.MSELoss(reduction='mean')\n",
    "optimizer2 = torch.optim.SGD(model2.parameters(), lr=0.01, momentum=0.9)\n",
    "scheduler2 = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer2, 'min', patience=5, factor=0.75)\n",
    "best_model_path = train_model(model2, Dataloaders_NON_OHE, criterion2, optimizer2, scheduler2, device, num_epochs=3, batch_size=batch_size, path='../Data/N12/Model/Segmentation/Regression/', description='temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UrbanGreenSegmentation(pl.LightningModule):\n",
    "    def __init__(self, rotate_training_data : bool = False, train_ratio : float = 0.8, patch_size : int = 100, batch_size : int = 16):\n",
    "        super(UrbanGreenSegmentation, self).__init__()\n",
    "        raw_data_array, raw_target_array = prepare_raw_files(one_hot_encode=True)\n",
    "        _, raw_target_array_Reg = prepare_raw_files(one_hot_encode=False)\n",
    "        self.batch_size = batch_size\n",
    "        self.Datasets_Seg = {\n",
    "            'Train' : TrainDataset2(raw_data_array, raw_target_array, patch_size = patch_size, rotate = rotate_training_data, train_ratio = train_ratio, one_hot_encoding = True),\n",
    "            'Validation' : TrainDataset2(raw_data_array, raw_target_array, patch_size = patch_size, is_validating = True, rotate = rotate_training_data, train_ratio = train_ratio, one_hot_encoding = True),\n",
    "            'Prediction' : TrainDataset2(raw_data_array, raw_target_array, patch_size = patch_size, is_evaluating = True, train_ratio = train_ratio, one_hot_encoding = True)\n",
    "        }\n",
    "        self.Datasets_Reg = {\n",
    "            'Train' : TrainDataset2(raw_data_array, raw_target_array_Reg, patch_size = patch_size, rotate = rotate_training_data, train_ratio = train_ratio, one_hot_encode=False),\n",
    "            'Validation' : TrainDataset2(raw_data_array, raw_target_array_Reg, patch_size = patch_size, is_validating = True, rotate = rotate_training_data, train_ratio = train_ratio, one_hot_encode=False),\n",
    "            'Prediction' : TrainDataset2(raw_data_array, raw_target_array_Reg, patch_size = patch_size, is_evaluating = True, train_ratio = train_ratio, one_hot_encode=False)\n",
    "        }\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        pass\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        pass\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        pass\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        train_optimizer = torch.optim.Adam(self.parameters(), lr=0.02)\n",
    "        train_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(train_optimizer, T_max=10)\n",
    "        return [train_optimizer], [train_scheduler]\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.Datasets['Train'], batch_size = self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.Datasets['Validation'], batch_size = self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.Datasets['Prediction'], batch_size = self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('tt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bef1a0741f78125b97ca6015f4b21165d553afbb2c419d3dfb1350931d81372"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

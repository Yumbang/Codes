{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import Type\n",
    "from torch import nn\n",
    "from torch.optim import optimizer\n",
    "import rasterio\n",
    "import zipfile\n",
    "from matplotlib import pyplot as plt\n",
    "import datetime\n",
    "from torchvision import transforms as transforms\n",
    "import shutil\n",
    "import torchmetrics\n",
    "import os\n",
    "import pytorch_lightning as pl\n",
    "import sklearn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# --- GPU selection --- #\n",
    "gpus = 7 # slot number (e.g., 3), no gpu use -> write just ' '\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpus)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax(array : Type[np.ndarray], dim = 0):\n",
    "    min = np.min(array, axis=dim)\n",
    "    max = np.max(array, axis=dim)\n",
    "    array = (array-min)/(max-min)\n",
    "    return array\n",
    "\n",
    "def log_minmax(array : Type[np.ndarray], dim = 0):\n",
    "    min = np.min(array, axis=dim)\n",
    "    array = array - min + 1\n",
    "    array = np.log(array)\n",
    "    max = np.max(array, axis=dim)\n",
    "    array = (array)/(max)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result(model: Type[nn.Module], dataloader : Type[DataLoader], path:str, description:str = '', reference_data:str = '', patch_size:int = 60, now = datetime.datetime.now()):\n",
    "    best_model = model\n",
    "    os.makedirs(os.path.join(path,f'{now.year}.{now.month}.{now.day}/', f'{description}/','tmp/'), exist_ok=True)\n",
    "    zipped_results = zipfile.ZipFile(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','RESULT_{0:0=2d}:{1:0=2d}'.format(now.hour, now.minute)+f'_{description}.zip'), 'w')\n",
    "    prediction = np.zeros((60,60,7))\n",
    "    for i, (data, index) in enumerate(dataloader):\n",
    "        prediction[i, :, :] = best_model(data).detach().numpy()\n",
    "    prediction_expanded = np.zeros((7,2400,2400))\n",
    "    for i in range(60):\n",
    "        for j in range(60):\n",
    "            for k in range(7):\n",
    "                prediction_expanded[k,i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size] = prediction[i,j,k]\n",
    "\n",
    "    reference_image = rasterio.open(reference_data)\n",
    "    layer_index = [1,2,7,8,9,10,11]\n",
    "\n",
    "    for i in range(prediction_expanded.shape[0]):\n",
    "        print('a') \n",
    "        processed_tiff = rasterio.open(\n",
    "            os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/', 'tmp/', f'Result_{layer_index[i]}_{description}.tif'),\n",
    "            'w',\n",
    "            driver='GTiff',\n",
    "            height=prediction_expanded.shape[1],\n",
    "            width=prediction_expanded.shape[2],\n",
    "            count=1,\n",
    "            dtype=prediction_expanded.dtype,\n",
    "            crs=reference_image.crs,\n",
    "            transform=reference_image.transform,\n",
    "        )\n",
    "        print('b')\n",
    "        processed_tiff.write(prediction_expanded[i,:,:],1)\n",
    "        processed_tiff.close()\n",
    "        print('c')\n",
    "        zipped_results.write(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/', 'tmp/', f'Result_{layer_index[i]}_{description}.tif'), f'Result_{layer_index[i]}_{description}.tif')\n",
    "\n",
    "    zipped_results.close()\n",
    "    return os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','RESULT_{0:0=2d}:{1:0=2d}'.format(now.hour, now.minute)+f'_{description}.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, scheduler, device, num_epochs=13, train_rate: float = 0.8, batch_size: int = 60, path:str = '../Data/N12/Model/', description:str = 'no_description', reference_data:str = ''): \n",
    "    train_loss_history = []\n",
    "    valid_loss_history = []\n",
    "\n",
    "    patch_size = dataloaders['Train'].dataset.data.shape[-1]\n",
    "    training_patches = len(dataloaders['Train'].dataset)\n",
    "    validating_patches = len(dataloaders['Validation'].dataset)\n",
    "    print(f'Training Patches : {training_patches}\\nValidating Patches : {validating_patches}')\n",
    "\n",
    "    best_model_epoch = 0\n",
    "    least_valid_loss = 100\n",
    "    now = datetime.datetime.now()\n",
    "    os.makedirs(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/', 'tmp/'), exist_ok=True)\n",
    "    zipped_model = zipfile.ZipFile(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/', '{0:0=2d}:{1:0=2d}'.format(now.hour, now.minute)+f'_{description}'+'.zip'), 'w')\n",
    "    \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        train_running_loss = 0.0\n",
    "        valid_running_loss = 0.0\n",
    "\n",
    "        for state in ['Train', 'Validation']:\n",
    "            for i, (inputs, labels) in enumerate(dataloaders[state]):\n",
    "                \n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                model.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                if state == 'Train':\n",
    "                    model.train()\n",
    "                    train_loss = criterion(outputs, labels)\n",
    "                    train_loss.backward()\n",
    "                    train_running_loss += train_loss.item() * inputs.size(0)\n",
    "                \n",
    "                if state == 'Validation':\n",
    "                    model.eval()\n",
    "                    valid_loss = criterion(outputs, labels)\n",
    "                    valid_running_loss += valid_loss.item() * inputs.size(0)\n",
    "\n",
    "                optimizer.step()\n",
    "                #valid_running_similarity += metric(outputs, labels)\n",
    "                #print('validating')\n",
    "                \n",
    "                #print(f'{i}th batch')\n",
    "            \n",
    "\n",
    "\n",
    "        \n",
    "        #print(f'Memory after a training : {torch.cuda.memory_allocated()/1024/1024}')\n",
    "\n",
    "        epoch_train_loss = train_running_loss / training_patches\n",
    "        epoch_valid_loss = valid_running_loss / validating_patches\n",
    "        scheduler.step(epoch_valid_loss)\n",
    "\n",
    "        print(f'Valid loss: {epoch_valid_loss} | Train loss: {epoch_train_loss}')\n",
    "\n",
    "\n",
    "        if epoch_valid_loss < least_valid_loss:\n",
    "            least_valid_loss = epoch_valid_loss\n",
    "            best_model_epoch = epoch\n",
    "\n",
    "        train_loss_history.append(epoch_train_loss)      \n",
    "        valid_loss_history.append(epoch_valid_loss)\n",
    "\n",
    "        torch.save(model.state_dict(), os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','tmp/', '{0:0=2d}.pth'.format(epoch)))\n",
    "        zipped_model.write(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','tmp/', '{0:0=2d}.pth'.format(epoch)))\n",
    "\n",
    "    plt.figure(figsize=(20,8))\n",
    "    plt.plot(train_loss_history, 'r-')\n",
    "    plt.plot(valid_loss_history, 'bo')\n",
    "    plt.savefig(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','tmp/', 'Tendency.png'), dpi=300)\n",
    "    zipped_model.write(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','tmp/', 'Tendency.png'))\n",
    "    zipped_model.writestr('README.txt', f'{description}\\nThe best Model : #{best_model_epoch}th model with loss {least_valid_loss}\\nOptimizer : {optimizer}\\nLoss function : {criterion}\\nBatch size : {batch_size}\\nScheduler : {scheduler}\\nPatch size : {patch_size}\\nTotal epochs : {num_epochs}\\nModel information :\\n{model.modules}')\n",
    "    \n",
    "    print('Best loss: {:4f}, in Epoch #{:0=3d}'.format(least_valid_loss, best_model_epoch))    \n",
    "    zipped_model.close()\n",
    "    shutil.copy(src=os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/', 'tmp/', '{0:0=2d}.pth'.format(epoch)), dst=os.path.join(path,f'{now.year}.{now.month}.{now.day}/', 'Best_Model_Parameters_of_{0:0=2d}:{1:0=2d}'.format(now.hour, now.minute)+f'_{description}'+'.pth'))\n",
    "    print('Model information is saved in '+os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/', '{0:0=2d}:{1:0=2d}'.format(now.hour, now.minute)+f'_{description}'+'.zip'))\n",
    "\n",
    "    model.load_state_dict(torch.load(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','tmp/', '{0:0=2d}.pth'.format(best_model_epoch))))\n",
    "    result_path = save_result(model = model.to('cpu'), dataloader=dataloaders['Prediction'], path=path, description=description, reference_data=reference_data, patch_size=patch_size, now=now)\n",
    "    print('Model result is saved in '+ result_path)\n",
    "    \n",
    "    shutil.rmtree(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','tmp/'))\n",
    "    best_model_path = os.path.join(path,f'{now.year}.{now.month}.{now.day}/', 'Best_Model_Parameters_of_{0:0=2d}:{1:0=2d}'.format(now.hour, now.minute)+f'_{description}'+'.pth')\n",
    "    return best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_raw_files():\n",
    "    '''if os.path.exists('../Data/N12/np/train_array.npy') and os.path.exists('../Data/N12/np/target_array_OHE.npy'):\n",
    "        train_array = np.load('../Data/N12/np/train_array.npy')\n",
    "        target_array = np.load('../Data/N12/np/target_array_OHE.npy')\n",
    "    else:'''\n",
    "    lidar_image = rasterio.open('../Data/N12/N12_lidar.tif').read()\n",
    "    lidar_array = np.array(lidar_image)\n",
    "    lidar_array = log_minmax(lidar_array, dim=(0,1))\n",
    "\n",
    "    lidar_1n_image = rasterio.open('../Data/N12/N12_lidar_1n.tif').read()\n",
    "    lidar_1n_array = np.array(lidar_1n_image)\n",
    "    lidar_1n_array = log_minmax(lidar_1n_array, dim=(0,1))\n",
    "\n",
    "    lidar_nt_image = rasterio.open('../Data/N12/N12_lidar_nt.tif').read()\n",
    "    lidar_nt_array = np.array(lidar_nt_image)\n",
    "    lidar_nt_array = log_minmax(lidar_nt_array, dim=(0,1))\n",
    "\n",
    "    RGB2020_image = rasterio.open('../Data/N12/N12_RGB2020.tif').read()\n",
    "    RGB2020_array = np.array(RGB2020_image)\n",
    "\n",
    "    train_array = np.stack([lidar_array, lidar_1n_array, lidar_nt_array]).squeeze()\n",
    "    train_array = np.concatenate((train_array,RGB2020_array))\n",
    "    target_image = rasterio.open('../Data/N12/N12_newlc.tif').read()\n",
    "    target_array = np.array(target_image, dtype=int).squeeze()\n",
    "    target_array = np.where(target_array == 1, 0, target_array)\n",
    "    target_array = np.where(target_array == 2, 1, target_array)\n",
    "    target_array = np.where(target_array == 7, 2, target_array)\n",
    "    target_array = np.where(target_array == 8, 3, target_array)\n",
    "    target_array = np.where(target_array == 9, 4, target_array)\n",
    "    target_array = np.where(target_array == 10, 5, target_array)\n",
    "    target_array = np.where(target_array == 11, 6, target_array)\n",
    "\n",
    "    target_array_OHE = np.zeros(shape=(7,2400,2400))\n",
    "    num = np.unique(target_array)\n",
    "    num = num.shape[0]\n",
    "    encoded_target_array = np.eye(num)[target_array]\n",
    "    for i in range(encoded_target_array.shape[-1]):\n",
    "        target_array_OHE[i,:,:]=encoded_target_array[:,:,i]\n",
    "\n",
    "    return train_array, target_array.astype(int), target_array_OHE.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset2(Dataset):\n",
    "    def __init__(self, data_array : Type[np.ndarray], target_array_OHE : Type[np.ndarray], target_array_RAW : Type[np.ndarray], patch_size : int, is_evaluating : bool = False, is_validating : bool = False, rotate : bool = False, train_ratio : float = 0.8):\n",
    "        self.is_validating = is_validating\n",
    "        self.is_evaluating = is_evaluating\n",
    "        seed = 386579\n",
    "\n",
    "        #print(f'Data shape: {data_array.shape} | Target shape: {target_array.shape}')\n",
    "\n",
    "        self.data = np.zeros(((data_array.shape[1]//patch_size) * (data_array.shape[2]//patch_size), data_array.shape[0], patch_size, patch_size))\n",
    "\n",
    "        for i in range(0,data_array.shape[1]//patch_size):\n",
    "            for j in range(0,data_array.shape[2]//patch_size):\n",
    "                self.data[data_array.shape[1]//patch_size*i+j,:,:,:] = data_array[:,i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size]\n",
    "\n",
    "        self.label_OHE = np.zeros(((data_array.shape[1]//patch_size) * (data_array.shape[2]//patch_size), target_array_OHE.shape[0] ,patch_size, patch_size), dtype=float)\n",
    "        for k in range(0,data_array.shape[1]//patch_size):\n",
    "            for l in range(0,data_array.shape[2]//patch_size):\n",
    "                self.label_OHE[data_array.shape[1]//patch_size*k+l,:,:,:] = target_array_OHE[:,i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size]\n",
    "\n",
    "        self.label_RAW = np.zeros(((data_array.shape[1]//patch_size) * (data_array.shape[2]//patch_size),data_array.shape[0]+1))\n",
    "        for k in range(0,data_array.shape[1]//patch_size):\n",
    "            for l in range(0,data_array.shape[2]//patch_size):\n",
    "                self.label_RAW[data_array.shape[1]//patch_size*k+l,:] = np.bincount(target_array_RAW[k*patch_size:(k+1)*patch_size, l*patch_size:(l+1)*patch_size].reshape(-1), minlength=7)/(patch_size*patch_size)\n",
    "\n",
    "\n",
    "        if not is_evaluating:\n",
    "            if rotate:\n",
    "                for i in range(2):\n",
    "                    rotated_data = np.rot90(self.data, k=i+1, axes=(-2, -1))\n",
    "                    self.data = np.concatenate((self.data, rotated_data), axis=0)\n",
    "                    rotated_label_OHE = np.rot90(self.label_OHE, k=i+1, axes=(-2, -1))\n",
    "                    rotated_label_RAW = self.label_RAW\n",
    "                    self.label_OHE = np.concatenate((self.label_OHE, rotated_label_OHE), axis=0)\n",
    "                    self.label_RAW = np.concatenate((self.label_RAW, rotated_label_RAW), axis=0)\n",
    "\n",
    "        train_size = int(self.data.shape[0]*train_ratio)\n",
    "        index_array = np.random.RandomState(seed=seed).permutation(self.data.shape[0])\n",
    "        self.train_index = index_array[0:train_size]\n",
    "        self.valid_index = index_array[train_size:index_array.shape[0]]\n",
    "        \n",
    "        self.data = torch.as_tensor(self.data).float()\n",
    "        self.label_OHE = torch.as_tensor(self.label_OHE).float()\n",
    "        self.label_RAW = torch.as_tensor(self.label_RAW).float()\n",
    "\n",
    "        self.data[:,3:6,:,:] = self.data[:,3:6,:,:]/255\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.is_evaluating:\n",
    "            return self.data.shape[0]\n",
    "\n",
    "        if self.is_validating:\n",
    "            return self.valid_index.shape[0]\n",
    "        else:\n",
    "            return self.train_index.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_evaluating:\n",
    "            sample = torch.as_tensor(self.data[idx,:,:,:]).float()\n",
    "            label_OHE = torch.as_tensor(self.label_OHE[idx,:]).float()\n",
    "            label_RAW = torch.as_tensor(self.label_RAW[idx,:]).float()\n",
    "            return sample, label_OHE, label_RAW\n",
    "        \n",
    "        if self.is_validating:\n",
    "            sample = torch.as_tensor(self.data[self.valid_index[idx],:,:,:]).float()\n",
    "            label_OHE = torch.as_tensor(self.label_OHE[self.valid_index[idx],:]).float()\n",
    "            label_RAW = torch.as_tensor(self.label_RAW[self.valid_index[idx],:]).float()\n",
    "        else:\n",
    "            sample = torch.as_tensor(self.data[self.train_index[idx],:,:,:]).float()\n",
    "            label_OHE = torch.as_tensor(self.label_OHE[self.train_index[idx],:]).float()\n",
    "            label_RAW = torch.as_tensor(self.label_RAW[self.train_index[idx],:]).float()\n",
    "\n",
    "        return sample, label_OHE, label_RAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_padding(inputs, kernel_size, dilation):\n",
    "    kernel_size_effective = kernel_size + (kernel_size - 1) * (dilation - 1)\n",
    "    pad_total = kernel_size_effective - 1\n",
    "    pad_beg = pad_total // 2\n",
    "    pad_end = pad_total - pad_beg\n",
    "    padded_inputs = F.pad(inputs, (pad_beg, pad_end, pad_beg, pad_end))\n",
    "    return padded_inputs\n",
    "\n",
    "\n",
    "class SeparableConv2d(nn.Module):\n",
    "    def __init__(self, inplanes, planes, kernel_size=3, stride=1, dilation=1, bias=False, BatchNorm=None):\n",
    "        super(SeparableConv2d, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(inplanes, inplanes, kernel_size, stride, 0, dilation,\n",
    "                               groups=inplanes, bias=bias)\n",
    "        self.bn = BatchNorm(inplanes)\n",
    "        self.pointwise = nn.Conv2d(inplanes, planes, 1, 1, 0, 1, 1, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = fixed_padding(x, self.conv1.kernel_size[0], dilation=self.conv1.dilation[0])\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBN(nn.Module):\n",
    "    def __init__(self, C_in, C_out, kernel_size, stride, dilation = 1, affine=True, fix_padding = False):\n",
    "        super(ConvBN, self).__init__()\n",
    "        self.fix_padding = fix_padding\n",
    "        self.conv2d = nn.Conv2d(C_in, C_in, kernel_size=kernel_size, stride=stride, groups=C_in, bias=False, dilation=dilation)\n",
    "        self.pointwise = nn.Conv2d(C_in, C_out, kernel_size=1, padding=0, bias=False)\n",
    "        self.batchnorm = nn.BatchNorm2d(C_in, affine=affine)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.fix_padding:\n",
    "           x = fixed_padding(x, self.conv2d.kernel_size[0], dilation=self.conv2d.dilation[0])\n",
    "        x = self.conv2d(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"class Block(nn.Module):\\n    def __init__(self, C_in, C_out, reps, stride = 1, dilation = 1, grow_first = True, start_with_relu = True, is_last = False):\\n        super(Block, self).__init__()\\n        \\n        if C_in!=C_out or stride!=1:\\n            self.skip = ConvBN(C_in, C_out, kernel_size=1, stride=stride)\\n        else:\\n            self.skip = None\\n\\n        self.relu = nn.ReLU(inplace=True)\\n        rep = []\\n\\n        filters = C_in\\n        if grow_first:\\n            rep.append(self.relu)\\n            rep.append(ConvBN(C_in, C_out, kernel_size=3, stride=1, dilation = dilation))\\n            filters = C_out\\n\\n        for i in range(reps-1):\\n            rep.append(self.relu)\\n            rep.append(ConvBN(filters, filters, 3, stride=1, dilation = dilation))\\n\\n        if not grow_first:\\n            rep.append(self.relu)\\n            rep.append(ConvBN(C_in, C_out, 3, stride=1, dilation = dilation))\\n\\n        if stride != 1:\\n            rep.append(self.relu)\\n            rep.append(ConvBN(C_out, C_out, 3, stride=2, dilation = dilation))\\n\\n        if stride == 1 and is_last:\\n            rep.append(self.relu)\\n            rep.append(ConvBN(C_out, C_out, 3, 1))\\n\\n        if not start_with_relu:\\n            rep = rep[1:]\\n\\n        self.rep = nn.Sequential(*rep)\\n\\n    def forward(self, x):\\n        #print(f'Shape before residual : {x.shape}')\\n\\n        if self.skip is not None:\\n            #print('trying residual')\\n            skip = self.skip(x)\\n            #print('succeded residual')\\n        else:\\n            skip = x\\n        x = self.rep(x)\\n\\n        #print(f'Shape after residual : {x.shape}')\\n        x += skip\\n        return x\\n\\n    \\n\\n        \""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''class Block(nn.Module):\n",
    "    def __init__(self, C_in, C_out, reps, stride = 1, dilation = 1, grow_first = True, start_with_relu = True, is_last = False):\n",
    "        super(Block, self).__init__()\n",
    "        \n",
    "        if C_in!=C_out or stride!=1:\n",
    "            self.skip = ConvBN(C_in, C_out, kernel_size=1, stride=stride)\n",
    "        else:\n",
    "            self.skip = None\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        rep = []\n",
    "\n",
    "        filters = C_in\n",
    "        if grow_first:\n",
    "            rep.append(self.relu)\n",
    "            rep.append(ConvBN(C_in, C_out, kernel_size=3, stride=1, dilation = dilation))\n",
    "            filters = C_out\n",
    "\n",
    "        for i in range(reps-1):\n",
    "            rep.append(self.relu)\n",
    "            rep.append(ConvBN(filters, filters, 3, stride=1, dilation = dilation))\n",
    "\n",
    "        if not grow_first:\n",
    "            rep.append(self.relu)\n",
    "            rep.append(ConvBN(C_in, C_out, 3, stride=1, dilation = dilation))\n",
    "\n",
    "        if stride != 1:\n",
    "            rep.append(self.relu)\n",
    "            rep.append(ConvBN(C_out, C_out, 3, stride=2, dilation = dilation))\n",
    "\n",
    "        if stride == 1 and is_last:\n",
    "            rep.append(self.relu)\n",
    "            rep.append(ConvBN(C_out, C_out, 3, 1))\n",
    "\n",
    "        if not start_with_relu:\n",
    "            rep = rep[1:]\n",
    "\n",
    "        self.rep = nn.Sequential(*rep)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(f'Shape before residual : {x.shape}')\n",
    "\n",
    "        if self.skip is not None:\n",
    "            #print('trying residual')\n",
    "            skip = self.skip(x)\n",
    "            #print('succeded residual')\n",
    "        else:\n",
    "            skip = x\n",
    "        x = self.rep(x)\n",
    "\n",
    "        #print(f'Shape after residual : {x.shape}')\n",
    "        x += skip\n",
    "        return x\n",
    "\n",
    "    \n",
    "\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class Xception(nn.Module):\\n    def __init__(self, output_stride=16):\\n        super(Xception, self).__init__()\\n        if output_stride == 16:\\n            entry_block3_stride = 2\\n            middle_block_dilation = 1\\n            exit_block_dilations = (1, 2)\\n        elif output_stride == 8:\\n            entry_block3_stride = 1\\n            middle_block_dilation = 2\\n            exit_block_dilations = (2, 4)\\n        else:\\n            raise NotImplementedError\\n\\n        self.entry_flow = nn.Sequential(\\n            nn.Conv2d(6, 32, kernel_size=3, stride=2, padding=1, bias=False),\\n            nn.BatchNorm2d(32),\\n            nn.ReLU(),\\n            nn.Conv2d(32,64, kernel_size=3, stride=1, padding=1, bias=False),\\n            nn.BatchNorm2d(64),\\n            nn.ReLU(),\\n            Block(64, 128, reps=2, stride=2, start_with_relu=False),\\n            Block(128, 256, reps=2, stride=2, start_with_relu=False, grow_first=True),\\n            Block(256, 728, reps=2, stride=entry_block3_stride, start_with_relu=True, grow_first=True, is_last=True)\\n        )\\n\\n        self.middle_flow = nn.Sequential(\\n            Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True),\\n            Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True),\\n            Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True),\\n            Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True),\\n            Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True),\\n            Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True),\\n            Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True),\\n            Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True)\\n        )\\n\\n        self.exit_flow = nn.Sequential(\\n            Block(728, 1024, reps=2, stride=1, dilation=exit_block_dilations[0], start_with_relu=True, grow_first=False, is_last=True),\\n            ConvBN(1024, 1536, 3, stride=1, dilation=exit_block_dilations[1]),\\n            ConvBN(1536, 1536, 3, stride=1, dilation=exit_block_dilations[1]),\\n            ConvBN(1536, 2048, 3, stride=1, dilation=exit_block_dilations[1])\\n        )\\n\\n    def forward(self, x):\\n        x = self.entry_flow(x)\\n        x = self.middle_flow(x)\\n        x = self.exit_flow(x)\\n        return x'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''class Xception(nn.Module):\n",
    "    def __init__(self, output_stride=16):\n",
    "        super(Xception, self).__init__()\n",
    "        if output_stride == 16:\n",
    "            entry_block3_stride = 2\n",
    "            middle_block_dilation = 1\n",
    "            exit_block_dilations = (1, 2)\n",
    "        elif output_stride == 8:\n",
    "            entry_block3_stride = 1\n",
    "            middle_block_dilation = 2\n",
    "            exit_block_dilations = (2, 4)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.entry_flow = nn.Sequential(\n",
    "            nn.Conv2d(6, 32, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            Block(64, 128, reps=2, stride=2, start_with_relu=False),\n",
    "            Block(128, 256, reps=2, stride=2, start_with_relu=False, grow_first=True),\n",
    "            Block(256, 728, reps=2, stride=entry_block3_stride, start_with_relu=True, grow_first=True, is_last=True)\n",
    "        )\n",
    "\n",
    "        self.middle_flow = nn.Sequential(\n",
    "            Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True),\n",
    "            Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True),\n",
    "            Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True),\n",
    "            Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True),\n",
    "            Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True),\n",
    "            Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True),\n",
    "            Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True),\n",
    "            Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True)\n",
    "        )\n",
    "\n",
    "        self.exit_flow = nn.Sequential(\n",
    "            Block(728, 1024, reps=2, stride=1, dilation=exit_block_dilations[0], start_with_relu=True, grow_first=False, is_last=True),\n",
    "            ConvBN(1024, 1536, 3, stride=1, dilation=exit_block_dilations[1]),\n",
    "            ConvBN(1536, 1536, 3, stride=1, dilation=exit_block_dilations[1]),\n",
    "            ConvBN(1536, 2048, 3, stride=1, dilation=exit_block_dilations[1])\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.entry_flow(x)\n",
    "        x = self.middle_flow(x)\n",
    "        x = self.exit_flow(x)\n",
    "        return x'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UrbanGreenRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UrbanGreenRegression, self).__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            ConvBN(6,32,3,1),#48\n",
    "            nn.ReLU(),\n",
    "            ConvBN(32,32,3,1),#46\n",
    "            nn.ReLU(),\n",
    "            ConvBN(32,32,3,1),#44\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)#22\n",
    "        )\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            ConvBN(32,64,3,1),#20\n",
    "            nn.ReLU(),\n",
    "            ConvBN(64,64,3,1),#18\n",
    "            nn.ReLU(),\n",
    "            ConvBN(64,64,3,1),#16\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)#8\n",
    "        )\n",
    "\n",
    "        self.fc_block_1 = nn.Sequential(\n",
    "            nn.Linear(in_features=4096, out_features=1024, bias=False),\n",
    "            nn.BatchNorm1d(num_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=1024, out_features=1024, bias=False),\n",
    "            nn.BatchNorm1d(num_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=1024, out_features=1024, bias=False),\n",
    "            nn.BatchNorm1d(num_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=1024, out_features=1024, bias=False),\n",
    "            nn.BatchNorm1d(num_features=1024),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc_block_2 = nn.Sequential(\n",
    "            nn.Linear(in_features=1024, out_features=256, bias=False),\n",
    "            nn.BatchNorm1d(num_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=64, bias=False),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,7, False),\n",
    "            nn.BatchNorm1d(7)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv_block_1(x)\n",
    "        x = self.conv_block_2(x)\n",
    "        print(x.shape)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        print(x.shape)\n",
    "        x = self.fc_block_1(x)\n",
    "        x = self.fc_block_2(x)\n",
    "        return torch.softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_array ,raw_target_array, OHE_target_array = prepare_raw_files()\n",
    "batch_size = 64\n",
    "patch_size = 50\n",
    "train_ratio = 0.8\n",
    "rotate_training_data = True\n",
    "Datasets_NON_OHE = {\n",
    "    'Train' : TrainDataset2(raw_data_array, OHE_target_array, raw_target_array, patch_size = patch_size, rotate = rotate_training_data, train_ratio = train_ratio),\n",
    "    'Validation' : TrainDataset2(raw_data_array, OHE_target_array, raw_target_array, patch_size = patch_size, is_validating = True, rotate = rotate_training_data, train_ratio = train_ratio),\n",
    "    'Prediction' : TrainDataset2(raw_data_array, OHE_target_array, raw_target_array, patch_size = patch_size, is_evaluating = True, train_ratio = train_ratio)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataloaders_NON_OHE = {\n",
    "    'Train' : DataLoader(Datasets_NON_OHE['Train'], batch_size=64),\n",
    "    'Validation' : DataLoader(Datasets_NON_OHE['Validation'], batch_size=64),\n",
    "    'Prediction' : DataLoader(Datasets_NON_OHE['Prediction'], batch_size=64)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 64, 8, 8])\n",
      "torch.Size([2, 4096])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [64, 6, 48, 48]              54\n",
      "       BatchNorm2d-2            [64, 6, 48, 48]              12\n",
      "            Conv2d-3           [64, 32, 48, 48]             192\n",
      "            ConvBN-4           [64, 32, 48, 48]               0\n",
      "              ReLU-5           [64, 32, 48, 48]               0\n",
      "            Conv2d-6           [64, 32, 46, 46]             288\n",
      "       BatchNorm2d-7           [64, 32, 46, 46]              64\n",
      "            Conv2d-8           [64, 32, 46, 46]           1,024\n",
      "            ConvBN-9           [64, 32, 46, 46]               0\n",
      "             ReLU-10           [64, 32, 46, 46]               0\n",
      "           Conv2d-11           [64, 32, 44, 44]             288\n",
      "      BatchNorm2d-12           [64, 32, 44, 44]              64\n",
      "           Conv2d-13           [64, 32, 44, 44]           1,024\n",
      "           ConvBN-14           [64, 32, 44, 44]               0\n",
      "             ReLU-15           [64, 32, 44, 44]               0\n",
      "        MaxPool2d-16           [64, 32, 22, 22]               0\n",
      "           Conv2d-17           [64, 32, 20, 20]             288\n",
      "      BatchNorm2d-18           [64, 32, 20, 20]              64\n",
      "           Conv2d-19           [64, 64, 20, 20]           2,048\n",
      "           ConvBN-20           [64, 64, 20, 20]               0\n",
      "             ReLU-21           [64, 64, 20, 20]               0\n",
      "           Conv2d-22           [64, 64, 18, 18]             576\n",
      "      BatchNorm2d-23           [64, 64, 18, 18]             128\n",
      "           Conv2d-24           [64, 64, 18, 18]           4,096\n",
      "           ConvBN-25           [64, 64, 18, 18]               0\n",
      "             ReLU-26           [64, 64, 18, 18]               0\n",
      "           Conv2d-27           [64, 64, 16, 16]             576\n",
      "      BatchNorm2d-28           [64, 64, 16, 16]             128\n",
      "           Conv2d-29           [64, 64, 16, 16]           4,096\n",
      "           ConvBN-30           [64, 64, 16, 16]               0\n",
      "             ReLU-31           [64, 64, 16, 16]               0\n",
      "        MaxPool2d-32             [64, 64, 8, 8]               0\n",
      "           Linear-33                 [64, 1024]       4,194,304\n",
      "      BatchNorm1d-34                 [64, 1024]           2,048\n",
      "             ReLU-35                 [64, 1024]               0\n",
      "           Linear-36                 [64, 1024]       1,048,576\n",
      "      BatchNorm1d-37                 [64, 1024]           2,048\n",
      "             ReLU-38                 [64, 1024]               0\n",
      "           Linear-39                 [64, 1024]       1,048,576\n",
      "      BatchNorm1d-40                 [64, 1024]           2,048\n",
      "             ReLU-41                 [64, 1024]               0\n",
      "           Linear-42                 [64, 1024]       1,048,576\n",
      "      BatchNorm1d-43                 [64, 1024]           2,048\n",
      "             ReLU-44                 [64, 1024]               0\n",
      "           Linear-45                  [64, 256]         262,144\n",
      "      BatchNorm1d-46                  [64, 256]             512\n",
      "             ReLU-47                  [64, 256]               0\n",
      "           Linear-48                   [64, 64]          16,384\n",
      "      BatchNorm1d-49                   [64, 64]             128\n",
      "             ReLU-50                   [64, 64]               0\n",
      "           Linear-51                    [64, 7]             448\n",
      "      BatchNorm1d-52                    [64, 7]              14\n",
      "================================================================\n",
      "Total params: 7,642,864\n",
      "Trainable params: 7,642,864\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.66\n",
      "Forward/backward pass size (MB): 594.73\n",
      "Params size (MB): 29.16\n",
      "Estimated Total Size (MB): 627.54\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "model_for_summary = UrbanGreenRegression()\n",
    "model_for_summary.to(device)\n",
    "summary(model_for_summary, input_size=(6,50,50), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Patches : 11520\n",
      "Validating Patches : 2880\n",
      "Epoch 0/2\n",
      "----------\n",
      "Valid loss: 0.032009559528281294 | Train loss: 0.04663574189180508\n",
      "Epoch 1/2\n",
      "----------\n",
      "Valid loss: 0.02846956524687509 | Train loss: 0.027796729574523244\n",
      "Epoch 2/2\n",
      "----------\n",
      "Valid loss: 0.02589251849955569 | Train loss: 0.02079458447891132\n",
      "Best loss: 0.025893, in Epoch #002\n",
      "Model information is saved in /home/bcyoon/Byeongchan/Data/N12/Model/Segmentation/Regression/2022.7.19/temp/13:43_temp.zip\n"
     ]
    },
    {
     "ename": "RasterioIOError",
     "evalue": ": No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32mrasterio/_base.pyx\u001b[0m in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mrasterio/_shim.pyx\u001b[0m in \u001b[0;36mrasterio._shim.open_dataset\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mrasterio/_err.pyx\u001b[0m in \u001b[0;36mrasterio._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: : No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRasterioIOError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25442/441733984.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moptimizer2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscheduler2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mbest_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataloaders_NON_OHE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/home/bcyoon/Byeongchan/Data/N12/Model/Segmentation/Regression/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'temp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_25442/2572862183.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, criterion, optimizer, scheduler, device, num_epochs, train_rate, batch_size, path, description, reference_data)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'{now.year}.{now.month}.{now.day}/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'{description}/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'tmp/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'{0:0=2d}.pth'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mresult_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Prediction'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreference_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model result is saved in '\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mresult_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_25442/2872442810.py\u001b[0m in \u001b[0;36msave_result\u001b[0;34m(model, dataloader, path, description, reference_data, patch_size, now)\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mprediction_expanded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mreference_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mlayer_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tt/lib/python3.7/site-packages/rasterio/env.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0menv_ctor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tt/lib/python3.7/site-packages/rasterio/__init__.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, width, height, count, crs, transform, dtype, nodata, sharing, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;31m# None.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatasetReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msharing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"r+\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             s = get_writer_for_path(path, driver=driver)(\n",
      "\u001b[0;32mrasterio/_base.pyx\u001b[0m in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRasterioIOError\u001b[0m: : No such file or directory"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2 = UrbanGreenRegression()\n",
    "criterion2 = torch.nn.MSELoss(reduction='mean')\n",
    "optimizer2 = torch.optim.SGD(model2.parameters(), lr=0.01, momentum=0.9)\n",
    "scheduler2 = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer2, 'min', patience=5, factor=0.75)\n",
    "best_model_path = train_model(model2, Dataloaders_NON_OHE, criterion2, optimizer2, scheduler2, device, num_epochs=3, batch_size=batch_size, path='/home/bcyoon/Byeongchan/Data/N12/Model/Segmentation/Regression/', description='temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UrbanGreenSegmentation(pl.LightningModule):\n",
    "    def __init__(self, rotate_training_data : bool = False, train_ratio : float = 0.8, patch_size : int = 100, batch_size : int = 16):\n",
    "        super(UrbanGreenSegmentation, self).__init__()\n",
    "        raw_data_array, raw_target_array = prepare_raw_files(one_hot_encode=True)\n",
    "        _, raw_target_array_Reg = prepare_raw_files(one_hot_encode=False)\n",
    "        self.batch_size = batch_size\n",
    "        self.Datasets_Seg = {\n",
    "            'Train' : TrainDataset2(raw_data_array, raw_target_array, patch_size = patch_size, rotate = rotate_training_data, train_ratio = train_ratio, one_hot_encoding = True),\n",
    "            'Validation' : TrainDataset2(raw_data_array, raw_target_array, patch_size = patch_size, is_validating = True, rotate = rotate_training_data, train_ratio = train_ratio, one_hot_encoding = True),\n",
    "            'Prediction' : TrainDataset2(raw_data_array, raw_target_array, patch_size = patch_size, is_evaluating = True, train_ratio = train_ratio, one_hot_encoding = True)\n",
    "        }\n",
    "        self.Datasets_Reg = {\n",
    "            'Train' : TrainDataset2(raw_data_array, raw_target_array_Reg, patch_size = patch_size, rotate = rotate_training_data, train_ratio = train_ratio, one_hot_encode=False),\n",
    "            'Validation' : TrainDataset2(raw_data_array, raw_target_array_Reg, patch_size = patch_size, is_validating = True, rotate = rotate_training_data, train_ratio = train_ratio, one_hot_encode=False),\n",
    "            'Prediction' : TrainDataset2(raw_data_array, raw_target_array_Reg, patch_size = patch_size, is_evaluating = True, train_ratio = train_ratio, one_hot_encode=False)\n",
    "        }\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        pass\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        pass\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        pass\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        train_optimizer = torch.optim.Adam(self.parameters(), lr=0.02)\n",
    "        train_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(train_optimizer, T_max=10)\n",
    "        return [train_optimizer], [train_scheduler]\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.Datasets['Train'], batch_size = self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.Datasets['Validation'], batch_size = self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.Datasets['Prediction'], batch_size = self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('tt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bef1a0741f78125b97ca6015f4b21165d553afbb2c419d3dfb1350931d81372"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

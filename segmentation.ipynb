{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import Type\n",
    "from torch import nn\n",
    "from torch.optim import optimizer\n",
    "import rasterio\n",
    "import zipfile\n",
    "from matplotlib import pyplot as plt\n",
    "import datetime\n",
    "from torchvision import transforms as transforms\n",
    "import shutil\n",
    "import torchmetrics\n",
    "import os\n",
    "import pytorch_lightning as pl\n",
    "import sklearn\n",
    "from torch.nn import functional as F\n",
    "import tqdm\n",
    "\n",
    "# --- GPU selection --- #\n",
    "gpus = 7 # slot number (e.g., 3), no gpu use -> write just ' '\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpus)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax(array : Type[np.ndarray], dim = 0):\n",
    "    min = np.min(array, axis=dim)\n",
    "    max = np.max(array, axis=dim)\n",
    "    array = (array-min)/(max-min)\n",
    "    return array\n",
    "\n",
    "def log_minmax(array : Type[np.ndarray], dim = 0):\n",
    "    min = array.min()\n",
    "    array = array - min + 1\n",
    "    array = np.log(array)\n",
    "    max = array.max()\n",
    "    array = (array)/(max)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result(model: Type[nn.Module], dataloader : Type[DataLoader], path:str, description:str = '', reference_data:str = '', patch_size:int = 60, now = datetime.datetime.now()):\n",
    "    best_model = model\n",
    "    os.makedirs(os.path.join(path,f'{now.year}.{now.month}.{now.day}/', f'{description}/','tmp/'), exist_ok=True)\n",
    "    zipped_results = zipfile.ZipFile(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','RESULT_{0:0=2d}:{1:0=2d}'.format(now.hour, now.minute)+f'_{description}.zip'), 'w')\n",
    "    prediction = np.zeros((2400//patch_size,2400//patch_size,7))\n",
    "\n",
    "    with tqdm.tqdm(enumerate(dataloader)) as data_pbar:\n",
    "        data_pbar.set_description('Predicting...')\n",
    "        for i, (data, index_OHE, index) in data_pbar:\n",
    "            prediction[i, :, :] = best_model(data).detach().numpy()\n",
    "\n",
    "    \n",
    "\n",
    "    prediction_expanded = np.zeros((7,2400,2400))\n",
    "    for i in range(2400//patch_size):\n",
    "        for j in range(2400//patch_size):\n",
    "            for k in range(7):\n",
    "                prediction_expanded[k,i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size] = prediction[i,j,k]\n",
    "\n",
    "    reference_image = rasterio.open(reference_data)\n",
    "    layer_index = [1,2,7,8,9,10,11]\n",
    "\n",
    "    with tqdm.trange(prediction_expanded.shape[0]) as write_pbar:\n",
    "        write_pbar.set_description('Writing data')\n",
    "        for i in write_pbar:\n",
    "            #print('a') \n",
    "            processed_tiff = rasterio.open(\n",
    "                os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/', 'tmp/', f'Result_{layer_index[i]}_{description}.tif'),\n",
    "                'w',\n",
    "                driver='GTiff',\n",
    "                height=prediction_expanded.shape[1],\n",
    "                width=prediction_expanded.shape[2],\n",
    "                count=1,\n",
    "                dtype=prediction_expanded.dtype,\n",
    "                crs=reference_image.crs,\n",
    "                transform=reference_image.transform,\n",
    "            )\n",
    "            #print('b')\n",
    "            processed_tiff.write(prediction_expanded[i,:,:],1)\n",
    "            processed_tiff.close()\n",
    "            #print('c')\n",
    "            zipped_results.write(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/', 'tmp/', f'Result_{layer_index[i]}_{description}.tif'), f'Result_{layer_index[i]}_{description}.tif')\n",
    "\n",
    "    zipped_results.close()\n",
    "    return os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','RESULT_{0:0=2d}:{1:0=2d}'.format(now.hour, now.minute)+f'_{description}.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, scheduler, device, num_epochs=13, train_rate: float = 0.8, batch_size: int = 60, path:str = '../Data/N12/Model/', description:str = 'no_description', reference_data:str = ''): \n",
    "    train_loss_history = []\n",
    "    valid_loss_history = []\n",
    "\n",
    "    patch_size = dataloaders['Train'].dataset.data.shape[-1]\n",
    "    training_patches = len(dataloaders['Train'].dataset)\n",
    "    validating_patches = len(dataloaders['Validation'].dataset)\n",
    "    print(f'Training Patches : {training_patches}\\nValidating Patches : {validating_patches}')\n",
    "\n",
    "    best_model_epoch = 0\n",
    "    least_valid_loss = 100\n",
    "    now = datetime.datetime.now()\n",
    "    os.makedirs(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/', 'tmp/'), exist_ok=True)\n",
    "    zipped_model = zipfile.ZipFile(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/', '{0:0=2d}:{1:0=2d}'.format(now.hour, now.minute)+f'_{description}'+'.zip'), 'w')\n",
    "    \n",
    "    epoch_range = tqdm.trange(num_epochs)\n",
    "    for epoch in epoch_range:\n",
    "\n",
    "        train_running_loss = 0.0\n",
    "        valid_running_loss = 0.0\n",
    "\n",
    "        epoch_range.set_description(f'EPOCH #{epoch}')\n",
    "        \n",
    "\n",
    "        for state in ['Train', 'Validation']:\n",
    "            #pbar = tqdm.tqdm(dataloaders[state])\n",
    "            for inputs, labels_OHE, labels in dataloaders[state]:\n",
    "                \n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                model.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                if state == 'Train':\n",
    "                    model.train()\n",
    "                    train_loss = criterion(outputs, labels)\n",
    "                    train_loss.backward()\n",
    "                    train_running_loss += train_loss.item() * inputs.size(0)\n",
    "                    #pbar.set_description('Train')\n",
    "                \n",
    "                if state == 'Validation':\n",
    "                    model.eval()\n",
    "                    valid_loss = criterion(outputs, labels)\n",
    "                    valid_running_loss += valid_loss.item() * inputs.size(0)\n",
    "                    #pbar.set_description('Valid')\n",
    "\n",
    "                optimizer.step()\n",
    "                #valid_running_similarity += metric(outputs, labels)\n",
    "                #print('validating')\n",
    "                \n",
    "                #print(f'{i}th batch')\n",
    "            #pbar.clear()\n",
    "            \n",
    "        epoch_range.refresh()\n",
    "\n",
    "        \n",
    "        #print(f'Memory after a training : {torch.cuda.memory_allocated()/1024/1024}')\n",
    "\n",
    "        epoch_train_loss = train_running_loss / training_patches\n",
    "        epoch_valid_loss = valid_running_loss / validating_patches\n",
    "        scheduler.step(epoch_valid_loss)\n",
    "\n",
    "        #print(f'Valid loss: {epoch_valid_loss} | Train loss: {epoch_train_loss}')\n",
    "\n",
    "\n",
    "        if epoch_valid_loss < least_valid_loss:\n",
    "            least_valid_loss = epoch_valid_loss\n",
    "            best_model_epoch = epoch\n",
    "\n",
    "        train_loss_history.append(epoch_train_loss)      \n",
    "        valid_loss_history.append(epoch_valid_loss)\n",
    "\n",
    "        torch.save(model.state_dict(), os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','tmp/', '{0:0=2d}.pth'.format(epoch)))\n",
    "        zipped_model.write(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','tmp/', '{0:0=2d}.pth'.format(epoch)))\n",
    "\n",
    "    plt.figure(figsize=(20,8))\n",
    "    plt.plot(train_loss_history, 'r-')\n",
    "    plt.plot(valid_loss_history, 'bo')\n",
    "    plt.savefig(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','tmp/', 'Tendency.png'), dpi=300)\n",
    "    zipped_model.write(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','tmp/', 'Tendency.png'))\n",
    "    zipped_model.writestr('README.txt', f'{description}\\nThe best Model : #{best_model_epoch}th model with loss {least_valid_loss}\\nOptimizer : {optimizer}\\nLoss function : {criterion}\\nBatch size : {batch_size}\\nScheduler : {scheduler}\\nPatch size : {patch_size}\\nTotal epochs : {num_epochs}\\nModel information :\\n{model.modules}')\n",
    "    \n",
    "    print('Best loss: {:4f}, in Epoch #{:0=3d}'.format(least_valid_loss, best_model_epoch))    \n",
    "    zipped_model.close()\n",
    "    shutil.copy(src=os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/', 'tmp/', '{0:0=2d}.pth'.format(epoch)), dst=os.path.join(path,f'{now.year}.{now.month}.{now.day}/', 'Best_Model_Parameters_of_{0:0=2d}:{1:0=2d}'.format(now.hour, now.minute)+f'_{description}'+'.pth'))\n",
    "    print('Model information is saved in '+os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/', '{0:0=2d}:{1:0=2d}'.format(now.hour, now.minute)+f'_{description}'+'.zip'))\n",
    "\n",
    "    model.load_state_dict(torch.load(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','tmp/', '{0:0=2d}.pth'.format(best_model_epoch))))\n",
    "    result_path = save_result(model = model.to('cpu'), dataloader=dataloaders['Prediction'], path=path, description=description, reference_data=reference_data, patch_size=patch_size, now=now)\n",
    "    print('Model result is saved in '+ result_path)\n",
    "    \n",
    "    shutil.rmtree(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','tmp/'))\n",
    "    best_model_path = os.path.join(path,f'{now.year}.{now.month}.{now.day}/', 'Best_Model_Parameters_of_{0:0=2d}:{1:0=2d}'.format(now.hour, now.minute)+f'_{description}'+'.pth')\n",
    "    return best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_raw_files(region:str):\n",
    "    if (os.path.exists(f'../Data/{region}/np/train_array.npy') and os.path.exists(f'../Data/{region}/np/target_array_OHE.npy')) and (os.path.exists(f'../Data/{region}/np/target_array_RAW.npy')):\n",
    "        print('Preexisting Data Found. Loading...')\n",
    "        train_array = np.load(f'../Data/{region}/np/train_array.npy')\n",
    "        target_array_OHE = np.load(f'../Data/{region}/np/target_array_OHE.npy')\n",
    "        target_array = np.load(f'../Data/{region}/np/target_array_RAW.npy')\n",
    "    else:\n",
    "        print('No Data Found. Loading from Raw Data')\n",
    "        lidar_image = rasterio.open(f'../Data/{region}/{region}_lidar.tif').read()\n",
    "        lidar_array = np.array(lidar_image)\n",
    "        lidar_array = log_minmax(lidar_array, dim=(0,1))\n",
    "\n",
    "        lidar_1n_image = rasterio.open(f'../Data/{region}/{region}_lidar_1n.tif').read()\n",
    "        lidar_1n_array = np.array(lidar_1n_image)\n",
    "        lidar_1n_array = log_minmax(lidar_1n_array, dim=(0,1))\n",
    "\n",
    "        lidar_nt_image = rasterio.open(f'../Data/{region}/{region}_lidar_nt.tif').read()\n",
    "        lidar_nt_array = np.array(lidar_nt_image)\n",
    "        lidar_nt_array = log_minmax(lidar_nt_array, dim=(0,1))\n",
    "\n",
    "        RGB2020_image = rasterio.open(f'../Data/{region}/{region}_RGB2020.tif').read()\n",
    "        RGB2020_array = np.array(RGB2020_image)\n",
    "\n",
    "        train_array = np.stack([lidar_array, lidar_1n_array, lidar_nt_array]).squeeze()\n",
    "        train_array = np.concatenate((train_array,RGB2020_array))\n",
    "        target_image = rasterio.open(f'../Data/{region}/{region}_newlc.tif').read()\n",
    "        target_array = np.array(target_image, dtype=int).squeeze()\n",
    "        target_array = np.where(target_array == 1, 0, target_array)\n",
    "        target_array = np.where(target_array == 2, 1, target_array)\n",
    "        target_array = np.where(target_array == 7, 2, target_array)\n",
    "        target_array = np.where(target_array == 8, 3, target_array)\n",
    "        target_array = np.where(target_array == 9, 4, target_array)\n",
    "        target_array = np.where(target_array == 10, 5, target_array)\n",
    "        target_array = np.where(target_array == 11, 6, target_array)\n",
    "\n",
    "        target_array_OHE = np.zeros(shape=(7,2400,2400))\n",
    "        num = np.unique(target_array)\n",
    "\n",
    "        num = max(num.shape[0],7)\n",
    "        encoded_target_array = np.eye(num)[target_array]\n",
    "        for i in range(encoded_target_array.shape[-1]):\n",
    "            target_array_OHE[i,:,:]=encoded_target_array[:,:,i]\n",
    "        \n",
    "        os.makedirs(f'../Data/{region}/np', exist_ok=True)\n",
    "        np.save(f'../Data/{region}/np/train_array.npy', train_array)\n",
    "        np.save(f'../Data/{region}/np/target_array_RAW.npy', target_array)\n",
    "        np.save(f'../Data/{region}/np/target_array_OHE.npy', target_array_OHE)\n",
    "\n",
    "    return train_array, target_array.astype(int), target_array_OHE.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset2(Dataset):\n",
    "    def __init__(self, data_array : Type[np.ndarray], target_array_OHE : Type[np.ndarray], target_array_RAW : Type[np.ndarray], patch_size : int, is_evaluating : bool = False, is_validating : bool = False, rotate : bool = False, train_ratio : float = 0.8):\n",
    "        self.is_validating = is_validating\n",
    "        self.is_evaluating = is_evaluating\n",
    "        seed = 386579\n",
    "\n",
    "        #print(f'Data shape: {data_array.shape} | Target shape: {target_array.shape}')\n",
    "\n",
    "        self.data = np.zeros(((data_array.shape[1]//patch_size) * (data_array.shape[2]//patch_size), data_array.shape[0], patch_size, patch_size))\n",
    "\n",
    "        for i in range(0,data_array.shape[1]//patch_size):\n",
    "            for j in range(0,data_array.shape[2]//patch_size):\n",
    "                self.data[data_array.shape[1]//patch_size*i+j,:,:,:] = data_array[:,i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size]\n",
    "\n",
    "        self.label_OHE = np.zeros(((data_array.shape[1]//patch_size) * (data_array.shape[2]//patch_size), target_array_OHE.shape[0] ,patch_size, patch_size), dtype=float)\n",
    "        for k in range(0,data_array.shape[1]//patch_size):\n",
    "            for l in range(0,data_array.shape[2]//patch_size):\n",
    "                self.label_OHE[data_array.shape[1]//patch_size*k+l,:,:,:] = target_array_OHE[:,i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size]\n",
    "\n",
    "        self.label_RAW = np.zeros(((data_array.shape[1]//patch_size) * (data_array.shape[2]//patch_size),data_array.shape[0]+1))\n",
    "        for k in range(0,data_array.shape[1]//patch_size):\n",
    "            for l in range(0,data_array.shape[2]//patch_size):\n",
    "                self.label_RAW[data_array.shape[1]//patch_size*k+l,:] = np.bincount(target_array_RAW[k*patch_size:(k+1)*patch_size, l*patch_size:(l+1)*patch_size].reshape(-1), minlength=7)/(patch_size*patch_size)\n",
    "\n",
    "\n",
    "        if not is_evaluating:\n",
    "            if rotate:\n",
    "                for i in range(2):\n",
    "                    rotated_data = np.rot90(self.data, k=i+1, axes=(-2, -1))\n",
    "                    self.data = np.concatenate((self.data, rotated_data), axis=0)\n",
    "                    rotated_label_OHE = np.rot90(self.label_OHE, k=i+1, axes=(-2, -1))\n",
    "                    rotated_label_RAW = self.label_RAW\n",
    "                    self.label_OHE = np.concatenate((self.label_OHE, rotated_label_OHE), axis=0)\n",
    "                    self.label_RAW = np.concatenate((self.label_RAW, rotated_label_RAW), axis=0)\n",
    "\n",
    "        train_size = int(self.data.shape[0]*train_ratio)\n",
    "        index_array = np.random.RandomState(seed=seed).permutation(self.data.shape[0])\n",
    "        self.train_index = index_array[0:train_size]\n",
    "        self.valid_index = index_array[train_size:index_array.shape[0]]\n",
    "        \n",
    "        self.data = torch.as_tensor(self.data).float()\n",
    "        self.label_OHE = torch.as_tensor(self.label_OHE).float()\n",
    "        self.label_RAW = torch.as_tensor(self.label_RAW).float()\n",
    "\n",
    "        self.data[:,3:6,:,:] = self.data[:,3:6,:,:]/255\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.is_evaluating:\n",
    "            return self.data.shape[0]\n",
    "\n",
    "        if self.is_validating:\n",
    "            return self.valid_index.shape[0]\n",
    "        else:\n",
    "            return self.train_index.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_evaluating:\n",
    "            sample = torch.as_tensor(self.data[idx,:,:,:]).float()\n",
    "            label_OHE = torch.as_tensor(self.label_OHE[idx,:]).float()\n",
    "            label_RAW = torch.as_tensor(self.label_RAW[idx,:]).float()\n",
    "            return sample, label_OHE, label_RAW\n",
    "        \n",
    "        if self.is_validating:\n",
    "            sample = torch.as_tensor(self.data[self.valid_index[idx],:,:,:]).float()\n",
    "            label_OHE = torch.as_tensor(self.label_OHE[self.valid_index[idx],:]).float()\n",
    "            label_RAW = torch.as_tensor(self.label_RAW[self.valid_index[idx],:]).float()\n",
    "        else:\n",
    "            sample = torch.as_tensor(self.data[self.train_index[idx],:,:,:]).float()\n",
    "            label_OHE = torch.as_tensor(self.label_OHE[self.train_index[idx],:]).float()\n",
    "            label_RAW = torch.as_tensor(self.label_RAW[self.train_index[idx],:]).float()\n",
    "\n",
    "        return sample, label_OHE, label_RAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_padding(inputs, kernel_size, dilation):\n",
    "    kernel_size_effective = kernel_size + (kernel_size - 1) * (dilation - 1)\n",
    "    pad_total = kernel_size_effective - 1\n",
    "    pad_beg = pad_total // 2\n",
    "    pad_end = pad_total - pad_beg\n",
    "    padded_inputs = F.pad(inputs, (pad_beg, pad_end, pad_beg, pad_end))\n",
    "    return padded_inputs\n",
    "\n",
    "\n",
    "class SeparableConv2d(nn.Module):\n",
    "    def __init__(self, inplanes, planes, kernel_size=3, stride=1, dilation=1, bias=False, BatchNorm=None):\n",
    "        super(SeparableConv2d, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(inplanes, inplanes, kernel_size, stride, 0, dilation,\n",
    "                               groups=inplanes, bias=bias)\n",
    "        self.bn = BatchNorm(inplanes)\n",
    "        self.pointwise = nn.Conv2d(inplanes, planes, 1, 1, 0, 1, 1, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = fixed_padding(x, self.conv1.kernel_size[0], dilation=self.conv1.dilation[0])\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBN(nn.Module):\n",
    "    def __init__(self, C_in, C_out, kernel_size, stride, dilation = 1, affine=True, fix_padding = False):\n",
    "        super(ConvBN, self).__init__()\n",
    "        self.fix_padding = fix_padding\n",
    "        self.conv2d = nn.Conv2d(C_in, C_in, kernel_size=kernel_size, stride=stride, groups=C_in, bias=False, dilation=dilation)\n",
    "        self.pointwise = nn.Conv2d(C_in, C_out, kernel_size=1, padding=0, bias=False)\n",
    "        self.batchnorm = nn.BatchNorm2d(C_in, affine=affine)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.fix_padding:\n",
    "           x = fixed_padding(x, self.conv2d.kernel_size[0], dilation=self.conv2d.dilation[0])\n",
    "        x = self.conv2d(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UrbanGreenRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UrbanGreenRegression, self).__init__()\n",
    "        '''self.conv_block_1 = nn.Sequential(\n",
    "            ConvBN(6,32,3,1),#98\n",
    "            nn.ReLU(),\n",
    "            ConvBN(32,32,3,1),#96\n",
    "            nn.ReLU(),\n",
    "            ConvBN(32,32,3,1),#94\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)#47\n",
    "        )\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            ConvBN(32,64,3,1),#45\n",
    "            nn.ReLU(),\n",
    "            ConvBN(64,64,3,1),#43\n",
    "            nn.ReLU(),\n",
    "            ConvBN(64,64,3,1),#41\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)#8\n",
    "        )'''\n",
    "\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(6,1,kernel_size=1,stride=1),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc_block_1 = nn.Sequential(\n",
    "            nn.Linear(in_features=100, out_features=256, bias=False),\n",
    "            nn.BatchNorm1d(num_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=256, bias=False),\n",
    "            nn.BatchNorm1d(num_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=256, bias=False),\n",
    "            nn.BatchNorm1d(num_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=256, bias=False),\n",
    "            nn.BatchNorm1d(num_features=256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc_block_2 = nn.Sequential(\n",
    "            nn.Linear(in_features=256, out_features=64, bias=False),\n",
    "            nn.BatchNorm1d(num_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=64, bias=False),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,7, False),\n",
    "            nn.BatchNorm1d(7)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv_block_1(x)\n",
    "        #x = self.conv_block_2(x)\n",
    "        #print(x.shape)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        #print(x.shape)\n",
    "        x = self.fc_block_1(x)\n",
    "        x = self.fc_block_2(x)\n",
    "        return torch.softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preexisting Data Found. Loading...\n"
     ]
    }
   ],
   "source": [
    "raw_data_array ,raw_target_array, OHE_target_array = prepare_raw_files('N12')\n",
    "batch_size = 4\n",
    "patch_size = 100\n",
    "train_ratio = 0.8\n",
    "rotate_training_data = False\n",
    "Datasets_NON_OHE = {\n",
    "    'Train' : TrainDataset2(raw_data_array, OHE_target_array, raw_target_array, patch_size = patch_size, rotate = rotate_training_data, train_ratio = train_ratio),\n",
    "    'Validation' : TrainDataset2(raw_data_array, OHE_target_array, raw_target_array, patch_size = patch_size, is_validating = True, rotate = rotate_training_data, train_ratio = train_ratio),\n",
    "    'Prediction' : TrainDataset2(raw_data_array, OHE_target_array, raw_target_array, patch_size = patch_size, is_evaluating = True, train_ratio = train_ratio)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataloaders_NON_OHE = {\n",
    "    'Train' : DataLoader(Datasets_NON_OHE['Train'], batch_size=batch_size),\n",
    "    'Validation' : DataLoader(Datasets_NON_OHE['Validation'], batch_size=batch_size),\n",
    "    'Prediction' : DataLoader(Datasets_NON_OHE['Prediction'], batch_size=2400//patch_size)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [64, 1, 10, 10]               7\n",
      "       BatchNorm2d-2            [64, 1, 10, 10]               2\n",
      "              ReLU-3            [64, 1, 10, 10]               0\n",
      "            Linear-4                  [64, 256]          25,600\n",
      "       BatchNorm1d-5                  [64, 256]             512\n",
      "              ReLU-6                  [64, 256]               0\n",
      "            Linear-7                  [64, 256]          65,536\n",
      "       BatchNorm1d-8                  [64, 256]             512\n",
      "              ReLU-9                  [64, 256]               0\n",
      "           Linear-10                  [64, 256]          65,536\n",
      "      BatchNorm1d-11                  [64, 256]             512\n",
      "             ReLU-12                  [64, 256]               0\n",
      "           Linear-13                  [64, 256]          65,536\n",
      "      BatchNorm1d-14                  [64, 256]             512\n",
      "             ReLU-15                  [64, 256]               0\n",
      "           Linear-16                   [64, 64]          16,384\n",
      "      BatchNorm1d-17                   [64, 64]             128\n",
      "             ReLU-18                   [64, 64]               0\n",
      "           Linear-19                   [64, 64]           4,096\n",
      "      BatchNorm1d-20                   [64, 64]             128\n",
      "             ReLU-21                   [64, 64]               0\n",
      "           Linear-22                    [64, 7]             448\n",
      "      BatchNorm1d-23                    [64, 7]              14\n",
      "================================================================\n",
      "Total params: 245,463\n",
      "Trainable params: 245,463\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.15\n",
      "Forward/backward pass size (MB): 1.84\n",
      "Params size (MB): 0.94\n",
      "Estimated Total Size (MB): 2.92\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "model_for_summary = UrbanGreenRegression()\n",
    "model_for_summary.to(device)\n",
    "summary(model_for_summary, input_size=(6,10,10), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Patches : 460\n",
      "Validating Patches : 116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH #0:   0%|          | 0/300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [4 x 10000], m2: [100 x 256] at /tmp/pip-req-build-4baxydiv/aten/src/THC/generic/THCTensorMathBlas.cu:290",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10158/563077844.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moptimizer2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscheduler2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mbest_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataloaders_NON_OHE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/home/bcyoon/Byeongchan/Data/N12/Model/Segmentation/Regression/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'patch_10_pointwiseConv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_10158/2890456484.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, criterion, optimizer, scheduler, device, num_epochs, train_rate, batch_size, path, description, reference_data)\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tt/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_10158/2222336999.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m#print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_block_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_block_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tt/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tt/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tt/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tt/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tt/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [4 x 10000], m2: [100 x 256] at /tmp/pip-req-build-4baxydiv/aten/src/THC/generic/THCTensorMathBlas.cu:290"
     ]
    }
   ],
   "source": [
    "model2 = UrbanGreenRegression()\n",
    "criterion2 = torch.nn.MSELoss(reduction='mean')\n",
    "optimizer2 = torch.optim.SGD(model2.parameters(), lr=0.01, momentum=0.9)\n",
    "scheduler2 = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer2, 'min', patience=5, factor=0.75)\n",
    "best_model_path = train_model(model2, Dataloaders_NON_OHE, criterion2, optimizer2, scheduler2, device, num_epochs=300, batch_size=batch_size, path='/home/bcyoon/Byeongchan/Data/N12/Model/Segmentation/Regression/', description='patch_10_pointwiseConv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = '/home/bcyoon/Byeongchan/Data/N12/Model/Segmentation/Regression/2022.7.26/Best_Model_Parameters_of_15:32_patch_10_pointwiseConv.pth'\n",
    "model2.load_state_dict(torch.load(best_model_path))\n",
    "result_path = save_result(model = model2.to('cpu'), dataloader=Dataloaders_NON_OHE['Prediction'], path='/home/bcyoon/Byeongchan/Data/N12/Model/Segmentation/Regression/', description='patch_10_pointwiseConv', reference_data='/home/bcyoon/Byeongchan/Data/N12/N12_lidar.tif', patch_size=patch_size, now=datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBN(nn.Module):\n",
    "    def __init__(self, Cin, Cout, kernel_size, stride=1):\n",
    "        super(ConvBN,self).__init__()\n",
    "        self.conv = nn.Conv2d(Cin, Cin, kernel_size=kernel_size, stride=stride, groups=Cin, bias=False)\n",
    "        self.batchnorm = nn.BatchNorm2d(Cin)\n",
    "        self.pointwise = nn.Conv2d(Cin, Cout, kernel_size=1, padding=0, bias=False)\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegBlock(nn.Module):\n",
    "    def __init__(self, skip:bool, in_channel:int, out_channel:int, is_last:bool = False):\n",
    "        super(SegBlock,self).__init__()\n",
    "        self.skip = skip\n",
    "        self.is_last = is_last\n",
    "        self.conv1 = ConvBN(in_channel, out_channel, kernel_size=3, stride=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = ConvBN(out_channel, out_channel, kernel_size=3, stride=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_add(skip:Type[torch.Tensor], target:Type[torch.Tensor])->torch.Tensor:\n",
    "    cropped_skip = skip[:,:,(skip.shape[-2]-target.shape[-2])//2:(skip.shape[-2]+target.shape[-2])//2,(skip.shape[-1]-target.shape[-1])//2:(skip.shape[-1]+target.shape[-1])//2]\n",
    "    return torch.cat((cropped_skip, target), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        self.enc1 = SegBlock(True, 3,64)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.enc2 = SegBlock(True, 64,128)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.enc3 = SegBlock(True, 128, 256)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.enc4 = SegBlock(True, 256, 512)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "        self.dec0 = SegBlock(False, 512, 1024)\n",
    "        self.upconv1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.dec1 = SegBlock(False,1024,512)\n",
    "        self.upconv2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec2 = SegBlock(False,512,256)\n",
    "        self.upconv3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec3 = SegBlock(False,256,128)\n",
    "        self.upconv4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec4 = SegBlock(False,128,64, is_last = True)\n",
    "\n",
    "    def forward(self,x):\n",
    "        enc1 = self.enc1(x)\n",
    "        x = self.pool1(enc1)\n",
    "        enc2 = self.enc2(x)\n",
    "        x = self.pool2(enc2)\n",
    "        enc3 = self.enc3(x)\n",
    "        x = self.pool3(enc3)\n",
    "        enc4 = self.enc4(x)\n",
    "        x = self.pool4(enc4)\n",
    "        x = self.dec0(x)\n",
    "        x = self.upconv1(x)\n",
    "        x = self.dec1(crop_add(enc4, x))\n",
    "        x = self.upconv2(x)\n",
    "        x = self.dec2(crop_add(enc3, x))\n",
    "        x = self.upconv3(x)\n",
    "        x = self.dec3(crop_add(enc2, x))\n",
    "        x = self.upconv4(x)\n",
    "        x = self.dec4(crop_add(enc1, x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mirror_extrapolate(inp:torch.Tensor, in_shape:tuple = (100,100), out_shape:tuple = (284,284)) -> torch.Tensor: # 배치 포함해서 input으로 넣어야 함\n",
    "    pad = ((out_shape[0]-in_shape[0])//2,(out_shape[0]-in_shape[0])//2,(out_shape[0]-in_shape[0])//2,(out_shape[0]-in_shape[0])//2)\n",
    "    return F.pad(inp, pad=pad, mode=\"reflect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset3(Dataset):\n",
    "    def __init__(self, data_array : Type[np.ndarray], target_array_OHE : Type[np.ndarray], target_array_RAW : Type[np.ndarray], patch_size : int, is_evaluating : bool = False, is_validating : bool = False, rotate : bool = False, train_ratio : float = 0.8):\n",
    "        self.is_validating = is_validating\n",
    "        self.is_evaluating = is_evaluating\n",
    "        seed = 386579\n",
    "\n",
    "        #print(f'Data shape: {data_array.shape} | Target shape: {target_array.shape}')\n",
    "\n",
    "        self.data = np.zeros(((data_array.shape[1]//patch_size) * (data_array.shape[2]//patch_size), data_array.shape[0], patch_size, patch_size))\n",
    "\n",
    "        for i in range(0,data_array.shape[1]//patch_size):\n",
    "            for j in range(0,data_array.shape[2]//patch_size):\n",
    "                self.data[data_array.shape[1]//patch_size*i+j,:,:,:] = data_array[:,i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size]\n",
    "\n",
    "        self.label_OHE = np.zeros(((data_array.shape[1]//patch_size) * (data_array.shape[2]//patch_size), target_array_OHE.shape[0] ,patch_size, patch_size), dtype=float)\n",
    "        for k in range(0,data_array.shape[1]//patch_size):\n",
    "            for l in range(0,data_array.shape[2]//patch_size):\n",
    "                self.label_OHE[data_array.shape[1]//patch_size*k+l,:,:,:] = target_array_OHE[:,i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size]\n",
    "\n",
    "        self.label_RAW = np.zeros(((data_array.shape[1]//patch_size) * (data_array.shape[2]//patch_size),data_array.shape[0]+1))\n",
    "        for k in range(0,data_array.shape[1]//patch_size):\n",
    "            for l in range(0,data_array.shape[2]//patch_size):\n",
    "                self.label_RAW[data_array.shape[1]//patch_size*k+l,:] = np.bincount(target_array_RAW[k*patch_size:(k+1)*patch_size, l*patch_size:(l+1)*patch_size].reshape(-1), minlength=7)/(patch_size*patch_size)\n",
    "\n",
    "\n",
    "        if not is_evaluating:\n",
    "            if rotate:\n",
    "                for i in range(2):\n",
    "                    rotated_data = np.rot90(self.data, k=i+1, axes=(-2, -1))\n",
    "                    self.data = np.concatenate((self.data, rotated_data), axis=0)\n",
    "                    rotated_label_OHE = np.rot90(self.label_OHE, k=i+1, axes=(-2, -1))\n",
    "                    rotated_label_RAW = self.label_RAW\n",
    "                    self.label_OHE = np.concatenate((self.label_OHE, rotated_label_OHE), axis=0)\n",
    "                    self.label_RAW = np.concatenate((self.label_RAW, rotated_label_RAW), axis=0)\n",
    "\n",
    "        train_size = int(self.data.shape[0]*train_ratio)\n",
    "        index_array = np.random.RandomState(seed=seed).permutation(self.data.shape[0])\n",
    "        self.train_index = index_array[0:train_size]\n",
    "        self.valid_index = index_array[train_size:index_array.shape[0]]\n",
    "        \n",
    "        self.data = torch.as_tensor(self.data).float()\n",
    "        self.data[:,3:6,:,:] = self.data[:,3:6,:,:]/255\n",
    "        self.data_seg = mirror_extrapolate(self.data).squeeze()[:,0:3,:,:]\n",
    "        self.data_reg = torch.zeros((self.data.shape[0], 100, 6, self.data.shape[-2]//10, self.data.shape[-1]//10))\n",
    "        print(self.data.shape)\n",
    "        for k in tqdm.trange(self.data.shape[0]):\n",
    "            for i in range(self.data.shape[-1]//10):\n",
    "                for j in range(self.data.shape[-2]//10):\n",
    "                    self.data_reg[k,10*i+j,:,:,:] = self.data[k,:,10*j:10*j+10, 10*i:10*i+10]\n",
    "\n",
    "\n",
    "        self.label_OHE = torch.as_tensor(self.label_OHE).float()\n",
    "        self.label_RAW = torch.as_tensor(self.label_RAW).float()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.is_evaluating:\n",
    "            return self.data.shape[0]\n",
    "\n",
    "        if self.is_validating:\n",
    "            return self.valid_index.shape[0]\n",
    "        else:\n",
    "            return self.train_index.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_evaluating:\n",
    "            data_reg = torch.as_tensor(self.data_reg[idx,:,:,:]).float()\n",
    "            data_seg = torch.as_tensor(self.data_seg[idx,:,:,:]).float()\n",
    "            label_OHE = torch.as_tensor(self.label_OHE[idx,:]).float()\n",
    "            label_RAW = torch.as_tensor(self.label_RAW[idx,:]).float()\n",
    "            return data_seg, data_reg, label_OHE, label_RAW\n",
    "        \n",
    "        if self.is_validating:\n",
    "            data_reg = torch.as_tensor(self.data_reg[self.valid_index[idx],:,:,:]).float()\n",
    "            data_seg = torch.as_tensor(self.data_seg[self.valid_index[idx],:,:,:]).float()\n",
    "            label_OHE = torch.as_tensor(self.label_OHE[self.valid_index[idx],:]).float()\n",
    "            label_RAW = torch.as_tensor(self.label_RAW[self.valid_index[idx],:]).float()\n",
    "        else:\n",
    "            data_reg = torch.as_tensor(self.data_reg[self.train_index[idx],:,:,:]).float()\n",
    "            data_seg = torch.as_tensor(self.data_seg[self.train_index[idx],:,:,:]).float()\n",
    "            label_OHE = torch.as_tensor(self.label_OHE[self.train_index[idx],:]).float()\n",
    "            label_RAW = torch.as_tensor(self.label_RAW[self.train_index[idx],:]).float()\n",
    "\n",
    "        return data_seg, data_reg, label_OHE, label_RAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_array ,raw_target_array, OHE_target_array = prepare_raw_files('N12')\n",
    "batch_size = 4\n",
    "patch_size = 100\n",
    "train_ratio = 0.8\n",
    "rotate_training_data = False\n",
    "Datasets_ver3 = {\n",
    "    'Train' : TrainDataset3(raw_data_array, OHE_target_array, raw_target_array, patch_size = patch_size, rotate = rotate_training_data, train_ratio = train_ratio),\n",
    "    'Validation' : TrainDataset3(raw_data_array, OHE_target_array, raw_target_array, patch_size = patch_size, is_validating = True, rotate = rotate_training_data, train_ratio = train_ratio),\n",
    "    'Prediction' : TrainDataset3(raw_data_array, OHE_target_array, raw_target_array, patch_size = patch_size, is_evaluating = True, train_ratio = train_ratio)\n",
    "}\n",
    "Dataloaders_ver3 = {\n",
    "    'Train' : DataLoader(Datasets_ver3['Train'], batch_size=batch_size),\n",
    "    'Validation' : DataLoader(Datasets_ver3['Validation'], batch_size=batch_size),\n",
    "    'Prediction' : DataLoader(Datasets_ver3['Prediction'], batch_size=2400//patch_size)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Splitted_Regression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Splitted_Regression, self).__init__()\n",
    "        self.regression = UrbanGreenRegression() # 4차원 텐서만 받음.\n",
    "        self.regression.load_state_dict(torch.load('/home/bcyoon/Byeongchan/Data/N12/Model/Segmentation/Regression/2022.7.26/Best_Model_Parameters_of_15:32_patch_10_pointwiseConv.pth'))\n",
    "        self.regression.to('cuda:0')\n",
    "        for param in self.regression.parameters():\n",
    "            param.requires_grad = False\n",
    "        #self.batchnorm = nn.BatchNorm2d(7)\n",
    "    def forward(self, x):\n",
    "        # x : (batch, 100, 6, 10, 10) 데이터\n",
    "        out = torch.zeros(x.shape[0],7,100)\n",
    "        out = out.to('cuda:0')\n",
    "        for i in range(x.shape[0]):\n",
    "            tmp = self.regression(x[i,:,:,:,:])\n",
    "            #print(tmp.shape)\n",
    "            out[i,:,:] = torch.transpose(tmp, 0, 1)\n",
    "        out = out.view(x.shape[0], 7, 10, 10)\n",
    "        #Bilinear Interpolation 추가할 것\n",
    "        out = F.interpolate(out, size=(100,100), mode='nearest')\n",
    "        #out = self.batchnorm(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UrbanGreenSegmentation(pl.LightningModule):\n",
    "    def __init__(self, rotate_training_data : bool = False, train_ratio : float = 0.8, patch_size : int = 100, batch_size : int = 4, region:str = 'N12'):\n",
    "        super(UrbanGreenSegmentation, self).__init__()\n",
    "        raw_data_array, OHE_target_array, raw_target_array = prepare_raw_files(region)\n",
    "        self.batch_size = batch_size\n",
    "        self.Datasets = {\n",
    "            'Train' : TrainDataset3(raw_data_array, OHE_target_array, raw_target_array, patch_size = patch_size, rotate = rotate_training_data, train_ratio = train_ratio),\n",
    "            'Validation' : TrainDataset3(raw_data_array, OHE_target_array, raw_target_array, patch_size = patch_size, is_validating = True, rotate = rotate_training_data, train_ratio = train_ratio),\n",
    "            'Prediction' : TrainDataset3(raw_data_array, OHE_target_array, raw_target_array, patch_size = patch_size, is_evaluating = True, train_ratio = train_ratio)\n",
    "        }\n",
    "\n",
    "        self.Dataloaders = {\n",
    "            'Train' : DataLoader(self.Datasets['Train'], batch_size=batch_size),\n",
    "            'Validation' : DataLoader(self.Datasets['Validation'], batch_size=batch_size),\n",
    "            'Prediction' : DataLoader(self.Datasets['Prediction'], batch_size=batch_size)\n",
    "        }\n",
    "        \n",
    "        # 3개 배치 사용시 메모리 5기가\n",
    "        # 2개 배치 사용시 메모리 3.8기가\n",
    "\n",
    "        self.unet = UNet()\n",
    "        self.regression = Splitted_Regression()\n",
    "        \n",
    "        self.fc1 = nn.Conv2d(in_channels=64, out_channels=7)\n",
    "        self.bn1 = nn.BatchNorm2d(7)\n",
    "        self.bn2 = nn.BatchNorm2d(14)\n",
    "        self.fc2 = nn.Conv2d(in_channels=14, out_channels=7)\n",
    "        self.softmax = nn.Softmax2d()\n",
    "\n",
    "    def forward(self, x_seg, x_reg):\n",
    "        x_reg = self.regression(x_reg)\n",
    "        x_seg = self.unet(x_seg)\n",
    "        x_seg = self.fc1(x_seg)\n",
    "        x_seg = self.bn1(x_seg)\n",
    "        x_seg = torch.cat((x_reg, x_seg), dim=1)\n",
    "        x_seg = self.bn2(x_seg)\n",
    "        x_seg = self.fc2(x_seg)\n",
    "        x_seg = self.softmax(x_seg)\n",
    "        return x_seg\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_seg, x_reg, y_seg, _ = batch\n",
    "        y_hat = self(x_seg, x_reg)\n",
    "        return {'loss' : F.cross_entropy(y_hat, y_seg)}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x_seg, x_reg, y_seg, _ = batch\n",
    "        y_hat = self(x_seg, x_reg)\n",
    "        return {\n",
    "            'valid_loss' : F.cross_entropy(y_hat, y_seg),\n",
    "            'y_hat' : y_hat.detach(),\n",
    "            'y' : y_seg.detach()\n",
    "        }\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        pass\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        train_optimizer = torch.optim.Adam(self.parameters(), lr=0.02)\n",
    "        train_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(train_optimizer, T_max=10)\n",
    "        return [train_optimizer], [train_scheduler]\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.Datasets['Train'], batch_size = self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.Datasets['Validation'], batch_size = self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.Datasets['Prediction'], batch_size = self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('tt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bef1a0741f78125b97ca6015f4b21165d553afbb2c419d3dfb1350931d81372"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

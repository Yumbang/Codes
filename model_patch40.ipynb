{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import Type\n",
    "from torch import nn\n",
    "from torch.optim import optimizer\n",
    "import rasterio\n",
    "import zipfile\n",
    "from matplotlib import pyplot as plt\n",
    "import datetime\n",
    "from torchvision import transforms as transforms\n",
    "import shutil\n",
    "import torchmetrics\n",
    "import os\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# --- GPU selection --- #\n",
    "gpus = 7 # slot number (e.g., 3), no gpu use -> write just ' '\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpus)\n",
    "#os.environ[\"TORCH_CUDA_ARCH_LIST\"]=\"3.5\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax(array : Type[np.ndarray], dim = 0):\n",
    "    min = np.min(array, axis=dim)\n",
    "    max = np.max(array, axis=dim)\n",
    "    array = (array-min)/(max-min)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar_image = rasterio.open('../Data/N12/N12_lidar.tif').read()\n",
    "lidar_array = np.array(lidar_image)\n",
    "lidar_array = minmax(lidar_array, dim=(0,1))\n",
    "\n",
    "lidar_1n_image = rasterio.open('../Data/N12/N12_lidar_1n.tif').read()\n",
    "lidar_1n_array = np.array(lidar_1n_image)\n",
    "lidar_1n_array = minmax(lidar_1n_array, dim=(0,1))\n",
    "\n",
    "lidar_nt_image = rasterio.open('../Data/N12/N12_lidar_nt.tif').read()\n",
    "lidar_nt_array = np.array(lidar_nt_image)\n",
    "lidar_nt_array = minmax(lidar_nt_array, dim=(0,1))\n",
    "\n",
    "RGB2020_image = rasterio.open('../Data/N12/N12_RGB2020.tif').read()\n",
    "RGB2020_array = np.array(RGB2020_image)\n",
    "train_array = np.stack([lidar_array, lidar_1n_array, lidar_nt_array]).squeeze()\n",
    "train_array = np.concatenate((train_array,RGB2020_array))\n",
    "target_image = rasterio.open('../Data/N12/N12_newlc.tif').read()\n",
    "target_array = np.array(target_image, dtype=int).squeeze()\n",
    "\n",
    "target_array = np.where(target_array == 1, 0, target_array)\n",
    "target_array = np.where(target_array == 2, 1, target_array)\n",
    "target_array = np.where(target_array == 7, 2, target_array)\n",
    "target_array = np.where(target_array == 8, 3, target_array)\n",
    "target_array = np.where(target_array == 9, 4, target_array)\n",
    "target_array = np.where(target_array == 10, 5, target_array)\n",
    "target_array = np.where(target_array == 11, 6, target_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, data_array : Type[np.ndarray], target_array : Type[np.ndarray], patch_size : int):\n",
    "        self.data = np.zeros(((data_array.shape[1]//patch_size) * (data_array.shape[2]//patch_size), data_array.shape[0], patch_size, patch_size))\n",
    "        for i in range(0,data_array.shape[1]//patch_size):\n",
    "            for j in range(0,data_array.shape[2]//patch_size):\n",
    "                self.data[data_array.shape[1]//patch_size*i+j,:,:,:] = data_array[:,i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size] #고치기\n",
    "                \n",
    "                #self.data =np.append(self.data, np.zeros(((1, data_array.shape[0], patch_size, patch_size))), axis = 0)\n",
    "                #self.data = np.concatenate(self.data, np.zeros(((1, data_array.shape[0], patch_size, patch_size))))\n",
    "\n",
    "        self.label = np.zeros(((data_array.shape[1]//patch_size) * (data_array.shape[2]//patch_size),data_array.shape[0]+1))\n",
    "        \n",
    "        for k in range(0,data_array.shape[1]//patch_size):\n",
    "            for l in range(0,data_array.shape[2]//patch_size):\n",
    "                self.label[data_array.shape[1]//patch_size*k+l,:] = np.bincount(target_array[k*patch_size:(k+1)*patch_size, l*patch_size:(l+1)*patch_size].reshape(-1), minlength=7)/(patch_size*patch_size)\n",
    "        self.data = torch.as_tensor(self.data).float()\n",
    "        self.label = torch.as_tensor(self.label).float()\n",
    "\n",
    "        self.data[:,3:6,:,:] = self.data[:,3:6,:,:]/255\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = torch.as_tensor(self.data[idx,:,:,:]).float()\n",
    "        label = torch.as_tensor(self.label[idx,:]).float()\n",
    "        return sample, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset2(Dataset):\n",
    "    def __init__(self, data_array : Type[np.ndarray], target_array : Type[np.ndarray], patch_size : int, is_evaluating : bool = False, is_validating : bool = False, rotate : bool = False, train_ratio : float = 0.8):\n",
    "        self.is_validating = is_validating\n",
    "        self.is_evaluating = is_evaluating\n",
    "        seed = 386579\n",
    "\n",
    "        self.data = np.zeros(((data_array.shape[1]//patch_size) * (data_array.shape[2]//patch_size), data_array.shape[0], patch_size, patch_size))\n",
    "\n",
    "        for i in range(0,data_array.shape[1]//patch_size):\n",
    "            for j in range(0,data_array.shape[2]//patch_size):\n",
    "                self.data[data_array.shape[1]//patch_size*i+j,:,:,:] = data_array[:,i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size]\n",
    "\n",
    "        self.label = np.zeros(((data_array.shape[1]//patch_size) * (data_array.shape[2]//patch_size),data_array.shape[0]+1))\n",
    "\n",
    "        for k in range(0,data_array.shape[1]//patch_size):\n",
    "            for l in range(0,data_array.shape[2]//patch_size):\n",
    "                self.label[data_array.shape[1]//patch_size*k+l,:] = np.bincount(target_array[k*patch_size:(k+1)*patch_size, l*patch_size:(l+1)*patch_size].reshape(-1), minlength=7)/(patch_size*patch_size)\n",
    "\n",
    "        if not is_evaluating:\n",
    "            if rotate:\n",
    "                for i in range(2):\n",
    "                    rotated_data = np.rot90(self.data, k=i+1, axes=(-2, -1))\n",
    "                    self.data = np.concatenate((self.data, rotated_data), axis=0)\n",
    "                    rotated_data = self.label\n",
    "                    self.label = np.concatenate((self.label, rotated_data), axis=0)\n",
    "                    \n",
    "                        \n",
    "                #self.data =np.append(self.data, np.zeros(((1, data_array.shape[0], patch_size, patch_size))), axis = 0)\n",
    "                #self.data = np.concatenate(self.data, np.zeros(((1, data_array.shape[0], patch_size, patch_size))))\n",
    "\n",
    "        train_size = int(self.data.shape[0]*train_ratio)\n",
    "        index_array = np.random.RandomState(seed=seed).permutation(self.data.shape[0])\n",
    "        self.train_index = index_array[0:train_size]\n",
    "        self.valid_index = index_array[train_size:index_array.shape[0]]\n",
    "        \n",
    "        self.data = torch.as_tensor(self.data).float()\n",
    "        self.label = torch.as_tensor(self.label).float()\n",
    "\n",
    "        self.data[:,3:6,:,:] = self.data[:,3:6,:,:]/255\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.is_evaluating:\n",
    "            return self.data.shape[0]\n",
    "\n",
    "        if self.is_validating:\n",
    "            return self.valid_index.shape[0]\n",
    "        else:\n",
    "            return self.train_index.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_evaluating:\n",
    "            sample = torch.as_tensor(self.data[idx,:,:,:]).float()\n",
    "            label = torch.as_tensor(self.label[idx,:]).float()\n",
    "            return sample, label\n",
    "        \n",
    "        if self.is_validating:\n",
    "            sample = torch.as_tensor(self.data[self.valid_index[idx],:,:,:]).float()\n",
    "            label = torch.as_tensor(self.label[self.valid_index[idx],:]).float()\n",
    "        else:\n",
    "            sample = torch.as_tensor(self.data[self.train_index[idx],:,:,:]).float()\n",
    "            label = torch.as_tensor(self.label[self.train_index[idx],:]).float()\n",
    "\n",
    "        return sample, label\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('tt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bef1a0741f78125b97ca6015f4b21165d553afbb2c419d3dfb1350931d81372"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

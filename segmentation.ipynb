{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import Type\n",
    "from torch import nn\n",
    "from torch.optim import optimizer\n",
    "import rasterio\n",
    "import zipfile\n",
    "from matplotlib import pyplot as plt\n",
    "import datetime\n",
    "from torchvision import transforms as transforms\n",
    "import shutil\n",
    "import torchmetrics\n",
    "import os\n",
    "import pytorch_lightning as pl\n",
    "import sklearn\n",
    "from torch.nn import functional as F\n",
    "import tqdm\n",
    "\n",
    "# --- GPU selection --- #\n",
    "gpus = 7 # slot number (e.g., 3), no gpu use -> write just ' '\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpus)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax(array : Type[np.ndarray], dim = 0):\n",
    "    min = np.min(array, axis=dim)\n",
    "    max = np.max(array, axis=dim)\n",
    "    array = (array-min)/(max-min)\n",
    "    return array\n",
    "\n",
    "def log_minmax(array : Type[np.ndarray], dim = 0):\n",
    "    min = np.min(array, axis=dim)\n",
    "    array = array - min + 1\n",
    "    array = np.log(array)\n",
    "    max = np.max(array, axis=dim)\n",
    "    array = (array)/(max)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result(model: Type[nn.Module], dataloader : Type[DataLoader], path:str, description:str = '', reference_data:str = '', patch_size:int = 60, now = datetime.datetime.now()):\n",
    "    best_model = model\n",
    "    os.makedirs(os.path.join(path,f'{now.year}.{now.month}.{now.day}/', f'{description}/','tmp/'), exist_ok=True)\n",
    "    zipped_results = zipfile.ZipFile(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','RESULT_{0:0=2d}:{1:0=2d}'.format(now.hour, now.minute)+f'_{description}.zip'), 'w')\n",
    "    prediction = np.zeros((2400//patch_size,2400//patch_size,7))\n",
    "\n",
    "    with tqdm.tqdm(enumerate(dataloader)) as data_pbar:\n",
    "        data_pbar.set_description('Predicting...')\n",
    "        for i, (data, index_OHE, index) in data_pbar:\n",
    "            prediction[i, :, :] = best_model(data).detach().numpy()\n",
    "\n",
    "    \n",
    "\n",
    "    prediction_expanded = np.zeros((7,2400,2400))\n",
    "    for i in range(2400//patch_size):\n",
    "        for j in range(2400//patch_size):\n",
    "            for k in range(7):\n",
    "                prediction_expanded[k,i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size] = prediction[i,j,k]\n",
    "\n",
    "    reference_image = rasterio.open(reference_data)\n",
    "    layer_index = [1,2,7,8,9,10,11]\n",
    "\n",
    "    with tqdm.trange(prediction_expanded.shape[0]) as write_pbar:\n",
    "        write_pbar.set_description('Writing data')\n",
    "        for i in write_pbar:\n",
    "            #print('a') \n",
    "            processed_tiff = rasterio.open(\n",
    "                os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/', 'tmp/', f'Result_{layer_index[i]}_{description}.tif'),\n",
    "                'w',\n",
    "                driver='GTiff',\n",
    "                height=prediction_expanded.shape[1],\n",
    "                width=prediction_expanded.shape[2],\n",
    "                count=1,\n",
    "                dtype=prediction_expanded.dtype,\n",
    "                crs=reference_image.crs,\n",
    "                transform=reference_image.transform,\n",
    "            )\n",
    "            #print('b')\n",
    "            processed_tiff.write(prediction_expanded[i,:,:],1)\n",
    "            processed_tiff.close()\n",
    "            #print('c')\n",
    "            zipped_results.write(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/', 'tmp/', f'Result_{layer_index[i]}_{description}.tif'), f'Result_{layer_index[i]}_{description}.tif')\n",
    "\n",
    "    zipped_results.close()\n",
    "    return os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','RESULT_{0:0=2d}:{1:0=2d}'.format(now.hour, now.minute)+f'_{description}.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, scheduler, device, num_epochs=13, train_rate: float = 0.8, batch_size: int = 60, path:str = '../Data/N12/Model/', description:str = 'no_description', reference_data:str = ''): \n",
    "    train_loss_history = []\n",
    "    valid_loss_history = []\n",
    "\n",
    "    patch_size = dataloaders['Train'].dataset.data.shape[-1]\n",
    "    training_patches = len(dataloaders['Train'].dataset)\n",
    "    validating_patches = len(dataloaders['Validation'].dataset)\n",
    "    print(f'Training Patches : {training_patches}\\nValidating Patches : {validating_patches}')\n",
    "\n",
    "    best_model_epoch = 0\n",
    "    least_valid_loss = 100\n",
    "    now = datetime.datetime.now()\n",
    "    os.makedirs(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/', 'tmp/'), exist_ok=True)\n",
    "    zipped_model = zipfile.ZipFile(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/', '{0:0=2d}:{1:0=2d}'.format(now.hour, now.minute)+f'_{description}'+'.zip'), 'w')\n",
    "    \n",
    "    epoch_range = tqdm.trange(num_epochs)\n",
    "    for epoch in epoch_range:\n",
    "\n",
    "        train_running_loss = 0.0\n",
    "        valid_running_loss = 0.0\n",
    "\n",
    "        epoch_range.set_description(f'EPOCH #{epoch}')\n",
    "        \n",
    "\n",
    "        for state in ['Train', 'Validation']:\n",
    "            #pbar = tqdm.tqdm(dataloaders[state])\n",
    "            for inputs, labels_OHE, labels in dataloaders[state]:\n",
    "                \n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                model.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                if state == 'Train':\n",
    "                    model.train()\n",
    "                    train_loss = criterion(outputs, labels)\n",
    "                    train_loss.backward()\n",
    "                    train_running_loss += train_loss.item() * inputs.size(0)\n",
    "                    #pbar.set_description('Train')\n",
    "                \n",
    "                if state == 'Validation':\n",
    "                    model.eval()\n",
    "                    valid_loss = criterion(outputs, labels)\n",
    "                    valid_running_loss += valid_loss.item() * inputs.size(0)\n",
    "                    #pbar.set_description('Valid')\n",
    "\n",
    "                optimizer.step()\n",
    "                #valid_running_similarity += metric(outputs, labels)\n",
    "                #print('validating')\n",
    "                \n",
    "                #print(f'{i}th batch')\n",
    "            #pbar.clear()\n",
    "            \n",
    "        epoch_range.refresh()\n",
    "\n",
    "        \n",
    "        #print(f'Memory after a training : {torch.cuda.memory_allocated()/1024/1024}')\n",
    "\n",
    "        epoch_train_loss = train_running_loss / training_patches\n",
    "        epoch_valid_loss = valid_running_loss / validating_patches\n",
    "        scheduler.step(epoch_valid_loss)\n",
    "\n",
    "        #print(f'Valid loss: {epoch_valid_loss} | Train loss: {epoch_train_loss}')\n",
    "\n",
    "\n",
    "        if epoch_valid_loss < least_valid_loss:\n",
    "            least_valid_loss = epoch_valid_loss\n",
    "            best_model_epoch = epoch\n",
    "\n",
    "        train_loss_history.append(epoch_train_loss)      \n",
    "        valid_loss_history.append(epoch_valid_loss)\n",
    "\n",
    "        torch.save(model.state_dict(), os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','tmp/', '{0:0=2d}.pth'.format(epoch)))\n",
    "        zipped_model.write(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','tmp/', '{0:0=2d}.pth'.format(epoch)))\n",
    "\n",
    "    plt.figure(figsize=(20,8))\n",
    "    plt.plot(train_loss_history, 'r-')\n",
    "    plt.plot(valid_loss_history, 'bo')\n",
    "    plt.savefig(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','tmp/', 'Tendency.png'), dpi=300)\n",
    "    zipped_model.write(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','tmp/', 'Tendency.png'))\n",
    "    zipped_model.writestr('README.txt', f'{description}\\nThe best Model : #{best_model_epoch}th model with loss {least_valid_loss}\\nOptimizer : {optimizer}\\nLoss function : {criterion}\\nBatch size : {batch_size}\\nScheduler : {scheduler}\\nPatch size : {patch_size}\\nTotal epochs : {num_epochs}\\nModel information :\\n{model.modules}')\n",
    "    \n",
    "    print('Best loss: {:4f}, in Epoch #{:0=3d}'.format(least_valid_loss, best_model_epoch))    \n",
    "    zipped_model.close()\n",
    "    shutil.copy(src=os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/', 'tmp/', '{0:0=2d}.pth'.format(epoch)), dst=os.path.join(path,f'{now.year}.{now.month}.{now.day}/', 'Best_Model_Parameters_of_{0:0=2d}:{1:0=2d}'.format(now.hour, now.minute)+f'_{description}'+'.pth'))\n",
    "    print('Model information is saved in '+os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/', '{0:0=2d}:{1:0=2d}'.format(now.hour, now.minute)+f'_{description}'+'.zip'))\n",
    "\n",
    "    model.load_state_dict(torch.load(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','tmp/', '{0:0=2d}.pth'.format(best_model_epoch))))\n",
    "    result_path = save_result(model = model.to('cpu'), dataloader=dataloaders['Prediction'], path=path, description=description, reference_data=reference_data, patch_size=patch_size, now=now)\n",
    "    print('Model result is saved in '+ result_path)\n",
    "    \n",
    "    shutil.rmtree(os.path.join(path,f'{now.year}.{now.month}.{now.day}/',f'{description}/','tmp/'))\n",
    "    best_model_path = os.path.join(path,f'{now.year}.{now.month}.{now.day}/', 'Best_Model_Parameters_of_{0:0=2d}:{1:0=2d}'.format(now.hour, now.minute)+f'_{description}'+'.pth')\n",
    "    return best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_raw_files():\n",
    "    '''if os.path.exists('../Data/N12/np/train_array.npy') and os.path.exists('../Data/N12/np/target_array_OHE.npy'):\n",
    "        train_array = np.load('../Data/N12/np/train_array.npy')\n",
    "        target_array = np.load('../Data/N12/np/target_array_OHE.npy')\n",
    "    else:'''\n",
    "    lidar_image = rasterio.open('../Data/N12/N12_lidar.tif').read()\n",
    "    lidar_array = np.array(lidar_image)\n",
    "    lidar_array = log_minmax(lidar_array, dim=(0,1))\n",
    "\n",
    "    lidar_1n_image = rasterio.open('../Data/N12/N12_lidar_1n.tif').read()\n",
    "    lidar_1n_array = np.array(lidar_1n_image)\n",
    "    lidar_1n_array = log_minmax(lidar_1n_array, dim=(0,1))\n",
    "\n",
    "    lidar_nt_image = rasterio.open('../Data/N12/N12_lidar_nt.tif').read()\n",
    "    lidar_nt_array = np.array(lidar_nt_image)\n",
    "    lidar_nt_array = log_minmax(lidar_nt_array, dim=(0,1))\n",
    "\n",
    "    RGB2020_image = rasterio.open('../Data/N12/N12_RGB2020.tif').read()\n",
    "    RGB2020_array = np.array(RGB2020_image)\n",
    "\n",
    "    train_array = np.stack([lidar_array, lidar_1n_array, lidar_nt_array]).squeeze()\n",
    "    train_array = np.concatenate((train_array,RGB2020_array))\n",
    "    target_image = rasterio.open('../Data/N12/N12_newlc.tif').read()\n",
    "    target_array = np.array(target_image, dtype=int).squeeze()\n",
    "    target_array = np.where(target_array == 1, 0, target_array)\n",
    "    target_array = np.where(target_array == 2, 1, target_array)\n",
    "    target_array = np.where(target_array == 7, 2, target_array)\n",
    "    target_array = np.where(target_array == 8, 3, target_array)\n",
    "    target_array = np.where(target_array == 9, 4, target_array)\n",
    "    target_array = np.where(target_array == 10, 5, target_array)\n",
    "    target_array = np.where(target_array == 11, 6, target_array)\n",
    "\n",
    "    target_array_OHE = np.zeros(shape=(7,2400,2400))\n",
    "    num = np.unique(target_array)\n",
    "    num = num.shape[0]\n",
    "    encoded_target_array = np.eye(num)[target_array]\n",
    "    for i in range(encoded_target_array.shape[-1]):\n",
    "        target_array_OHE[i,:,:]=encoded_target_array[:,:,i]\n",
    "\n",
    "    return train_array, target_array.astype(int), target_array_OHE.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset2(Dataset):\n",
    "    def __init__(self, data_array : Type[np.ndarray], target_array_OHE : Type[np.ndarray], target_array_RAW : Type[np.ndarray], patch_size : int, is_evaluating : bool = False, is_validating : bool = False, rotate : bool = False, train_ratio : float = 0.8):\n",
    "        self.is_validating = is_validating\n",
    "        self.is_evaluating = is_evaluating\n",
    "        seed = 386579\n",
    "\n",
    "        #print(f'Data shape: {data_array.shape} | Target shape: {target_array.shape}')\n",
    "\n",
    "        self.data = np.zeros(((data_array.shape[1]//patch_size) * (data_array.shape[2]//patch_size), data_array.shape[0], patch_size, patch_size))\n",
    "\n",
    "        for i in range(0,data_array.shape[1]//patch_size):\n",
    "            for j in range(0,data_array.shape[2]//patch_size):\n",
    "                self.data[data_array.shape[1]//patch_size*i+j,:,:,:] = data_array[:,i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size]\n",
    "\n",
    "        self.label_OHE = np.zeros(((data_array.shape[1]//patch_size) * (data_array.shape[2]//patch_size), target_array_OHE.shape[0] ,patch_size, patch_size), dtype=float)\n",
    "        for k in range(0,data_array.shape[1]//patch_size):\n",
    "            for l in range(0,data_array.shape[2]//patch_size):\n",
    "                self.label_OHE[data_array.shape[1]//patch_size*k+l,:,:,:] = target_array_OHE[:,i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size]\n",
    "\n",
    "        self.label_RAW = np.zeros(((data_array.shape[1]//patch_size) * (data_array.shape[2]//patch_size),data_array.shape[0]+1))\n",
    "        for k in range(0,data_array.shape[1]//patch_size):\n",
    "            for l in range(0,data_array.shape[2]//patch_size):\n",
    "                self.label_RAW[data_array.shape[1]//patch_size*k+l,:] = np.bincount(target_array_RAW[k*patch_size:(k+1)*patch_size, l*patch_size:(l+1)*patch_size].reshape(-1), minlength=7)/(patch_size*patch_size)\n",
    "\n",
    "\n",
    "        if not is_evaluating:\n",
    "            if rotate:\n",
    "                for i in range(2):\n",
    "                    rotated_data = np.rot90(self.data, k=i+1, axes=(-2, -1))\n",
    "                    self.data = np.concatenate((self.data, rotated_data), axis=0)\n",
    "                    rotated_label_OHE = np.rot90(self.label_OHE, k=i+1, axes=(-2, -1))\n",
    "                    rotated_label_RAW = self.label_RAW\n",
    "                    self.label_OHE = np.concatenate((self.label_OHE, rotated_label_OHE), axis=0)\n",
    "                    self.label_RAW = np.concatenate((self.label_RAW, rotated_label_RAW), axis=0)\n",
    "\n",
    "        train_size = int(self.data.shape[0]*train_ratio)\n",
    "        index_array = np.random.RandomState(seed=seed).permutation(self.data.shape[0])\n",
    "        self.train_index = index_array[0:train_size]\n",
    "        self.valid_index = index_array[train_size:index_array.shape[0]]\n",
    "        \n",
    "        self.data = torch.as_tensor(self.data).float()\n",
    "        self.label_OHE = torch.as_tensor(self.label_OHE).float()\n",
    "        self.label_RAW = torch.as_tensor(self.label_RAW).float()\n",
    "\n",
    "        self.data[:,3:6,:,:] = self.data[:,3:6,:,:]/255\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.is_evaluating:\n",
    "            return self.data.shape[0]\n",
    "\n",
    "        if self.is_validating:\n",
    "            return self.valid_index.shape[0]\n",
    "        else:\n",
    "            return self.train_index.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_evaluating:\n",
    "            sample = torch.as_tensor(self.data[idx,:,:,:]).float()\n",
    "            label_OHE = torch.as_tensor(self.label_OHE[idx,:]).float()\n",
    "            label_RAW = torch.as_tensor(self.label_RAW[idx,:]).float()\n",
    "            return sample, label_OHE, label_RAW\n",
    "        \n",
    "        if self.is_validating:\n",
    "            sample = torch.as_tensor(self.data[self.valid_index[idx],:,:,:]).float()\n",
    "            label_OHE = torch.as_tensor(self.label_OHE[self.valid_index[idx],:]).float()\n",
    "            label_RAW = torch.as_tensor(self.label_RAW[self.valid_index[idx],:]).float()\n",
    "        else:\n",
    "            sample = torch.as_tensor(self.data[self.train_index[idx],:,:,:]).float()\n",
    "            label_OHE = torch.as_tensor(self.label_OHE[self.train_index[idx],:]).float()\n",
    "            label_RAW = torch.as_tensor(self.label_RAW[self.train_index[idx],:]).float()\n",
    "\n",
    "        return sample, label_OHE, label_RAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_padding(inputs, kernel_size, dilation):\n",
    "    kernel_size_effective = kernel_size + (kernel_size - 1) * (dilation - 1)\n",
    "    pad_total = kernel_size_effective - 1\n",
    "    pad_beg = pad_total // 2\n",
    "    pad_end = pad_total - pad_beg\n",
    "    padded_inputs = F.pad(inputs, (pad_beg, pad_end, pad_beg, pad_end))\n",
    "    return padded_inputs\n",
    "\n",
    "\n",
    "class SeparableConv2d(nn.Module):\n",
    "    def __init__(self, inplanes, planes, kernel_size=3, stride=1, dilation=1, bias=False, BatchNorm=None):\n",
    "        super(SeparableConv2d, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(inplanes, inplanes, kernel_size, stride, 0, dilation,\n",
    "                               groups=inplanes, bias=bias)\n",
    "        self.bn = BatchNorm(inplanes)\n",
    "        self.pointwise = nn.Conv2d(inplanes, planes, 1, 1, 0, 1, 1, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = fixed_padding(x, self.conv1.kernel_size[0], dilation=self.conv1.dilation[0])\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBN(nn.Module):\n",
    "    def __init__(self, C_in, C_out, kernel_size, stride, dilation = 1, affine=True, fix_padding = False):\n",
    "        super(ConvBN, self).__init__()\n",
    "        self.fix_padding = fix_padding\n",
    "        self.conv2d = nn.Conv2d(C_in, C_in, kernel_size=kernel_size, stride=stride, groups=C_in, bias=False, dilation=dilation)\n",
    "        self.pointwise = nn.Conv2d(C_in, C_out, kernel_size=1, padding=0, bias=False)\n",
    "        self.batchnorm = nn.BatchNorm2d(C_in, affine=affine)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.fix_padding:\n",
    "           x = fixed_padding(x, self.conv2d.kernel_size[0], dilation=self.conv2d.dilation[0])\n",
    "        x = self.conv2d(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UrbanGreenRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UrbanGreenRegression, self).__init__()\n",
    "        '''self.conv_block_1 = nn.Sequential(\n",
    "            ConvBN(6,32,3,1),#98\n",
    "            nn.ReLU(),\n",
    "            ConvBN(32,32,3,1),#96\n",
    "            nn.ReLU(),\n",
    "            ConvBN(32,32,3,1),#94\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)#47\n",
    "        )\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            ConvBN(32,64,3,1),#45\n",
    "            nn.ReLU(),\n",
    "            ConvBN(64,64,3,1),#43\n",
    "            nn.ReLU(),\n",
    "            ConvBN(64,64,3,1),#41\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)#8\n",
    "        )'''\n",
    "\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(6,1,kernel_size=1,stride=1),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc_block_1 = nn.Sequential(\n",
    "            nn.Linear(in_features=100, out_features=256, bias=False),\n",
    "            nn.BatchNorm1d(num_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=256, bias=False),\n",
    "            nn.BatchNorm1d(num_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=256, bias=False),\n",
    "            nn.BatchNorm1d(num_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=256, bias=False),\n",
    "            nn.BatchNorm1d(num_features=256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc_block_2 = nn.Sequential(\n",
    "            nn.Linear(in_features=256, out_features=64, bias=False),\n",
    "            nn.BatchNorm1d(num_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=64, bias=False),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,7, False),\n",
    "            nn.BatchNorm1d(7)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv_block_1(x)\n",
    "        #x = self.conv_block_2(x)\n",
    "        #print(x.shape)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        #print(x.shape)\n",
    "        x = self.fc_block_1(x)\n",
    "        x = self.fc_block_2(x)\n",
    "        return torch.softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_array ,raw_target_array, OHE_target_array = prepare_raw_files()\n",
    "batch_size = 6400\n",
    "patch_size = 10\n",
    "train_ratio = 0.8\n",
    "rotate_training_data = False\n",
    "Datasets_NON_OHE = {\n",
    "    'Train' : TrainDataset2(raw_data_array, OHE_target_array, raw_target_array, patch_size = patch_size, rotate = rotate_training_data, train_ratio = train_ratio),\n",
    "    'Validation' : TrainDataset2(raw_data_array, OHE_target_array, raw_target_array, patch_size = patch_size, is_validating = True, rotate = rotate_training_data, train_ratio = train_ratio),\n",
    "    'Prediction' : TrainDataset2(raw_data_array, OHE_target_array, raw_target_array, patch_size = patch_size, is_evaluating = True, train_ratio = train_ratio)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataloaders_NON_OHE = {\n",
    "    'Train' : DataLoader(Datasets_NON_OHE['Train'], batch_size=batch_size),\n",
    "    'Validation' : DataLoader(Datasets_NON_OHE['Validation'], batch_size=batch_size),\n",
    "    'Prediction' : DataLoader(Datasets_NON_OHE['Prediction'], batch_size=2400//patch_size)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [64, 1, 10, 10]               7\n",
      "       BatchNorm2d-2            [64, 1, 10, 10]               2\n",
      "              ReLU-3            [64, 1, 10, 10]               0\n",
      "            Linear-4                  [64, 256]          25,600\n",
      "       BatchNorm1d-5                  [64, 256]             512\n",
      "              ReLU-6                  [64, 256]               0\n",
      "            Linear-7                  [64, 256]          65,536\n",
      "       BatchNorm1d-8                  [64, 256]             512\n",
      "              ReLU-9                  [64, 256]               0\n",
      "           Linear-10                  [64, 256]          65,536\n",
      "      BatchNorm1d-11                  [64, 256]             512\n",
      "             ReLU-12                  [64, 256]               0\n",
      "           Linear-13                  [64, 256]          65,536\n",
      "      BatchNorm1d-14                  [64, 256]             512\n",
      "             ReLU-15                  [64, 256]               0\n",
      "           Linear-16                   [64, 64]          16,384\n",
      "      BatchNorm1d-17                   [64, 64]             128\n",
      "             ReLU-18                   [64, 64]               0\n",
      "           Linear-19                   [64, 64]           4,096\n",
      "      BatchNorm1d-20                   [64, 64]             128\n",
      "             ReLU-21                   [64, 64]               0\n",
      "           Linear-22                    [64, 7]             448\n",
      "      BatchNorm1d-23                    [64, 7]              14\n",
      "================================================================\n",
      "Total params: 245,463\n",
      "Trainable params: 245,463\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.15\n",
      "Forward/backward pass size (MB): 1.84\n",
      "Params size (MB): 0.94\n",
      "Estimated Total Size (MB): 2.92\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "model_for_summary = UrbanGreenRegression()\n",
    "model_for_summary.to(device)\n",
    "summary(model_for_summary, input_size=(6,10,10), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Patches : 46080\n",
      "Validating Patches : 11520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH #99: 100%|██████████| 100/100 [04:01<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss: 0.056393, in Epoch #099\n",
      "Model information is saved in /home/bcyoon/Byeongchan/Data/N12/Model/Segmentation/Regression/2022.7.26/patch_10_pointwiseConv/15:32_patch_10_pointwiseConv.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting...: : 240it [00:02, 86.95it/s] \n"
     ]
    },
    {
     "ename": "RasterioIOError",
     "evalue": ": No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32mrasterio/_base.pyx\u001b[0m in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mrasterio/_shim.pyx\u001b[0m in \u001b[0;36mrasterio._shim.open_dataset\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mrasterio/_err.pyx\u001b[0m in \u001b[0;36mrasterio._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: : No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRasterioIOError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36886/1131153193.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moptimizer2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscheduler2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mbest_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataloaders_NON_OHE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/home/bcyoon/Byeongchan/Data/N12/Model/Segmentation/Regression/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'patch_10_pointwiseConv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_36886/2890456484.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, criterion, optimizer, scheduler, device, num_epochs, train_rate, batch_size, path, description, reference_data)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'{now.year}.{now.month}.{now.day}/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'{description}/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'tmp/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'{0:0=2d}.pth'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mresult_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Prediction'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreference_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model result is saved in '\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mresult_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_36886/4093458235.py\u001b[0m in \u001b[0;36msave_result\u001b[0;34m(model, dataloader, path, description, reference_data, patch_size, now)\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mprediction_expanded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mreference_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mlayer_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tt/lib/python3.7/site-packages/rasterio/env.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0menv_ctor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tt/lib/python3.7/site-packages/rasterio/__init__.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, width, height, count, crs, transform, dtype, nodata, sharing, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;31m# None.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatasetReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msharing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"r+\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             s = get_writer_for_path(path, driver=driver)(\n",
      "\u001b[0;32mrasterio/_base.pyx\u001b[0m in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRasterioIOError\u001b[0m: : No such file or directory"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2 = UrbanGreenRegression()\n",
    "criterion2 = torch.nn.MSELoss(reduction='mean')\n",
    "optimizer2 = torch.optim.SGD(model2.parameters(), lr=0.01, momentum=0.9)\n",
    "scheduler2 = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer2, 'min', patience=5, factor=0.75)\n",
    "best_model_path = train_model(model2, Dataloaders_NON_OHE, criterion2, optimizer2, scheduler2, device, num_epochs=100, batch_size=batch_size, path='/home/bcyoon/Byeongchan/Data/N12/Model/Segmentation/Regression/', description='patch_10_pointwiseConv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting...: : 240it [00:03, 72.82it/s]\n",
      "Writing data: 100%|██████████| 7/7 [00:01<00:00,  3.82it/s]\n"
     ]
    }
   ],
   "source": [
    "best_model_path = '/home/bcyoon/Byeongchan/Data/N12/Model/Segmentation/Regression/2022.7.26/Best_Model_Parameters_of_15:32_patch_10_pointwiseConv.pth'\n",
    "model2.load_state_dict(torch.load(best_model_path))\n",
    "result_path = save_result(model = model2.to('cpu'), dataloader=Dataloaders_NON_OHE['Prediction'], path='/home/bcyoon/Byeongchan/Data/N12/Model/Segmentation/Regression/', description='patch_10_pointwiseConv', reference_data='/home/bcyoon/Byeongchan/Data/N12/N12_lidar.tif', patch_size=patch_size, now=datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBN(nn.Module):\n",
    "    def __init__(self, Cin, Cout, kernel_size, stride=1):\n",
    "        super(ConvBN,self).__init__()\n",
    "        self.conv = nn.Conv2d(Cin, Cin, kernel_size=kernel_size, stride=stride, groups=Cin, bias=False)\n",
    "        self.batchnorm = nn.BatchNorm2d(Cin)\n",
    "        self.pointwise = nn.Conv2d(Cin, Cout, kernel_size=1, padding=0, bias=False)\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegBlock(nn.Module):\n",
    "    def __init__(self, skip:bool, in_channel:int, out_channel:int, is_last:bool = False):\n",
    "        super(SegBlock,self).__init__()\n",
    "        self.skip = skip\n",
    "        self.is_last = is_last\n",
    "        self.conv1 = ConvBN(in_channel, out_channel, kernel_size=3, stride=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = ConvBN(out_channel, out_channel, kernel_size=3, stride=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [16, 64, 138, 138]             576\n",
      "       BatchNorm2d-2         [16, 64, 138, 138]             128\n",
      "            Conv2d-3        [16, 128, 138, 138]           8,192\n",
      "            ConvBN-4        [16, 128, 138, 138]               0\n",
      "              ReLU-5        [16, 128, 138, 138]               0\n",
      "            Conv2d-6        [16, 128, 136, 136]           1,152\n",
      "       BatchNorm2d-7        [16, 128, 136, 136]             256\n",
      "            Conv2d-8        [16, 128, 136, 136]          16,384\n",
      "            ConvBN-9        [16, 128, 136, 136]               0\n",
      "             ReLU-10        [16, 128, 136, 136]               0\n",
      "================================================================\n",
      "Total params: 26,688\n",
      "Trainable params: 26,688\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 76.56\n",
      "Forward/backward pass size (MB): 2635.25\n",
      "Params size (MB): 0.10\n",
      "Estimated Total Size (MB): 2711.91\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_for_summary = SegBlock(skip=True, in_channel=64, out_channel=128)\n",
    "model_for_summary.to(device)\n",
    "summary(model_for_summary, input_size=(64,140,140), batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_add(skip:Type[torch.Tensor], target:Type[torch.Tensor])->torch.Tensor:\n",
    "    cropped_skip = skip[:,:,(skip.shape[-2]-target.shape[-2])//2:(skip.shape[-2]+target.shape[-2])//2,(skip.shape[-1]-target.shape[-1])//2:(skip.shape[-1]+target.shape[-1])//2]\n",
    "    return torch.cat((cropped_skip, target), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net 마지막에 Fully Convolutional Layer 추가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        self.enc1 = SegBlock(True, 3,64)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.enc2 = SegBlock(True, 64,128)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.enc3 = SegBlock(True, 128, 256)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.enc4 = SegBlock(True, 256, 512)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "        self.dec0 = SegBlock(False, 512, 1024)\n",
    "        self.upconv1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.dec1 = SegBlock(False,1024,512)\n",
    "        self.upconv2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec2 = SegBlock(False,512,256)\n",
    "        self.upconv3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec3 = SegBlock(False,256,128)\n",
    "        self.upconv4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec4 = SegBlock(False,128,64, is_last = True)\n",
    "\n",
    "    def forward(self,x):\n",
    "        enc1 = self.enc1(x)\n",
    "        x = self.pool1(enc1)\n",
    "        enc2 = self.enc2(x)\n",
    "        x = self.pool2(enc2)\n",
    "        enc3 = self.enc3(x)\n",
    "        x = self.pool3(enc3)\n",
    "        enc4 = self.enc4(x)\n",
    "        x = self.pool4(enc4)\n",
    "        x = self.dec0(x)\n",
    "        x = self.upconv1(x)\n",
    "        x = self.dec1(crop_add(enc4, x))\n",
    "        x = self.upconv2(x)\n",
    "        x = self.dec2(crop_add(enc3, x))\n",
    "        x = self.upconv3(x)\n",
    "        x = self.dec3(crop_add(enc2, x))\n",
    "        x = self.upconv4(x)\n",
    "        x = self.dec4(crop_add(enc1, x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [4, 3, 282, 282]              27\n",
      "       BatchNorm2d-2           [4, 3, 282, 282]               6\n",
      "            Conv2d-3          [4, 64, 282, 282]             192\n",
      "            ConvBN-4          [4, 64, 282, 282]               0\n",
      "              ReLU-5          [4, 64, 282, 282]               0\n",
      "            Conv2d-6          [4, 64, 280, 280]             576\n",
      "       BatchNorm2d-7          [4, 64, 280, 280]             128\n",
      "            Conv2d-8          [4, 64, 280, 280]           4,096\n",
      "            ConvBN-9          [4, 64, 280, 280]               0\n",
      "             ReLU-10          [4, 64, 280, 280]               0\n",
      "         SegBlock-11          [4, 64, 280, 280]               0\n",
      "        MaxPool2d-12          [4, 64, 140, 140]               0\n",
      "           Conv2d-13          [4, 64, 138, 138]             576\n",
      "      BatchNorm2d-14          [4, 64, 138, 138]             128\n",
      "           Conv2d-15         [4, 128, 138, 138]           8,192\n",
      "           ConvBN-16         [4, 128, 138, 138]               0\n",
      "             ReLU-17         [4, 128, 138, 138]               0\n",
      "           Conv2d-18         [4, 128, 136, 136]           1,152\n",
      "      BatchNorm2d-19         [4, 128, 136, 136]             256\n",
      "           Conv2d-20         [4, 128, 136, 136]          16,384\n",
      "           ConvBN-21         [4, 128, 136, 136]               0\n",
      "             ReLU-22         [4, 128, 136, 136]               0\n",
      "         SegBlock-23         [4, 128, 136, 136]               0\n",
      "        MaxPool2d-24           [4, 128, 68, 68]               0\n",
      "           Conv2d-25           [4, 128, 66, 66]           1,152\n",
      "      BatchNorm2d-26           [4, 128, 66, 66]             256\n",
      "           Conv2d-27           [4, 256, 66, 66]          32,768\n",
      "           ConvBN-28           [4, 256, 66, 66]               0\n",
      "             ReLU-29           [4, 256, 66, 66]               0\n",
      "           Conv2d-30           [4, 256, 64, 64]           2,304\n",
      "      BatchNorm2d-31           [4, 256, 64, 64]             512\n",
      "           Conv2d-32           [4, 256, 64, 64]          65,536\n",
      "           ConvBN-33           [4, 256, 64, 64]               0\n",
      "             ReLU-34           [4, 256, 64, 64]               0\n",
      "         SegBlock-35           [4, 256, 64, 64]               0\n",
      "        MaxPool2d-36           [4, 256, 32, 32]               0\n",
      "           Conv2d-37           [4, 256, 30, 30]           2,304\n",
      "      BatchNorm2d-38           [4, 256, 30, 30]             512\n",
      "           Conv2d-39           [4, 512, 30, 30]         131,072\n",
      "           ConvBN-40           [4, 512, 30, 30]               0\n",
      "             ReLU-41           [4, 512, 30, 30]               0\n",
      "           Conv2d-42           [4, 512, 28, 28]           4,608\n",
      "      BatchNorm2d-43           [4, 512, 28, 28]           1,024\n",
      "           Conv2d-44           [4, 512, 28, 28]         262,144\n",
      "           ConvBN-45           [4, 512, 28, 28]               0\n",
      "             ReLU-46           [4, 512, 28, 28]               0\n",
      "         SegBlock-47           [4, 512, 28, 28]               0\n",
      "        MaxPool2d-48           [4, 512, 14, 14]               0\n",
      "           Conv2d-49           [4, 512, 12, 12]           4,608\n",
      "      BatchNorm2d-50           [4, 512, 12, 12]           1,024\n",
      "           Conv2d-51          [4, 1024, 12, 12]         524,288\n",
      "           ConvBN-52          [4, 1024, 12, 12]               0\n",
      "             ReLU-53          [4, 1024, 12, 12]               0\n",
      "           Conv2d-54          [4, 1024, 10, 10]           9,216\n",
      "      BatchNorm2d-55          [4, 1024, 10, 10]           2,048\n",
      "           Conv2d-56          [4, 1024, 10, 10]       1,048,576\n",
      "           ConvBN-57          [4, 1024, 10, 10]               0\n",
      "             ReLU-58          [4, 1024, 10, 10]               0\n",
      "         SegBlock-59          [4, 1024, 10, 10]               0\n",
      "  ConvTranspose2d-60           [4, 512, 20, 20]       2,097,664\n",
      "           Conv2d-61          [4, 1024, 18, 18]           9,216\n",
      "      BatchNorm2d-62          [4, 1024, 18, 18]           2,048\n",
      "           Conv2d-63           [4, 512, 18, 18]         524,288\n",
      "           ConvBN-64           [4, 512, 18, 18]               0\n",
      "             ReLU-65           [4, 512, 18, 18]               0\n",
      "           Conv2d-66           [4, 512, 16, 16]           4,608\n",
      "      BatchNorm2d-67           [4, 512, 16, 16]           1,024\n",
      "           Conv2d-68           [4, 512, 16, 16]         262,144\n",
      "           ConvBN-69           [4, 512, 16, 16]               0\n",
      "             ReLU-70           [4, 512, 16, 16]               0\n",
      "         SegBlock-71           [4, 512, 16, 16]               0\n",
      "  ConvTranspose2d-72           [4, 256, 32, 32]         524,544\n",
      "           Conv2d-73           [4, 512, 30, 30]           4,608\n",
      "      BatchNorm2d-74           [4, 512, 30, 30]           1,024\n",
      "           Conv2d-75           [4, 256, 30, 30]         131,072\n",
      "           ConvBN-76           [4, 256, 30, 30]               0\n",
      "             ReLU-77           [4, 256, 30, 30]               0\n",
      "           Conv2d-78           [4, 256, 28, 28]           2,304\n",
      "      BatchNorm2d-79           [4, 256, 28, 28]             512\n",
      "           Conv2d-80           [4, 256, 28, 28]          65,536\n",
      "           ConvBN-81           [4, 256, 28, 28]               0\n",
      "             ReLU-82           [4, 256, 28, 28]               0\n",
      "         SegBlock-83           [4, 256, 28, 28]               0\n",
      "  ConvTranspose2d-84           [4, 128, 56, 56]         131,200\n",
      "           Conv2d-85           [4, 256, 54, 54]           2,304\n",
      "      BatchNorm2d-86           [4, 256, 54, 54]             512\n",
      "           Conv2d-87           [4, 128, 54, 54]          32,768\n",
      "           ConvBN-88           [4, 128, 54, 54]               0\n",
      "             ReLU-89           [4, 128, 54, 54]               0\n",
      "           Conv2d-90           [4, 128, 52, 52]           1,152\n",
      "      BatchNorm2d-91           [4, 128, 52, 52]             256\n",
      "           Conv2d-92           [4, 128, 52, 52]          16,384\n",
      "           ConvBN-93           [4, 128, 52, 52]               0\n",
      "             ReLU-94           [4, 128, 52, 52]               0\n",
      "         SegBlock-95           [4, 128, 52, 52]               0\n",
      "  ConvTranspose2d-96          [4, 64, 104, 104]          32,832\n",
      "           Conv2d-97         [4, 128, 102, 102]           1,152\n",
      "      BatchNorm2d-98         [4, 128, 102, 102]             256\n",
      "           Conv2d-99          [4, 64, 102, 102]           8,192\n",
      "          ConvBN-100          [4, 64, 102, 102]               0\n",
      "            ReLU-101          [4, 64, 102, 102]               0\n",
      "          Conv2d-102          [4, 64, 100, 100]             576\n",
      "     BatchNorm2d-103          [4, 64, 100, 100]             128\n",
      "          Conv2d-104          [4, 64, 100, 100]           4,096\n",
      "          ConvBN-105          [4, 64, 100, 100]               0\n",
      "            ReLU-106          [4, 64, 100, 100]               0\n",
      "        SegBlock-107          [4, 64, 100, 100]               0\n",
      "================================================================\n",
      "Total params: 5,988,065\n",
      "Trainable params: 5,988,065\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.69\n",
      "Forward/backward pass size (MB): 3287.94\n",
      "Params size (MB): 22.84\n",
      "Estimated Total Size (MB): 3314.47\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_for_summary = UNet()\n",
    "model_for_summary.to(device)\n",
    "summary(model_for_summary, input_size=(3,284,284), batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNET에 쓸 Mirroring Extrapolation 함수 추가\n",
    "## Regression 결과 Bilinear Interpolation 함수 추가\n",
    "## Regression 결과 Fully Convolutional Layer에 조합할 연산 추가, 이후 다시 Convolutional Layer 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UrbanGreenSegmentation(pl.LightningModule):\n",
    "    def __init__(self, rotate_training_data : bool = False, train_ratio : float = 0.8, patch_size : int = 100, batch_size : int = 16):\n",
    "        super(UrbanGreenSegmentation, self).__init__()\n",
    "        raw_data_array, OHE_target_array, raw_target_array = prepare_raw_files()\n",
    "        self.batch_size = batch_size\n",
    "        self.Datasets = {\n",
    "            'Train' : TrainDataset2(raw_data_array, OHE_target_array, raw_target_array, patch_size = patch_size, rotate = rotate_training_data, train_ratio = train_ratio),\n",
    "            'Validation' : TrainDataset2(raw_data_array, OHE_target_array, raw_target_array, patch_size = patch_size, is_validating = True, rotate = rotate_training_data, train_ratio = train_ratio),\n",
    "            'Prediction' : TrainDataset2(raw_data_array, OHE_target_array, raw_target_array, patch_size = patch_size, is_evaluating = True, train_ratio = train_ratio)\n",
    "        }\n",
    "        self.Dataloaders = {\n",
    "            'Train' : DataLoader(self.Datasets['Train'], batch_size=batch_size),\n",
    "            'Validation' : DataLoader(self.Datasets['Validation'], batch_size=batch_size),\n",
    "            'Prediction' : DataLoader(self.Datasets['Prediction'], batch_size=batch_size)\n",
    "        }\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        pass\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        pass\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        pass\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        train_optimizer = torch.optim.Adam(self.parameters(), lr=0.02)\n",
    "        train_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(train_optimizer, T_max=10)\n",
    "        return [train_optimizer], [train_scheduler]\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.Datasets['Train'], batch_size = self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.Datasets['Validation'], batch_size = self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.Datasets['Prediction'], batch_size = self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('tt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bef1a0741f78125b97ca6015f4b21165d553afbb2c419d3dfb1350931d81372"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
